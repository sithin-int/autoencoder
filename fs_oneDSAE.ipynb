{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b54003-83d4-4e49-bc27-639bf5e0e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils as utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e2f99-9a00-49e9-b816-32a704ed876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"inputs/radiomicsFeatures.csv\"\n",
    "OUT_DIR = r\"outputs/oneDSAE\"\n",
    "MASK_FEATS = [\"id\", \"label\"]\n",
    "\n",
    "NUM_REPEATS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7772f5-6eb3-4748-bf66-1528e9d8b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_wout_original_glcm_ClusterProminence</th>\n",
       "      <th>adc_original_firstorder_Minimum</th>\n",
       "      <th>sub_wout_original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>sub_wout_original_firstorder_Maximum</th>\n",
       "      <th>adc_original_glcm_ClusterShade</th>\n",
       "      <th>sub_wout_original_firstorder_Mean</th>\n",
       "      <th>sub_win_original_glcm_Autocorrelation</th>\n",
       "      <th>adc_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_win_original_glszm_ZoneEntropy</th>\n",
       "      <th>t2w_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>t2w_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glcm_MaximumProbability</th>\n",
       "      <th>sub_win_original_glcm_Imc1</th>\n",
       "      <th>sub_wout_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2535039</td>\n",
       "      <td>1</td>\n",
       "      <td>4.677862e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14835.837461</td>\n",
       "      <td>299.900214</td>\n",
       "      <td>3755.933491</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>...</td>\n",
       "      <td>6.339939</td>\n",
       "      <td>0.286470</td>\n",
       "      <td>10.166389</td>\n",
       "      <td>27423.571919</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>2946.837800</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.041978</td>\n",
       "      <td>10.452108</td>\n",
       "      <td>0.033786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2417361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.834267e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-17634.034850</td>\n",
       "      <td>299.918235</td>\n",
       "      <td>3941.494865</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.424770</td>\n",
       "      <td>0.350004</td>\n",
       "      <td>11.649157</td>\n",
       "      <td>21732.551407</td>\n",
       "      <td>0.604518</td>\n",
       "      <td>3322.225544</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.109242</td>\n",
       "      <td>11.891117</td>\n",
       "      <td>0.009861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2602563</td>\n",
       "      <td>1</td>\n",
       "      <td>5.159220e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-19736.430500</td>\n",
       "      <td>299.820687</td>\n",
       "      <td>2455.254084</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>...</td>\n",
       "      <td>7.239270</td>\n",
       "      <td>0.350692</td>\n",
       "      <td>10.919838</td>\n",
       "      <td>15567.069802</td>\n",
       "      <td>0.574356</td>\n",
       "      <td>3407.597573</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.194449</td>\n",
       "      <td>11.214368</td>\n",
       "      <td>0.018991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2902440</td>\n",
       "      <td>0</td>\n",
       "      <td>3.613791e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-12881.976888</td>\n",
       "      <td>299.240444</td>\n",
       "      <td>3954.079034</td>\n",
       "      <td>0.576021</td>\n",
       "      <td>...</td>\n",
       "      <td>7.454390</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>18389.243521</td>\n",
       "      <td>0.566131</td>\n",
       "      <td>3121.573712</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>11.669841</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2921898</td>\n",
       "      <td>0</td>\n",
       "      <td>5.773968e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2116.811733</td>\n",
       "      <td>299.983523</td>\n",
       "      <td>3793.819336</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.755170</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>9.504938</td>\n",
       "      <td>245786.779116</td>\n",
       "      <td>0.469149</td>\n",
       "      <td>3175.569089</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.058680</td>\n",
       "      <td>11.459667</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  sub_wout_original_glcm_ClusterProminence  \\\n",
       "0  2535039      1                              4.677862e+06   \n",
       "1  2417361      0                              4.834267e+06   \n",
       "2  2602563      1                              5.159220e+06   \n",
       "3  2902440      0                              3.613791e+06   \n",
       "4  2921898      0                              5.773968e+06   \n",
       "\n",
       "   adc_original_firstorder_Minimum  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              0.0   \n",
       "\n",
       "   sub_wout_original_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                          0.003103   \n",
       "1                                          0.001672   \n",
       "2                                          0.001600   \n",
       "3                                          0.002428   \n",
       "4                                          0.001720   \n",
       "\n",
       "   sub_wout_original_firstorder_Maximum  adc_original_glcm_ClusterShade  \\\n",
       "0                                 600.0                    14835.837461   \n",
       "1                                 600.0                   -17634.034850   \n",
       "2                                 600.0                   -19736.430500   \n",
       "3                                 600.0                   -12881.976888   \n",
       "4                                 600.0                     2116.811733   \n",
       "\n",
       "   sub_wout_original_firstorder_Mean  sub_win_original_glcm_Autocorrelation  \\\n",
       "0                         299.900214                            3755.933491   \n",
       "1                         299.918235                            3941.494865   \n",
       "2                         299.820687                            2455.254084   \n",
       "3                         299.240444                            3954.079034   \n",
       "4                         299.983523                            3793.819336   \n",
       "\n",
       "   adc_original_glszm_LargeAreaLowGrayLevelEmphasis  ...  \\\n",
       "0                                          0.010393  ...   \n",
       "1                                          0.058145  ...   \n",
       "2                                          0.019202  ...   \n",
       "3                                          0.576021  ...   \n",
       "4                                          0.011764  ...   \n",
       "\n",
       "   sub_win_original_glszm_ZoneEntropy  \\\n",
       "0                            6.339939   \n",
       "1                            7.424770   \n",
       "2                            7.239270   \n",
       "3                            7.454390   \n",
       "4                            6.755170   \n",
       "\n",
       "   t2w_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.286470    \n",
       "1                                           0.350004    \n",
       "2                                           0.350692    \n",
       "3                                           0.380537    \n",
       "4                                           0.265413    \n",
       "\n",
       "   t2w_original_glcm_JointEntropy  \\\n",
       "0                       10.166389   \n",
       "1                       11.649157   \n",
       "2                       10.919838   \n",
       "3                       11.530000   \n",
       "4                        9.504938   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                       27423.571919   \n",
       "1                                       21732.551407   \n",
       "2                                       15567.069802   \n",
       "3                                       18389.243521   \n",
       "4                                      245786.779116   \n",
       "\n",
       "   sub_win_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.461100        \n",
       "1                                           0.604518        \n",
       "2                                           0.574356        \n",
       "3                                           0.566131        \n",
       "4                                           0.469149        \n",
       "\n",
       "   sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                        2946.837800        \n",
       "1                                        3322.225544        \n",
       "2                                        3407.597573        \n",
       "3                                        3121.573712        \n",
       "4                                        3175.569089        \n",
       "\n",
       "   sub_win_original_glcm_MaximumProbability  sub_win_original_glcm_Imc1  \\\n",
       "0                                  0.034622                   -0.041978   \n",
       "1                                  0.002107                   -0.109242   \n",
       "2                                  0.004002                   -0.194449   \n",
       "3                                  0.004134                   -0.116415   \n",
       "4                                  0.027634                   -0.058680   \n",
       "\n",
       "   sub_wout_original_glcm_JointEntropy  \\\n",
       "0                            10.452108   \n",
       "1                            11.891117   \n",
       "2                            11.214368   \n",
       "3                            11.669841   \n",
       "4                            11.459667   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaLowGrayLevelEmphasis  \n",
       "0                                          0.033786  \n",
       "1                                          0.009861  \n",
       "2                                          0.018991  \n",
       "3                                          0.007846  \n",
       "4                                          0.024444  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c7db66-a4d3-4a87-ba00-1ee6878852f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = feats_df.id.to_numpy()\n",
    "labels = feats_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b7a02-3bc1-474b-ba32-8be75ab9ceb1",
   "metadata": {},
   "source": [
    "### Feature Selection Pipeline with MonteCarlo Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451ea514-c68e-4faa-b273-5430c3631f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for repeat#- 1\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.603975\n",
      "normal_mse= 0.9684318182143298 anomaly_mse= 0.8721424842422659 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 2\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.858169\n",
      "normal_mse= 1.0763739157806744 anomaly_mse= 1.0638659000396729 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 3\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.876221\n",
      "normal_mse= 0.7182127603075721 anomaly_mse= 0.865104316310449 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 4\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.810794\n",
      "normal_mse= 0.9955791221423582 anomaly_mse= 1.233290200883692 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 5\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.454107\n",
      "normal_mse= 1.03682079911232 anomaly_mse= 1.2217128344557502 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 6\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.638454\n",
      "normal_mse= 1.3150790699503638 anomaly_mse= 1.2912783893671902 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 7\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.538662\n",
      "normal_mse= 1.107121615247293 anomaly_mse= 1.0925410850481554 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 8\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.502375\n",
      "normal_mse= 1.1203325194391338 anomaly_mse= 0.9696184762499549 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 9\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.880097\n",
      "normal_mse= 1.0143078822981229 anomaly_mse= 0.9497820741750977 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 10\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.863944\n",
      "normal_mse= 1.1413621414791455 anomaly_mse= 0.9264362264763225 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 11\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.882417\n",
      "normal_mse= 0.8198954815214331 anomaly_mse= 0.8518824401226911 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 12\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.407085\n",
      "normal_mse= 0.8743532299995422 anomaly_mse= 0.8803339153528214 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 13\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.870980\n",
      "normal_mse= 0.9863062622872266 anomaly_mse= 0.9413491392677481 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 14\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.496483\n",
      "normal_mse= 1.1921930455348708 anomaly_mse= 1.4018744826316833 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 15\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.669820\n",
      "normal_mse= 0.7545769167217341 anomaly_mse= 0.8495396856557239 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 16\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.860480\n",
      "normal_mse= 1.0219563787633723 anomaly_mse= 0.8732676587321542 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 17\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.850487\n",
      "normal_mse= 0.7076275633140043 anomaly_mse= 0.7847939905795184 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 18\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837621\n",
      "normal_mse= 0.9359122419899161 anomaly_mse= 0.9239769591526552 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 19\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862734\n",
      "normal_mse= 0.8988609219139273 anomaly_mse= 0.8756436333060265 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 20\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.495886\n",
      "normal_mse= 0.7586161738092249 anomaly_mse= 0.7735703641718085 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 21\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.502160\n",
      "normal_mse= 0.5711664252660491 anomaly_mse= 0.8888886123895645 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 22\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.860920\n",
      "normal_mse= 0.8505253168669614 anomaly_mse= 0.9605185382745483 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 23\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.871203\n",
      "normal_mse= 0.7310242639346556 anomaly_mse= 0.7518794719468463 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 24\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.870360\n",
      "normal_mse= 0.7523843442851846 anomaly_mse= 0.880019102584232 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 25\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.866981\n",
      "normal_mse= 1.09049700606953 anomaly_mse= 0.9080881842158057 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 26\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.680740\n",
      "normal_mse= 0.8586562926119025 anomaly_mse= 0.8858568207784132 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 27\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.866674\n",
      "normal_mse= 1.0636605823581868 anomaly_mse= 0.9721332571723245 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 28\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.470077\n",
      "normal_mse= 0.8381837985732339 anomaly_mse= 0.9271444827318192 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 29\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.878217\n",
      "normal_mse= 0.7606912878426638 anomaly_mse= 0.890423635867509 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 30\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.840186\n",
      "normal_mse= 0.7039429992437363 anomaly_mse= 0.8503608818758618 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 31\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.287132\n",
      "normal_mse= 0.7208399637178942 anomaly_mse= 0.6746162433515895 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 32\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.688683\n",
      "normal_mse= 0.7640604864467274 anomaly_mse= 0.8265174566344782 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 33\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.865591\n",
      "normal_mse= 0.8281600705601952 anomaly_mse= 0.744878077371554 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 34\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.903945\n",
      "normal_mse= 0.757634622129527 anomaly_mse= 0.8568477535789664 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 35\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.592461\n",
      "normal_mse= 0.9134055091576143 anomaly_mse= 0.8050666939128529 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 36\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.815786\n",
      "normal_mse= 0.8129297684539448 anomaly_mse= 0.9068572290919044 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 37\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.394418\n",
      "normal_mse= 0.7583286423574794 anomaly_mse= 0.8707078492099588 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 38\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.867392\n",
      "normal_mse= 0.8307933739640496 anomaly_mse= 0.728929689662023 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 39\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.878579\n",
      "normal_mse= 1.0972078564492138 anomaly_mse= 1.0250117981975728 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 40\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.893251\n",
      "normal_mse= 0.7993296845392748 anomaly_mse= 1.0084191675890575 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 41\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.872289\n",
      "normal_mse= 0.8059593926776539 anomaly_mse= 0.8389066877690229 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 42\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.495623\n",
      "normal_mse= 1.0414815247058868 anomaly_mse= 1.0835704451257533 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 43\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.867783\n",
      "normal_mse= 0.8865636898712679 anomaly_mse= 1.020814535292712 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 44\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.859192\n",
      "normal_mse= 0.7507703561674465 anomaly_mse= 0.8908894211053848 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 45\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.817467\n",
      "normal_mse= 0.7707359079610218 anomaly_mse= 0.8531146808104082 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 46\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.858613\n",
      "normal_mse= 0.6451984223994341 anomaly_mse= 0.7240889485586773 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 47\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.870216\n",
      "normal_mse= 0.843971161679788 anomaly_mse= 0.8608696027235552 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 48\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.853317\n",
      "normal_mse= 0.8633318638259714 anomaly_mse= 0.8703721355308186 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 49\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.826262\n",
      "normal_mse= 1.091048537330194 anomaly_mse= 0.9818945709954608 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 50\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.507514\n",
      "normal_mse= 0.8125211637128483 anomaly_mse= 0.7603199637748979 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 51\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.546510\n",
      "normal_mse= 1.0099137357690118 anomaly_mse= 1.2203834056854248 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 52\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.861637\n",
      "normal_mse= 0.8614651804620569 anomaly_mse= 0.8840687125921249 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 53\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.872541\n",
      "normal_mse= 0.7789859785275026 anomaly_mse= 0.7328373823653568 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 54\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.462673\n",
      "normal_mse= 0.7143940248272636 anomaly_mse= 0.9230264073068445 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 55\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851057\n",
      "normal_mse= 1.0140852684324437 anomaly_mse= 0.9362118379636244 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 56\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.404388\n",
      "normal_mse= 1.0093199055303226 anomaly_mse= 0.9268883852796121 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 57\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879667\n",
      "normal_mse= 0.8072842061519623 anomaly_mse= 0.9191720695658163 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 58\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.838773\n",
      "normal_mse= 0.7788745002313093 anomaly_mse= 0.7393674335696481 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 59\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.850167\n",
      "normal_mse= 0.9672132147984072 anomaly_mse= 0.9923388341611082 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 60\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.520329\n",
      "normal_mse= 1.050608297640627 anomaly_mse= 0.9370135272091086 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 61\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.861862\n",
      "normal_mse= 0.9667178351770748 anomaly_mse= 0.9349133805795149 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 62\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.872214\n",
      "normal_mse= 0.829339857805859 anomaly_mse= 0.8883010853420604 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 63\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.883898\n",
      "normal_mse= 0.9396104067564011 anomaly_mse= 0.9517676532268524 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 64\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.743649\n",
      "normal_mse= 1.0332482606172562 anomaly_mse= 0.8507842313159596 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 65\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.852523\n",
      "normal_mse= 0.7286301553249359 anomaly_mse= 0.9758338968862187 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 66\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851918\n",
      "normal_mse= 0.8970807086337697 anomaly_mse= 0.9282534312118184 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 67\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837819\n",
      "normal_mse= 0.6170933842658997 anomaly_mse= 0.7750472941181876 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 68\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.623795\n",
      "normal_mse= 0.982290202921087 anomaly_mse= 0.9164913289926269 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 69\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.895534\n",
      "normal_mse= 0.9146848036484285 anomaly_mse= 0.9465029679916122 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 70\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.877758\n",
      "normal_mse= 0.9037244062532078 anomaly_mse= 0.8981385359709914 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 71\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.858148\n",
      "normal_mse= 0.8622090897776864 anomaly_mse= 0.799062036655166 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 72\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.886778\n",
      "normal_mse= 0.848782101815397 anomaly_mse= 0.8383101204579527 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 73\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.498870\n",
      "normal_mse= 1.0546344911510295 anomaly_mse= 1.098104722120545 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 74\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.855774\n",
      "normal_mse= 0.819871948523955 anomaly_mse= 0.8608268309723247 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 75\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.556336\n",
      "normal_mse= 0.7831575897606936 anomaly_mse= 0.6830609054727987 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 76\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.817168\n",
      "normal_mse= 0.9729881720109419 anomaly_mse= 0.9323099614544348 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 77\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.576902\n",
      "normal_mse= 0.9454194077036597 anomaly_mse= 0.8149425197731365 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 78\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.512952\n",
      "normal_mse= 0.9859875738620758 anomaly_mse= 1.1892439316619525 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 79\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.871228\n",
      "normal_mse= 0.8923542242158543 anomaly_mse= 0.9660842445763674 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 80\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.899224\n",
      "normal_mse= 0.7707702937451276 anomaly_mse= 0.9991526983001016 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 81\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851067\n",
      "normal_mse= 0.8803420662879944 anomaly_mse= 0.8744927685369145 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 82\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.895810\n",
      "normal_mse= 1.2366170314225284 anomaly_mse= 1.1092688671567223 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 83\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.570452\n",
      "normal_mse= 0.9413809369910847 anomaly_mse= 0.9544353932142258 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 84\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.562050\n",
      "normal_mse= 1.1897230249914257 anomaly_mse= 1.046390869400718 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 85\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.835168\n",
      "normal_mse= 1.069933919744058 anomaly_mse= 1.0988275456157597 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 86\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.873215\n",
      "normal_mse= 0.629757512699474 anomaly_mse= 0.6950696178457954 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 87\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.921096\n",
      "normal_mse= 0.9084846445105292 anomaly_mse= 0.9474893808364868 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 88\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.842198\n",
      "normal_mse= 0.7532383311878551 anomaly_mse= 0.8244120559909127 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 89\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.619505\n",
      "normal_mse= 0.6316661739891226 anomaly_mse= 0.7995967743071642 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 90\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.479209\n",
      "normal_mse= 0.8846359103918076 anomaly_mse= 0.8556383130225268 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 91\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.887816\n",
      "normal_mse= 0.8960833969441327 anomaly_mse= 0.8856619257818569 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 92\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.854646\n",
      "normal_mse= 0.8458001044663516 anomaly_mse= 0.8976266790520061 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 93\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.847672\n",
      "normal_mse= 1.002625357020985 anomaly_mse= 0.8360538347200914 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 94\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.842971\n",
      "normal_mse= 0.7622606794942509 anomaly_mse= 0.8621172275055539 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 95\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.859325\n",
      "normal_mse= 0.721326391805302 anomaly_mse= 0.8339828693053939 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 96\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.542036\n",
      "normal_mse= 0.7955198057673194 anomaly_mse= 1.0172775807705792 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 97\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.475901\n",
      "normal_mse= 0.9024190401489084 anomaly_mse= 0.9694597125053406 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 98\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.440362\n",
      "normal_mse= 0.802900340069424 anomaly_mse= 0.881044780666178 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 99\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862100\n",
      "normal_mse= 0.9509986178441481 anomaly_mse= 0.8816179050640627 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 100\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862515\n",
      "normal_mse= 0.9424419863657518 anomaly_mse= 0.9711165780370886 anomaly_mse>normal_mse= True\n"
     ]
    }
   ],
   "source": [
    "feats = feats_df.columns[~feats_df.columns.isin(MASK_FEATS)].to_list()\n",
    "\n",
    "results_df = {**{\"outer_seed\":[], \"exe_time\":[], \"re_mean\":[]}, **{\"re_\"+feat:[] for feat in feats}, **{\"label\":[]}} # {**dict1, **dict2,...} is a way to merge multiple dictionaries\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for i in range(NUM_REPEATS):\n",
    "\n",
    "    print(f\"Running for repeat#- {i+1}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_epochs = 1_000\n",
    "    batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    lr = 1e-3\n",
    "    h_lambda = 1e-2 #with l1 regularization\n",
    "    \n",
    "    input_dim = len(feats)\n",
    "    latent_dim = 10\n",
    "    \n",
    "    activation_fn = nn.LeakyReLU()\n",
    "    encoder_layers = [50, 30, 20] #under-complete hidden layers\n",
    "\n",
    "    train_pids, test_pids, train_labels, test_labels = train_test_split(pids, labels, test_size=0.25, random_state=i, stratify=labels)\n",
    "\n",
    "    \n",
    "    X =  feats_df[feats_df[\"id\"].isin(train_pids)][feats].to_numpy()\n",
    "    y = feats_df[feats_df[\"id\"].isin(train_pids)].label.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # X[X>=3] = 3\n",
    "    # X[X<=-3] = -3\n",
    "\n",
    "    X_norm, X_anomaly = utils.norm_anomaly_split(X, y)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    idx = np.random.permutation(len(X_norm))\n",
    "    \n",
    "    X_train= X_norm[idx[:-len(X_anomaly)]]\n",
    "    X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "    X_test_anomaly = X_anomaly\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train[X_train>=3] = 3\n",
    "    X_train[X_train<=-3] = -3\n",
    "    \n",
    "    X_test_norm = scaler.transform(X_test_norm)\n",
    "    X_test_norm[X_test_norm>=3] = 3\n",
    "    X_test_norm[X_test_norm<=-3] = -3\n",
    "    \n",
    "    X_test_anomaly = scaler.transform(X_test_anomaly)\n",
    "    X_test_anomaly[X_test_anomaly>=3] = 3\n",
    "    X_test_anomaly[X_test_anomaly<=-3] = -3\n",
    "    \n",
    "    \n",
    "    X_train =  torch.from_numpy(X_train).float()\n",
    "   \n",
    "    X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "    X_test_anomaly = torch.from_numpy(X_test_anomaly).float()\n",
    "    X_test = torch.cat([X_test_norm, X_test_anomaly])\n",
    "\n",
    "    train_ds = utils.Dataset(X_train)\n",
    "    val_ds = utils.Dataset(X_train)\n",
    "    dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "    \n",
    "    dsae = utils.Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "    model = utils.Model(dsae)\n",
    "    model.compile(lr, h_lambda, loss_fn, cuda_device_id=0)\n",
    "    _ = model.fit(dls, num_epochs, verbose=False)\n",
    "\n",
    "    exe_time = time.time()-start_time\n",
    "    \n",
    "    recon_X_test_norm, h_norm = model.net(X_test_norm)\n",
    "    recon_X_test_anomaly, h_anomaly = model.net(X_test_anomaly)\n",
    "\n",
    "    recon_X_test = torch.cat([recon_X_test_norm, recon_X_test_anomaly])\n",
    "    y_test = torch.cat([torch.zeros(len(recon_X_test_norm)), torch.ones(len(recon_X_test_anomaly))])\n",
    "    \n",
    "    re_test = nn.MSELoss(reduction=\"none\")(recon_X_test, X_test)\n",
    "\n",
    "    for re_row, label in zip(re_test, y_test):\n",
    "        results_df[\"outer_seed\"].append(i)\n",
    "        results_df[\"exe_time\"].append(exe_time)\n",
    "        results_df[\"re_mean\"].append(re_row.mean().item())\n",
    "\n",
    "        for feat, re_feat in zip(feats, re_row):\n",
    "            results_df[\"re_\"+feat].append(re_feat.item())\n",
    "\n",
    "        results_df[\"label\"].append(label.item())\n",
    "\n",
    "    _df = pd.DataFrame(results_df)\n",
    "    grp_mean_df = _df[_df.outer_seed==i].groupby(by=[\"label\"]).mean()\n",
    "\n",
    "    print(\"normal_mse=\",grp_mean_df.loc[0].re_mean, \"anomaly_mse=\", grp_mean_df.loc[1].re_mean, \"anomaly_mse>normal_mse=\", grp_mean_df.loc[1].re_mean>grp_mean_df.loc[0].re_mean)\n",
    "\n",
    "    grp_mean_df = grp_mean_df[[\"re_\"+feat for feat in feats]]\n",
    "    delta = grp_mean_df.loc[1] - grp_mean_df.loc[0]\n",
    "\n",
    "    rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "    rank_df = pd.DataFrame({\"feature\":feats, \"rank\":rank})\n",
    "    rank_df.to_csv(os.path.join(OUT_DIR, f\"rank_df{i}.csv\"), index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "results_df = pd.DataFrame(results_df) \n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"results_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcf544-f2db-4e84-a733-3e30488ceab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
