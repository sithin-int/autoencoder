{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c8d6ec-6037-4500-9bb5-1e518c6e1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils as utils\n",
    "import similarity_index as similarity_index\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd380604-c818-49b5-81ec-32e6cd9296a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"inputs/radiomicsFeatures.csv\"\n",
    "OUT_DIR = r\"outputs/ensembleDSAE\"\n",
    "MASK_FEATS = [\"id\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67d8e59-4d33-42ee-a6db-996b07b5dd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_wout_original_glcm_ClusterProminence</th>\n",
       "      <th>adc_original_firstorder_Minimum</th>\n",
       "      <th>sub_wout_original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>sub_wout_original_firstorder_Maximum</th>\n",
       "      <th>adc_original_glcm_ClusterShade</th>\n",
       "      <th>sub_wout_original_firstorder_Mean</th>\n",
       "      <th>sub_win_original_glcm_Autocorrelation</th>\n",
       "      <th>adc_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_win_original_glszm_ZoneEntropy</th>\n",
       "      <th>t2w_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>t2w_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glcm_MaximumProbability</th>\n",
       "      <th>sub_win_original_glcm_Imc1</th>\n",
       "      <th>sub_wout_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2535039</td>\n",
       "      <td>1</td>\n",
       "      <td>4.677862e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14835.837461</td>\n",
       "      <td>299.900214</td>\n",
       "      <td>3755.933491</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>...</td>\n",
       "      <td>6.339939</td>\n",
       "      <td>0.286470</td>\n",
       "      <td>10.166389</td>\n",
       "      <td>27423.571919</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>2946.837800</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.041978</td>\n",
       "      <td>10.452108</td>\n",
       "      <td>0.033786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2417361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.834267e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-17634.034850</td>\n",
       "      <td>299.918235</td>\n",
       "      <td>3941.494865</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.424770</td>\n",
       "      <td>0.350004</td>\n",
       "      <td>11.649157</td>\n",
       "      <td>21732.551407</td>\n",
       "      <td>0.604518</td>\n",
       "      <td>3322.225544</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.109242</td>\n",
       "      <td>11.891117</td>\n",
       "      <td>0.009861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2602563</td>\n",
       "      <td>1</td>\n",
       "      <td>5.159220e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-19736.430500</td>\n",
       "      <td>299.820687</td>\n",
       "      <td>2455.254084</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>...</td>\n",
       "      <td>7.239270</td>\n",
       "      <td>0.350692</td>\n",
       "      <td>10.919838</td>\n",
       "      <td>15567.069802</td>\n",
       "      <td>0.574356</td>\n",
       "      <td>3407.597573</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.194449</td>\n",
       "      <td>11.214368</td>\n",
       "      <td>0.018991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2902440</td>\n",
       "      <td>0</td>\n",
       "      <td>3.613791e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-12881.976888</td>\n",
       "      <td>299.240444</td>\n",
       "      <td>3954.079034</td>\n",
       "      <td>0.576021</td>\n",
       "      <td>...</td>\n",
       "      <td>7.454390</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>18389.243521</td>\n",
       "      <td>0.566131</td>\n",
       "      <td>3121.573712</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>11.669841</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2921898</td>\n",
       "      <td>0</td>\n",
       "      <td>5.773968e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2116.811733</td>\n",
       "      <td>299.983523</td>\n",
       "      <td>3793.819336</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.755170</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>9.504938</td>\n",
       "      <td>245786.779116</td>\n",
       "      <td>0.469149</td>\n",
       "      <td>3175.569089</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.058680</td>\n",
       "      <td>11.459667</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  sub_wout_original_glcm_ClusterProminence  \\\n",
       "0  2535039      1                              4.677862e+06   \n",
       "1  2417361      0                              4.834267e+06   \n",
       "2  2602563      1                              5.159220e+06   \n",
       "3  2902440      0                              3.613791e+06   \n",
       "4  2921898      0                              5.773968e+06   \n",
       "\n",
       "   adc_original_firstorder_Minimum  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              0.0   \n",
       "\n",
       "   sub_wout_original_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                          0.003103   \n",
       "1                                          0.001672   \n",
       "2                                          0.001600   \n",
       "3                                          0.002428   \n",
       "4                                          0.001720   \n",
       "\n",
       "   sub_wout_original_firstorder_Maximum  adc_original_glcm_ClusterShade  \\\n",
       "0                                 600.0                    14835.837461   \n",
       "1                                 600.0                   -17634.034850   \n",
       "2                                 600.0                   -19736.430500   \n",
       "3                                 600.0                   -12881.976888   \n",
       "4                                 600.0                     2116.811733   \n",
       "\n",
       "   sub_wout_original_firstorder_Mean  sub_win_original_glcm_Autocorrelation  \\\n",
       "0                         299.900214                            3755.933491   \n",
       "1                         299.918235                            3941.494865   \n",
       "2                         299.820687                            2455.254084   \n",
       "3                         299.240444                            3954.079034   \n",
       "4                         299.983523                            3793.819336   \n",
       "\n",
       "   adc_original_glszm_LargeAreaLowGrayLevelEmphasis  ...  \\\n",
       "0                                          0.010393  ...   \n",
       "1                                          0.058145  ...   \n",
       "2                                          0.019202  ...   \n",
       "3                                          0.576021  ...   \n",
       "4                                          0.011764  ...   \n",
       "\n",
       "   sub_win_original_glszm_ZoneEntropy  \\\n",
       "0                            6.339939   \n",
       "1                            7.424770   \n",
       "2                            7.239270   \n",
       "3                            7.454390   \n",
       "4                            6.755170   \n",
       "\n",
       "   t2w_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.286470    \n",
       "1                                           0.350004    \n",
       "2                                           0.350692    \n",
       "3                                           0.380537    \n",
       "4                                           0.265413    \n",
       "\n",
       "   t2w_original_glcm_JointEntropy  \\\n",
       "0                       10.166389   \n",
       "1                       11.649157   \n",
       "2                       10.919838   \n",
       "3                       11.530000   \n",
       "4                        9.504938   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                       27423.571919   \n",
       "1                                       21732.551407   \n",
       "2                                       15567.069802   \n",
       "3                                       18389.243521   \n",
       "4                                      245786.779116   \n",
       "\n",
       "   sub_win_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.461100        \n",
       "1                                           0.604518        \n",
       "2                                           0.574356        \n",
       "3                                           0.566131        \n",
       "4                                           0.469149        \n",
       "\n",
       "   sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                        2946.837800        \n",
       "1                                        3322.225544        \n",
       "2                                        3407.597573        \n",
       "3                                        3121.573712        \n",
       "4                                        3175.569089        \n",
       "\n",
       "   sub_win_original_glcm_MaximumProbability  sub_win_original_glcm_Imc1  \\\n",
       "0                                  0.034622                   -0.041978   \n",
       "1                                  0.002107                   -0.109242   \n",
       "2                                  0.004002                   -0.194449   \n",
       "3                                  0.004134                   -0.116415   \n",
       "4                                  0.027634                   -0.058680   \n",
       "\n",
       "   sub_wout_original_glcm_JointEntropy  \\\n",
       "0                            10.452108   \n",
       "1                            11.891117   \n",
       "2                            11.214368   \n",
       "3                            11.669841   \n",
       "4                            11.459667   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaLowGrayLevelEmphasis  \n",
       "0                                          0.033786  \n",
       "1                                          0.009861  \n",
       "2                                          0.018991  \n",
       "3                                          0.007846  \n",
       "4                                          0.024444  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6efc18-aa18-494c-9781-cde3d937cbe3",
   "metadata": {},
   "source": [
    "### Stratified CV Fold Generation (Consistent across FS algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd985de-47b7-40a1-83b3-14014e8efada",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = feats_df.id.to_numpy()\n",
    "labels = feats_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac94421f-8f10-460f-a89b-8877a4a32614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'train': array([2602563, 2921898, 3039346, 3110297, 3110706, 3137563, 3207798,\n",
       "         3213683, 3222346, 3226033, 3303911, 3325442, 3327697, 3329611,\n",
       "         3336537, 3405013, 3416781, 3419338, 3502691, 3504033, 3513664,\n",
       "         3519247, 3522629, 3534419, 3536230, 3607842, 3610014, 3613524,\n",
       "         3616819, 3618480, 3621681, 3621824, 3622974, 3631910, 3632788,\n",
       "         3701079, 3702147, 3707565, 3713983, 3714280, 3715560, 3716356,\n",
       "         3718385, 3720950, 3724846, 3725583, 3726460, 3727030, 3727850,\n",
       "         3729691, 3730269, 3800022, 3802504, 3808093, 3811134, 3811967,\n",
       "         3812057, 3815317, 3817381, 3819464, 3821188, 3821859, 3822353,\n",
       "         3823428, 3825318, 3827579, 3828403, 3901619, 3904119, 3904751,\n",
       "         3906071, 3906505, 3907211, 3907314, 3907344, 3908895, 3911843,\n",
       "         9534972, 9803775, 9816715]),\n",
       "  'val': array([2535039, 2417361, 2902440, 3310301, 3332798, 3534604, 3605303,\n",
       "         3621917, 3702859, 3703425, 3712766, 3728041, 3805884, 3811851,\n",
       "         3819781, 3823293, 3833691, 3833806, 3900009, 3902242])},\n",
       " 1: {'train': array([2535039, 2417361, 2602563, 2902440, 2921898, 3039346, 3110297,\n",
       "         3110706, 3137563, 3207798, 3213683, 3222346, 3226033, 3303911,\n",
       "         3310301, 3327697, 3329611, 3332798, 3416781, 3502691, 3504033,\n",
       "         3513664, 3519247, 3522629, 3534604, 3536230, 3605303, 3610014,\n",
       "         3613524, 3616819, 3618480, 3621681, 3621917, 3631910, 3632788,\n",
       "         3702859, 3703425, 3712766, 3713983, 3714280, 3715560, 3720950,\n",
       "         3724846, 3725583, 3726460, 3727030, 3727850, 3728041, 3800022,\n",
       "         3802504, 3805884, 3808093, 3811134, 3811851, 3811967, 3812057,\n",
       "         3819464, 3819781, 3821188, 3822353, 3823293, 3823428, 3825318,\n",
       "         3827579, 3828403, 3833691, 3833806, 3900009, 3902242, 3901619,\n",
       "         3904119, 3904751, 3906071, 3907211, 3907314, 3908895, 3911843,\n",
       "         9534972, 9803775, 9816715]),\n",
       "  'val': array([3325442, 3336537, 3405013, 3419338, 3534419, 3607842, 3621824,\n",
       "         3622974, 3701079, 3702147, 3707565, 3716356, 3718385, 3729691,\n",
       "         3730269, 3815317, 3817381, 3821859, 3906505, 3907344])},\n",
       " 2: {'train': array([2535039, 2417361, 2602563, 2902440, 2921898, 3110297, 3137563,\n",
       "         3213683, 3222346, 3226033, 3303911, 3310301, 3325442, 3329611,\n",
       "         3332798, 3336537, 3405013, 3416781, 3419338, 3502691, 3504033,\n",
       "         3513664, 3519247, 3522629, 3534419, 3534604, 3605303, 3607842,\n",
       "         3613524, 3616819, 3618480, 3621824, 3621917, 3622974, 3631910,\n",
       "         3632788, 3701079, 3702147, 3702859, 3703425, 3707565, 3712766,\n",
       "         3713983, 3714280, 3715560, 3716356, 3718385, 3720950, 3724846,\n",
       "         3725583, 3727030, 3727850, 3728041, 3729691, 3730269, 3805884,\n",
       "         3811134, 3811851, 3815317, 3817381, 3819464, 3819781, 3821859,\n",
       "         3822353, 3823293, 3825318, 3827579, 3828403, 3833691, 3833806,\n",
       "         3900009, 3902242, 3901619, 3906505, 3907314, 3907344, 3911843,\n",
       "         9534972, 9803775, 9816715]),\n",
       "  'val': array([3039346, 3110706, 3207798, 3327697, 3536230, 3610014, 3621681,\n",
       "         3726460, 3800022, 3802504, 3808093, 3811967, 3812057, 3821188,\n",
       "         3823428, 3904119, 3904751, 3906071, 3907211, 3908895])},\n",
       " 3: {'train': array([2535039, 2417361, 2902440, 3039346, 3110297, 3110706, 3207798,\n",
       "         3226033, 3310301, 3325442, 3327697, 3329611, 3332798, 3336537,\n",
       "         3405013, 3416781, 3419338, 3502691, 3504033, 3513664, 3519247,\n",
       "         3534419, 3534604, 3536230, 3605303, 3607842, 3610014, 3616819,\n",
       "         3621681, 3621824, 3621917, 3622974, 3632788, 3701079, 3702147,\n",
       "         3702859, 3703425, 3707565, 3712766, 3713983, 3716356, 3718385,\n",
       "         3726460, 3727030, 3727850, 3728041, 3729691, 3730269, 3800022,\n",
       "         3802504, 3805884, 3808093, 3811134, 3811851, 3811967, 3812057,\n",
       "         3815317, 3817381, 3819781, 3821188, 3821859, 3823293, 3823428,\n",
       "         3825318, 3827579, 3828403, 3833691, 3833806, 3900009, 3902242,\n",
       "         3904119, 3904751, 3906071, 3906505, 3907211, 3907314, 3907344,\n",
       "         3908895, 9534972, 9816715]),\n",
       "  'val': array([2602563, 2921898, 3137563, 3213683, 3222346, 3303911, 3522629,\n",
       "         3613524, 3618480, 3631910, 3714280, 3715560, 3720950, 3724846,\n",
       "         3725583, 3819464, 3822353, 3901619, 3911843, 9803775])},\n",
       " 4: {'train': array([2535039, 2417361, 2602563, 2902440, 2921898, 3039346, 3110706,\n",
       "         3137563, 3207798, 3213683, 3222346, 3303911, 3310301, 3325442,\n",
       "         3327697, 3332798, 3336537, 3405013, 3419338, 3522629, 3534419,\n",
       "         3534604, 3536230, 3605303, 3607842, 3610014, 3613524, 3618480,\n",
       "         3621681, 3621824, 3621917, 3622974, 3631910, 3701079, 3702147,\n",
       "         3702859, 3703425, 3707565, 3712766, 3714280, 3715560, 3716356,\n",
       "         3718385, 3720950, 3724846, 3725583, 3726460, 3728041, 3729691,\n",
       "         3730269, 3800022, 3802504, 3805884, 3808093, 3811851, 3811967,\n",
       "         3812057, 3815317, 3817381, 3819464, 3819781, 3821188, 3821859,\n",
       "         3822353, 3823293, 3823428, 3833691, 3833806, 3900009, 3902242,\n",
       "         3901619, 3904119, 3904751, 3906071, 3906505, 3907211, 3907344,\n",
       "         3908895, 3911843, 9803775]),\n",
       "  'val': array([3110297, 3226033, 3329611, 3416781, 3502691, 3504033, 3513664,\n",
       "         3519247, 3616819, 3632788, 3713983, 3727030, 3727850, 3811134,\n",
       "         3825318, 3827579, 3828403, 3907314, 9534972, 9816715])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_count = 5\n",
    "\n",
    "cv_dict = {}\n",
    "skf = StratifiedKFold(n_splits = cv_count, random_state=0, shuffle=True)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(skf.split(pids, labels)):\n",
    "    cv_dict[i] = {\"train\":pids[train_idx], \"val\":pids[val_idx]} \n",
    "\n",
    "cv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96a9d3-946f-4dc5-8051-6ba783ed4d20",
   "metadata": {},
   "source": [
    "### Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c0ae46-b2b1-4d80-862f-0b501950455f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for fold - 0\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 8s\n",
      "Best val Loss: 0.836318\n",
      "b= 0 normal_mse= 0.8677940964698792 anomaly_mse= 0.907132625579834 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.738372\n",
      "b= 1 normal_mse= 1.1694172620773315 anomaly_mse= 1.0855456590652466 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.750266\n",
      "b= 2 normal_mse= 0.7504907846450806 anomaly_mse= 0.8968709111213684 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.170860\n",
      "b= 3 normal_mse= 1.2321064472198486 anomaly_mse= 1.103742241859436 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044348\n",
      "b= 4 normal_mse= 0.8730214834213257 anomaly_mse= 0.9628665447235107 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.850474\n",
      "b= 5 normal_mse= 0.9370166659355164 anomaly_mse= 0.9616538882255554 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748114\n",
      "b= 6 normal_mse= 0.7587926387786865 anomaly_mse= 0.9035707712173462 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.162829\n",
      "b= 7 normal_mse= 1.2344099283218384 anomaly_mse= 1.0924092531204224 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.041360\n",
      "b= 8 normal_mse= 0.8730427622795105 anomaly_mse= 0.9577100276947021 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.851919\n",
      "b= 9 normal_mse= 0.9394505620002747 anomaly_mse= 0.9591653347015381 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748595\n",
      "b= 10 normal_mse= 0.75780189037323 anomaly_mse= 0.902052640914917 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.175464\n",
      "b= 11 normal_mse= 1.2224502563476562 anomaly_mse= 1.0992285013198853 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044527\n",
      "b= 12 normal_mse= 0.8723291158676147 anomaly_mse= 0.9586281776428223 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.844959\n",
      "b= 13 normal_mse= 0.9409392476081848 anomaly_mse= 0.96221923828125 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748224\n",
      "b= 14 normal_mse= 0.7533212900161743 anomaly_mse= 0.8999420404434204 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.173240\n",
      "b= 15 normal_mse= 1.2289623022079468 anomaly_mse= 1.0948997735977173 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.045399\n",
      "b= 16 normal_mse= 0.8750466108322144 anomaly_mse= 0.9660481810569763 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.845989\n",
      "b= 17 normal_mse= 0.936320960521698 anomaly_mse= 0.9683231115341187 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.749143\n",
      "b= 18 normal_mse= 0.7520874738693237 anomaly_mse= 0.8976802825927734 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.169979\n",
      "b= 19 normal_mse= 1.2336065769195557 anomaly_mse= 1.1005358695983887 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.041436\n",
      "b= 20 normal_mse= 0.8675193190574646 anomaly_mse= 0.9553560614585876 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.849410\n",
      "b= 21 normal_mse= 0.9381701946258545 anomaly_mse= 0.9616622924804688 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.740339\n",
      "b= 22 normal_mse= 0.7553534507751465 anomaly_mse= 0.9074587225914001 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.167452\n",
      "b= 23 normal_mse= 1.231047511100769 anomaly_mse= 1.0994446277618408 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.048472\n",
      "b= 24 normal_mse= 0.8695720434188843 anomaly_mse= 0.9494288563728333 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.849625\n",
      "b= 25 normal_mse= 0.9387285113334656 anomaly_mse= 0.9642161726951599 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.746448\n",
      "b= 26 normal_mse= 0.7545212507247925 anomaly_mse= 0.8998009562492371 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.174317\n",
      "b= 27 normal_mse= 1.2306609153747559 anomaly_mse= 1.0994203090667725 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044614\n",
      "b= 28 normal_mse= 0.8711336851119995 anomaly_mse= 0.9581956267356873 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.847017\n",
      "b= 29 normal_mse= 0.9361227750778198 anomaly_mse= 0.9629937410354614 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748705\n",
      "b= 30 normal_mse= 0.7517545223236084 anomaly_mse= 0.8961021304130554 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.173255\n",
      "b= 31 normal_mse= 1.22989022731781 anomaly_mse= 1.096954107284546 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.045259\n",
      "b= 32 normal_mse= 0.8708732724189758 anomaly_mse= 0.9583985209465027 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.844388\n",
      "b= 33 normal_mse= 0.9376705288887024 anomaly_mse= 0.9706302881240845 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748641\n",
      "b= 34 normal_mse= 0.7508570551872253 anomaly_mse= 0.89881432056427 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.170121\n",
      "b= 35 normal_mse= 1.230928659439087 anomaly_mse= 1.093765139579773 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.043068\n",
      "b= 36 normal_mse= 0.8720038533210754 anomaly_mse= 0.9578945636749268 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.843913\n",
      "b= 37 normal_mse= 0.9367184638977051 anomaly_mse= 0.9654300808906555 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.746114\n",
      "b= 38 normal_mse= 0.7537438273429871 anomaly_mse= 0.8968117237091064 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.170252\n",
      "b= 39 normal_mse= 1.2305973768234253 anomaly_mse= 1.097620964050293 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.045746\n",
      "b= 40 normal_mse= 0.8714298605918884 anomaly_mse= 0.9569817185401917 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.850037\n",
      "b= 41 normal_mse= 0.9375008344650269 anomaly_mse= 0.9575827717781067 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.745938\n",
      "b= 42 normal_mse= 0.7535531520843506 anomaly_mse= 0.8983399271965027 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.167330\n",
      "b= 43 normal_mse= 1.2219042778015137 anomaly_mse= 1.1029596328735352 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044800\n",
      "b= 44 normal_mse= 0.8733559846878052 anomaly_mse= 0.9513654112815857 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.851407\n",
      "b= 45 normal_mse= 0.9437885880470276 anomaly_mse= 0.9706256985664368 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748939\n",
      "b= 46 normal_mse= 0.752893328666687 anomaly_mse= 0.8945073485374451 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.168078\n",
      "b= 47 normal_mse= 1.2277088165283203 anomaly_mse= 1.0926393270492554 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.042914\n",
      "b= 48 normal_mse= 0.8755982518196106 anomaly_mse= 0.9588879942893982 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.848723\n",
      "b= 49 normal_mse= 0.9386641979217529 anomaly_mse= 0.9629690647125244 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.749289\n",
      "b= 50 normal_mse= 0.7556021809577942 anomaly_mse= 0.8995800018310547 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.175240\n",
      "b= 51 normal_mse= 1.2248047590255737 anomaly_mse= 1.0940654277801514 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044987\n",
      "b= 52 normal_mse= 0.873044490814209 anomaly_mse= 0.9571008682250977 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.848274\n",
      "b= 53 normal_mse= 0.9381929636001587 anomaly_mse= 0.962174654006958 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.745170\n",
      "b= 54 normal_mse= 0.7521583437919617 anomaly_mse= 0.8988774418830872 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.176352\n",
      "b= 55 normal_mse= 1.233954668045044 anomaly_mse= 1.0890693664550781 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044947\n",
      "b= 56 normal_mse= 0.8683168292045593 anomaly_mse= 0.9565048217773438 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.848315\n",
      "b= 57 normal_mse= 0.9376915693283081 anomaly_mse= 0.9611045122146606 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.745986\n",
      "b= 58 normal_mse= 0.7552632689476013 anomaly_mse= 0.8976434469223022 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.173498\n",
      "b= 59 normal_mse= 1.2247308492660522 anomaly_mse= 1.0961973667144775 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.043778\n",
      "b= 60 normal_mse= 0.8732607364654541 anomaly_mse= 0.9646190404891968 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.848171\n",
      "b= 61 normal_mse= 0.9372599720954895 anomaly_mse= 0.9628511667251587 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.747616\n",
      "b= 62 normal_mse= 0.7534117698669434 anomaly_mse= 0.8994725942611694 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.173791\n",
      "b= 63 normal_mse= 1.2297585010528564 anomaly_mse= 1.1020448207855225 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.045923\n",
      "b= 64 normal_mse= 0.8739508986473083 anomaly_mse= 0.9571765661239624 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.846584\n",
      "b= 65 normal_mse= 0.9380532503128052 anomaly_mse= 0.9656201601028442 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748368\n",
      "b= 66 normal_mse= 0.755218505859375 anomaly_mse= 0.8955203890800476 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.173052\n",
      "b= 67 normal_mse= 1.2356784343719482 anomaly_mse= 1.0949863195419312 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.049047\n",
      "b= 68 normal_mse= 0.8721258044242859 anomaly_mse= 0.9643787145614624 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.851263\n",
      "b= 69 normal_mse= 0.940557062625885 anomaly_mse= 0.9636952877044678 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748336\n",
      "b= 70 normal_mse= 0.7517886161804199 anomaly_mse= 0.8970751166343689 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.165050\n",
      "b= 71 normal_mse= 1.2356163263320923 anomaly_mse= 1.1008591651916504 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044508\n",
      "b= 72 normal_mse= 0.8679543137550354 anomaly_mse= 0.951524555683136 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.841217\n",
      "b= 73 normal_mse= 0.9371212124824524 anomaly_mse= 0.967582643032074 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.747435\n",
      "b= 74 normal_mse= 0.7515978813171387 anomaly_mse= 0.8974869847297668 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.170840\n",
      "b= 75 normal_mse= 1.2318886518478394 anomaly_mse= 1.0995707511901855 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.050206\n",
      "b= 76 normal_mse= 0.8764333128929138 anomaly_mse= 0.9588029980659485 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.847585\n",
      "b= 77 normal_mse= 0.9409350156784058 anomaly_mse= 0.9700925946235657 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.747123\n",
      "b= 78 normal_mse= 0.7534105777740479 anomaly_mse= 0.8977536559104919 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.171485\n",
      "b= 79 normal_mse= 1.2314740419387817 anomaly_mse= 1.1055124998092651 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044014\n",
      "b= 80 normal_mse= 0.8733881115913391 anomaly_mse= 0.9571977257728577 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.846942\n",
      "b= 81 normal_mse= 0.9375506043434143 anomaly_mse= 0.9652916789054871 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.746226\n",
      "b= 82 normal_mse= 0.7531719207763672 anomaly_mse= 0.8999602794647217 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.169984\n",
      "b= 83 normal_mse= 1.23312509059906 anomaly_mse= 1.103757381439209 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.046181\n",
      "b= 84 normal_mse= 0.873587429523468 anomaly_mse= 0.9648916125297546 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.845314\n",
      "b= 85 normal_mse= 0.9395264983177185 anomaly_mse= 0.9620810747146606 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.746787\n",
      "b= 86 normal_mse= 0.7541988492012024 anomaly_mse= 0.8985459208488464 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.172621\n",
      "b= 87 normal_mse= 1.2320247888565063 anomaly_mse= 1.0942972898483276 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.046373\n",
      "b= 88 normal_mse= 0.8701996803283691 anomaly_mse= 0.9573653340339661 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.846015\n",
      "b= 89 normal_mse= 0.9404581189155579 anomaly_mse= 0.9602625370025635 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.747140\n",
      "b= 90 normal_mse= 0.7530613541603088 anomaly_mse= 0.8948156833648682 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.167380\n",
      "b= 91 normal_mse= 1.2280399799346924 anomaly_mse= 1.1004741191864014 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.041385\n",
      "b= 92 normal_mse= 0.8666256070137024 anomaly_mse= 0.9546037316322327 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.847716\n",
      "b= 93 normal_mse= 0.9396088719367981 anomaly_mse= 0.9600474238395691 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.745783\n",
      "b= 94 normal_mse= 0.757625937461853 anomaly_mse= 0.8994114995002747 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.169757\n",
      "b= 95 normal_mse= 1.228736162185669 anomaly_mse= 1.100361943244934 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.046551\n",
      "b= 96 normal_mse= 0.8698245882987976 anomaly_mse= 0.9590888023376465 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.849248\n",
      "b= 97 normal_mse= 0.9359087944030762 anomaly_mse= 0.9642581939697266 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.747155\n",
      "b= 98 normal_mse= 0.7530147433280945 anomaly_mse= 0.8982986211776733 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.166896\n",
      "b= 99 normal_mse= 1.2297354936599731 anomaly_mse= 1.0953716039657593 anomaly_mse>normal_mse= False\n",
      "Running for fold - 1\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.894743\n",
      "b= 0 normal_mse= 1.2196104526519775 anomaly_mse= 1.1585612297058105 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.605658\n",
      "b= 1 normal_mse= 0.7396194934844971 anomaly_mse= 0.936753511428833 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.078459\n",
      "b= 2 normal_mse= 0.9336392879486084 anomaly_mse= 1.002163290977478 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.793226\n",
      "b= 3 normal_mse= 0.95496666431427 anomaly_mse= 0.988789439201355 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.891119\n",
      "b= 4 normal_mse= 1.2220951318740845 anomaly_mse= 1.162706732749939 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.601087\n",
      "b= 5 normal_mse= 0.7410550713539124 anomaly_mse= 0.9440442323684692 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.078520\n",
      "b= 6 normal_mse= 0.9391510486602783 anomaly_mse= 1.0028287172317505 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.793046\n",
      "b= 7 normal_mse= 0.9532128572463989 anomaly_mse= 0.9940084218978882 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.893865\n",
      "b= 8 normal_mse= 1.2259937524795532 anomaly_mse= 1.1647822856903076 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.599600\n",
      "b= 9 normal_mse= 0.7469136118888855 anomaly_mse= 0.948694109916687 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.078356\n",
      "b= 10 normal_mse= 0.9262655973434448 anomaly_mse= 1.0069694519042969 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.789053\n",
      "b= 11 normal_mse= 0.9583109021186829 anomaly_mse= 1.0019750595092773 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.890991\n",
      "b= 12 normal_mse= 1.2258049249649048 anomaly_mse= 1.1701371669769287 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.599391\n",
      "b= 13 normal_mse= 0.7423306703567505 anomaly_mse= 0.9391728043556213 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.072144\n",
      "b= 14 normal_mse= 0.9214595556259155 anomaly_mse= 1.0161906480789185 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791645\n",
      "b= 15 normal_mse= 0.9521944522857666 anomaly_mse= 1.0010496377944946 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.893574\n",
      "b= 16 normal_mse= 1.2189326286315918 anomaly_mse= 1.1568635702133179 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.604372\n",
      "b= 17 normal_mse= 0.7400076985359192 anomaly_mse= 0.9375802278518677 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.076475\n",
      "b= 18 normal_mse= 0.9327060580253601 anomaly_mse= 1.0030853748321533 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791422\n",
      "b= 19 normal_mse= 0.9531631469726562 anomaly_mse= 0.9949948787689209 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892893\n",
      "b= 20 normal_mse= 1.222679853439331 anomaly_mse= 1.1652430295944214 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.605620\n",
      "b= 21 normal_mse= 0.7410796880722046 anomaly_mse= 0.9336789846420288 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.075061\n",
      "b= 22 normal_mse= 0.9367626905441284 anomaly_mse= 1.0007935762405396 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.793592\n",
      "b= 23 normal_mse= 0.9553500413894653 anomaly_mse= 0.9934775829315186 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.888584\n",
      "b= 24 normal_mse= 1.2200199365615845 anomaly_mse= 1.1540520191192627 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.601973\n",
      "b= 25 normal_mse= 0.7411068081855774 anomaly_mse= 0.9440618753433228 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.077817\n",
      "b= 26 normal_mse= 0.9334567785263062 anomaly_mse= 1.0042656660079956 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.792976\n",
      "b= 27 normal_mse= 0.9537189602851868 anomaly_mse= 0.9943487644195557 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.896056\n",
      "b= 28 normal_mse= 1.2207982540130615 anomaly_mse= 1.1546459197998047 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.602869\n",
      "b= 29 normal_mse= 0.7406153082847595 anomaly_mse= 0.9404217004776001 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.078134\n",
      "b= 30 normal_mse= 0.9330986738204956 anomaly_mse= 1.001089096069336 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791996\n",
      "b= 31 normal_mse= 0.9524480700492859 anomaly_mse= 0.9957886338233948 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892234\n",
      "b= 32 normal_mse= 1.2244117259979248 anomaly_mse= 1.1626496315002441 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.603589\n",
      "b= 33 normal_mse= 0.7394986152648926 anomaly_mse= 0.9370244741439819 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.073046\n",
      "b= 34 normal_mse= 0.9360441565513611 anomaly_mse= 1.0018411874771118 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.793808\n",
      "b= 35 normal_mse= 0.9541096091270447 anomaly_mse= 0.9922244548797607 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.893517\n",
      "b= 36 normal_mse= 1.2189322710037231 anomaly_mse= 1.1586209535598755 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.605118\n",
      "b= 37 normal_mse= 0.7404584288597107 anomaly_mse= 0.9357704520225525 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.076918\n",
      "b= 38 normal_mse= 0.9339261054992676 anomaly_mse= 0.9991718530654907 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.792876\n",
      "b= 39 normal_mse= 0.9526439905166626 anomaly_mse= 0.9949796199798584 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.889098\n",
      "b= 40 normal_mse= 1.2215864658355713 anomaly_mse= 1.1534981727600098 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.604356\n",
      "b= 41 normal_mse= 0.7383117079734802 anomaly_mse= 0.9328161478042603 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.078752\n",
      "b= 42 normal_mse= 0.934778094291687 anomaly_mse= 1.0070399045944214 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.793571\n",
      "b= 43 normal_mse= 0.9506255388259888 anomaly_mse= 0.9914976954460144 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892226\n",
      "b= 44 normal_mse= 1.2247225046157837 anomaly_mse= 1.1594111919403076 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.602125\n",
      "b= 45 normal_mse= 0.7390279769897461 anomaly_mse= 0.9435555934906006 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.078912\n",
      "b= 46 normal_mse= 0.9330990314483643 anomaly_mse= 1.0002045631408691 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791253\n",
      "b= 47 normal_mse= 0.9595456123352051 anomaly_mse= 0.9987790584564209 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.891212\n",
      "b= 48 normal_mse= 1.2205376625061035 anomaly_mse= 1.154930591583252 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.603903\n",
      "b= 49 normal_mse= 0.7380860447883606 anomaly_mse= 0.9421302080154419 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.079300\n",
      "b= 50 normal_mse= 0.9295452833175659 anomaly_mse= 1.0009465217590332 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791943\n",
      "b= 51 normal_mse= 0.952045738697052 anomaly_mse= 0.993802547454834 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.890180\n",
      "b= 52 normal_mse= 1.2234644889831543 anomaly_mse= 1.1661759614944458 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.602966\n",
      "b= 53 normal_mse= 0.7415685653686523 anomaly_mse= 0.9393643736839294 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.075204\n",
      "b= 54 normal_mse= 0.9344189167022705 anomaly_mse= 1.0009608268737793 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791145\n",
      "b= 55 normal_mse= 0.9586471319198608 anomaly_mse= 0.9937035441398621 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892579\n",
      "b= 56 normal_mse= 1.2229969501495361 anomaly_mse= 1.1587131023406982 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.602016\n",
      "b= 57 normal_mse= 0.7404997944831848 anomaly_mse= 0.940590500831604 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.076084\n",
      "b= 58 normal_mse= 0.9303993582725525 anomaly_mse= 1.0057647228240967 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.794058\n",
      "b= 59 normal_mse= 0.9522861242294312 anomaly_mse= 0.9914848804473877 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.890920\n",
      "b= 60 normal_mse= 1.2256004810333252 anomaly_mse= 1.1672102212905884 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.602695\n",
      "b= 61 normal_mse= 0.7386122345924377 anomaly_mse= 0.9381289482116699 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.077613\n",
      "b= 62 normal_mse= 0.9307281970977783 anomaly_mse= 1.0039492845535278 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791352\n",
      "b= 63 normal_mse= 0.9526997208595276 anomaly_mse= 0.9993056654930115 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892547\n",
      "b= 64 normal_mse= 1.2225029468536377 anomaly_mse= 1.1645264625549316 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.601815\n",
      "b= 65 normal_mse= 0.739795982837677 anomaly_mse= 0.9388302564620972 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.067941\n",
      "b= 66 normal_mse= 0.9422884583473206 anomaly_mse= 1.0025087594985962 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.793343\n",
      "b= 67 normal_mse= 0.9515471458435059 anomaly_mse= 0.9904547929763794 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892800\n",
      "b= 68 normal_mse= 1.2234654426574707 anomaly_mse= 1.161433219909668 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.604333\n",
      "b= 69 normal_mse= 0.739987313747406 anomaly_mse= 0.9389379024505615 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.081128\n",
      "b= 70 normal_mse= 0.9421777725219727 anomaly_mse= 0.9994725584983826 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.792905\n",
      "b= 71 normal_mse= 0.9517380595207214 anomaly_mse= 0.996204137802124 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892933\n",
      "b= 72 normal_mse= 1.2251601219177246 anomaly_mse= 1.1611590385437012 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.602370\n",
      "b= 73 normal_mse= 0.7466937899589539 anomaly_mse= 0.9460265636444092 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.081091\n",
      "b= 74 normal_mse= 0.9331567287445068 anomaly_mse= 1.0024269819259644 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791120\n",
      "b= 75 normal_mse= 0.9523012042045593 anomaly_mse= 0.9944219589233398 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.886436\n",
      "b= 76 normal_mse= 1.221023678779602 anomaly_mse= 1.1474725008010864 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.600446\n",
      "b= 77 normal_mse= 0.7429178357124329 anomaly_mse= 0.941764771938324 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.075466\n",
      "b= 78 normal_mse= 0.932664692401886 anomaly_mse= 1.0016998052597046 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.792074\n",
      "b= 79 normal_mse= 0.9540634751319885 anomaly_mse= 0.9952371716499329 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.887124\n",
      "b= 80 normal_mse= 1.2224998474121094 anomaly_mse= 1.1479130983352661 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.603284\n",
      "b= 81 normal_mse= 0.7422271966934204 anomaly_mse= 0.9395032525062561 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.076099\n",
      "b= 82 normal_mse= 0.9292866587638855 anomaly_mse= 1.0052845478057861 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.790294\n",
      "b= 83 normal_mse= 0.9543077945709229 anomaly_mse= 0.9881828427314758 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.892709\n",
      "b= 84 normal_mse= 1.2237669229507446 anomaly_mse= 1.1649290323257446 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.602848\n",
      "b= 85 normal_mse= 0.7386102676391602 anomaly_mse= 0.933660626411438 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.074644\n",
      "b= 86 normal_mse= 0.9312542676925659 anomaly_mse= 1.0049552917480469 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791072\n",
      "b= 87 normal_mse= 0.9515978097915649 anomaly_mse= 0.9930927157402039 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.891222\n",
      "b= 88 normal_mse= 1.225156545639038 anomaly_mse= 1.165448784828186 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.601774\n",
      "b= 89 normal_mse= 0.7400328516960144 anomaly_mse= 0.9369608759880066 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.074927\n",
      "b= 90 normal_mse= 0.9336782097816467 anomaly_mse= 1.0039312839508057 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.792268\n",
      "b= 91 normal_mse= 0.9497342705726624 anomaly_mse= 0.991618275642395 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.893354\n",
      "b= 92 normal_mse= 1.2280672788619995 anomaly_mse= 1.1645616292953491 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.601694\n",
      "b= 93 normal_mse= 0.7411459684371948 anomaly_mse= 0.9375156760215759 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.079398\n",
      "b= 94 normal_mse= 0.9401370286941528 anomaly_mse= 1.000016212463379 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.790814\n",
      "b= 95 normal_mse= 0.9533098340034485 anomaly_mse= 0.993122935295105 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.893287\n",
      "b= 96 normal_mse= 1.2195101976394653 anomaly_mse= 1.1552528142929077 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.604164\n",
      "b= 97 normal_mse= 0.7380515336990356 anomaly_mse= 0.9331111311912537 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.077946\n",
      "b= 98 normal_mse= 0.9311982989311218 anomaly_mse= 1.00534987449646 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.791854\n",
      "b= 99 normal_mse= 0.953139066696167 anomaly_mse= 0.9883241057395935 anomaly_mse>normal_mse= True\n",
      "Running for fold - 2\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.807402\n",
      "b= 0 normal_mse= 0.810153067111969 anomaly_mse= 0.7487038373947144 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.998044\n",
      "b= 1 normal_mse= 1.2188911437988281 anomaly_mse= 0.8806426525115967 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.099814\n",
      "b= 2 normal_mse= 0.6465412974357605 anomaly_mse= 0.7060474157333374 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.861798\n",
      "b= 3 normal_mse= 1.3038066625595093 anomaly_mse= 0.9506902694702148 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.809545\n",
      "b= 4 normal_mse= 0.8144228458404541 anomaly_mse= 0.7573666572570801 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.998337\n",
      "b= 5 normal_mse= 1.2125746011734009 anomaly_mse= 0.8864988684654236 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.104050\n",
      "b= 6 normal_mse= 0.6466203927993774 anomaly_mse= 0.7066887021064758 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.864605\n",
      "b= 7 normal_mse= 1.29923415184021 anomaly_mse= 0.9453256726264954 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.805719\n",
      "b= 8 normal_mse= 0.8092755079269409 anomaly_mse= 0.7471076250076294 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.003223\n",
      "b= 9 normal_mse= 1.2123744487762451 anomaly_mse= 0.878703773021698 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.109536\n",
      "b= 10 normal_mse= 0.6502763628959656 anomaly_mse= 0.7019467949867249 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.861910\n",
      "b= 11 normal_mse= 1.300014615058899 anomaly_mse= 0.9460291266441345 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.806901\n",
      "b= 12 normal_mse= 0.8126872777938843 anomaly_mse= 0.7553489208221436 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.003223\n",
      "b= 13 normal_mse= 1.2205618619918823 anomaly_mse= 0.8876820206642151 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.111328\n",
      "b= 14 normal_mse= 0.642516016960144 anomaly_mse= 0.7015184760093689 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.866926\n",
      "b= 15 normal_mse= 1.2981339693069458 anomaly_mse= 0.949180006980896 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.810107\n",
      "b= 16 normal_mse= 0.8140075206756592 anomaly_mse= 0.7524045705795288 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.999386\n",
      "b= 17 normal_mse= 1.2134983539581299 anomaly_mse= 0.8845609426498413 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.103031\n",
      "b= 18 normal_mse= 0.6459361910820007 anomaly_mse= 0.7065035700798035 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.866729\n",
      "b= 19 normal_mse= 1.3046625852584839 anomaly_mse= 0.9356730580329895 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.807909\n",
      "b= 20 normal_mse= 0.8106567859649658 anomaly_mse= 0.7431795597076416 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.005530\n",
      "b= 21 normal_mse= 1.2102105617523193 anomaly_mse= 0.8810375332832336 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.110360\n",
      "b= 22 normal_mse= 0.6478723287582397 anomaly_mse= 0.7014168500900269 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.857869\n",
      "b= 23 normal_mse= 1.3080261945724487 anomaly_mse= 0.9496209621429443 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.807591\n",
      "b= 24 normal_mse= 0.8118812441825867 anomaly_mse= 0.7452958226203918 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.003248\n",
      "b= 25 normal_mse= 1.21567702293396 anomaly_mse= 0.8810209035873413 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.109246\n",
      "b= 26 normal_mse= 0.6432801485061646 anomaly_mse= 0.7080758213996887 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.862342\n",
      "b= 27 normal_mse= 1.3034594058990479 anomaly_mse= 0.9472112655639648 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.808467\n",
      "b= 28 normal_mse= 0.8146132826805115 anomaly_mse= 0.7448557019233704 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.994832\n",
      "b= 29 normal_mse= 1.2219496965408325 anomaly_mse= 0.8778651356697083 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.109659\n",
      "b= 30 normal_mse= 0.6397095322608948 anomaly_mse= 0.7002301216125488 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.869746\n",
      "b= 31 normal_mse= 1.3028440475463867 anomaly_mse= 0.9492713809013367 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.810121\n",
      "b= 32 normal_mse= 0.8126384615898132 anomaly_mse= 0.7490304708480835 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.999496\n",
      "b= 33 normal_mse= 1.2172865867614746 anomaly_mse= 0.880107045173645 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.106172\n",
      "b= 34 normal_mse= 0.6395205855369568 anomaly_mse= 0.7011414170265198 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.862875\n",
      "b= 35 normal_mse= 1.3000972270965576 anomaly_mse= 0.9528215527534485 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.804919\n",
      "b= 36 normal_mse= 0.8170420527458191 anomaly_mse= 0.7518244385719299 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.002323\n",
      "b= 37 normal_mse= 1.2101836204528809 anomaly_mse= 0.8847786784172058 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.100353\n",
      "b= 38 normal_mse= 0.6531824469566345 anomaly_mse= 0.7075375914573669 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.867441\n",
      "b= 39 normal_mse= 1.3043419122695923 anomaly_mse= 0.9457984566688538 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.805915\n",
      "b= 40 normal_mse= 0.8107978701591492 anomaly_mse= 0.7465267181396484 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.999509\n",
      "b= 41 normal_mse= 1.219239354133606 anomaly_mse= 0.8794212937355042 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.104342\n",
      "b= 42 normal_mse= 0.6479607224464417 anomaly_mse= 0.7052220702171326 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.863846\n",
      "b= 43 normal_mse= 1.3046473264694214 anomaly_mse= 0.9508874416351318 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.809380\n",
      "b= 44 normal_mse= 0.8114907741546631 anomaly_mse= 0.7522357702255249 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.000967\n",
      "b= 45 normal_mse= 1.216335654258728 anomaly_mse= 0.8815320730209351 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.116314\n",
      "b= 46 normal_mse= 0.6405484676361084 anomaly_mse= 0.7001495361328125 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.862017\n",
      "b= 47 normal_mse= 1.3000788688659668 anomaly_mse= 0.9495605230331421 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.807077\n",
      "b= 48 normal_mse= 0.8121163249015808 anomaly_mse= 0.7526047825813293 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.003063\n",
      "b= 49 normal_mse= 1.209682583808899 anomaly_mse= 0.8833832740783691 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.102024\n",
      "b= 50 normal_mse= 0.6511979699134827 anomaly_mse= 0.706299364566803 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.866765\n",
      "b= 51 normal_mse= 1.2996952533721924 anomaly_mse= 0.9496923685073853 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.810480\n",
      "b= 52 normal_mse= 0.8138687610626221 anomaly_mse= 0.7528707385063171 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.003635\n",
      "b= 53 normal_mse= 1.2179805040359497 anomaly_mse= 0.8808848261833191 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.108071\n",
      "b= 54 normal_mse= 0.6458658576011658 anomaly_mse= 0.7028687000274658 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.860925\n",
      "b= 55 normal_mse= 1.3013046979904175 anomaly_mse= 0.9491868019104004 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.807531\n",
      "b= 56 normal_mse= 0.8095799088478088 anomaly_mse= 0.7496885061264038 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.004042\n",
      "b= 57 normal_mse= 1.2175525426864624 anomaly_mse= 0.8773733377456665 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.104308\n",
      "b= 58 normal_mse= 0.6436091661453247 anomaly_mse= 0.7040079236030579 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.867622\n",
      "b= 59 normal_mse= 1.2990825176239014 anomaly_mse= 0.9460607171058655 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.805829\n",
      "b= 60 normal_mse= 0.8098248243331909 anomaly_mse= 0.7455379962921143 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.998427\n",
      "b= 61 normal_mse= 1.2197965383529663 anomaly_mse= 0.8766352534294128 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.100551\n",
      "b= 62 normal_mse= 0.6456882357597351 anomaly_mse= 0.7067171931266785 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.859902\n",
      "b= 63 normal_mse= 1.3050858974456787 anomaly_mse= 0.9540343284606934 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.807544\n",
      "b= 64 normal_mse= 0.8114293813705444 anomaly_mse= 0.7511330842971802 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.001159\n",
      "b= 65 normal_mse= 1.220252275466919 anomaly_mse= 0.8838186264038086 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.104611\n",
      "b= 66 normal_mse= 0.6432427763938904 anomaly_mse= 0.705852210521698 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.862149\n",
      "b= 67 normal_mse= 1.3041589260101318 anomaly_mse= 0.9424904584884644 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.807732\n",
      "b= 68 normal_mse= 0.809505820274353 anomaly_mse= 0.7515401840209961 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.004292\n",
      "b= 69 normal_mse= 1.2123045921325684 anomaly_mse= 0.8821121454238892 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.102255\n",
      "b= 70 normal_mse= 0.6496873497962952 anomaly_mse= 0.707136869430542 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.862712\n",
      "b= 71 normal_mse= 1.3021647930145264 anomaly_mse= 0.943855881690979 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.810402\n",
      "b= 72 normal_mse= 0.814872682094574 anomaly_mse= 0.7510086894035339 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.002791\n",
      "b= 73 normal_mse= 1.2134453058242798 anomaly_mse= 0.8801931142807007 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.108876\n",
      "b= 74 normal_mse= 0.6423745155334473 anomaly_mse= 0.6998108625411987 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.870158\n",
      "b= 75 normal_mse= 1.3026819229125977 anomaly_mse= 0.9436443448066711 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.809406\n",
      "b= 76 normal_mse= 0.8117014765739441 anomaly_mse= 0.7509804964065552 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.998949\n",
      "b= 77 normal_mse= 1.2163865566253662 anomaly_mse= 0.8827481865882874 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.112643\n",
      "b= 78 normal_mse= 0.6421566009521484 anomaly_mse= 0.7035035490989685 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.865127\n",
      "b= 79 normal_mse= 1.303337574005127 anomaly_mse= 0.9446154832839966 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.806834\n",
      "b= 80 normal_mse= 0.8110150098800659 anomaly_mse= 0.7482981085777283 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.000285\n",
      "b= 81 normal_mse= 1.218043565750122 anomaly_mse= 0.8824102282524109 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.102238\n",
      "b= 82 normal_mse= 0.6497268080711365 anomaly_mse= 0.7052997350692749 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.867840\n",
      "b= 83 normal_mse= 1.3032835721969604 anomaly_mse= 0.950070858001709 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.810309\n",
      "b= 84 normal_mse= 0.8121584057807922 anomaly_mse= 0.7559067606925964 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.000760\n",
      "b= 85 normal_mse= 1.2167726755142212 anomaly_mse= 0.8807294368743896 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.104907\n",
      "b= 86 normal_mse= 0.6422139406204224 anomaly_mse= 0.7075607776641846 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.864519\n",
      "b= 87 normal_mse= 1.3030250072479248 anomaly_mse= 0.9485984444618225 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.806703\n",
      "b= 88 normal_mse= 0.8114679455757141 anomaly_mse= 0.7512466907501221 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.000316\n",
      "b= 89 normal_mse= 1.2189687490463257 anomaly_mse= 0.8763933777809143 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.101082\n",
      "b= 90 normal_mse= 0.6463721990585327 anomaly_mse= 0.7042487859725952 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.865111\n",
      "b= 91 normal_mse= 1.3059138059616089 anomaly_mse= 0.949954628944397 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.809906\n",
      "b= 92 normal_mse= 0.8107849359512329 anomaly_mse= 0.7464621663093567 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.001619\n",
      "b= 93 normal_mse= 1.221092700958252 anomaly_mse= 0.8792378306388855 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.113899\n",
      "b= 94 normal_mse= 0.6476176977157593 anomaly_mse= 0.7059404253959656 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.865360\n",
      "b= 95 normal_mse= 1.3039312362670898 anomaly_mse= 0.9438745975494385 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.811199\n",
      "b= 96 normal_mse= 0.8125157952308655 anomaly_mse= 0.7503188848495483 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.003697\n",
      "b= 97 normal_mse= 1.2119417190551758 anomaly_mse= 0.8835486769676208 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.105866\n",
      "b= 98 normal_mse= 0.6384064555168152 anomaly_mse= 0.7046091556549072 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.865740\n",
      "b= 99 normal_mse= 1.3058302402496338 anomaly_mse= 0.9472519755363464 anomaly_mse>normal_mse= False\n",
      "Running for fold - 3\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.713055\n",
      "b= 0 normal_mse= 1.3282443284988403 anomaly_mse= 1.1991883516311646 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.684204\n",
      "b= 1 normal_mse= 0.8070440292358398 anomaly_mse= 0.9169145226478577 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.649359\n",
      "b= 2 normal_mse= 0.8741987347602844 anomaly_mse= 0.9476194977760315 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.319253\n",
      "b= 3 normal_mse= 0.7771932482719421 anomaly_mse= 0.9210976362228394 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.716973\n",
      "b= 4 normal_mse= 1.3237262964248657 anomaly_mse= 1.198783040046692 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.687889\n",
      "b= 5 normal_mse= 0.8098534345626831 anomaly_mse= 0.9171769022941589 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.646970\n",
      "b= 6 normal_mse= 0.8731910586357117 anomaly_mse= 0.9436677098274231 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.317708\n",
      "b= 7 normal_mse= 0.7771324515342712 anomaly_mse= 0.9223229289054871 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.720857\n",
      "b= 8 normal_mse= 1.3179872035980225 anomaly_mse= 1.1985836029052734 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.680382\n",
      "b= 9 normal_mse= 0.8091432452201843 anomaly_mse= 0.9112895131111145 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.649241\n",
      "b= 10 normal_mse= 0.8748706579208374 anomaly_mse= 0.9451688528060913 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.310380\n",
      "b= 11 normal_mse= 0.7767261862754822 anomaly_mse= 0.9225654006004333 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.717916\n",
      "b= 12 normal_mse= 1.325678825378418 anomaly_mse= 1.1950018405914307 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.682420\n",
      "b= 13 normal_mse= 0.8098969459533691 anomaly_mse= 0.9181141257286072 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.649442\n",
      "b= 14 normal_mse= 0.8739714622497559 anomaly_mse= 0.9396067261695862 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.318335\n",
      "b= 15 normal_mse= 0.7747206687927246 anomaly_mse= 0.9222207069396973 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.720674\n",
      "b= 16 normal_mse= 1.319521188735962 anomaly_mse= 1.197661280632019 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.684516\n",
      "b= 17 normal_mse= 0.8075783252716064 anomaly_mse= 0.9087262153625488 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.648814\n",
      "b= 18 normal_mse= 0.8757914900779724 anomaly_mse= 0.944214403629303 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.324085\n",
      "b= 19 normal_mse= 0.7761619091033936 anomaly_mse= 0.9150792956352234 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.718438\n",
      "b= 20 normal_mse= 1.3231632709503174 anomaly_mse= 1.19948148727417 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.685179\n",
      "b= 21 normal_mse= 0.8137779831886292 anomaly_mse= 0.9072589874267578 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.649417\n",
      "b= 22 normal_mse= 0.8743855953216553 anomaly_mse= 0.9478263258934021 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.326210\n",
      "b= 23 normal_mse= 0.7783185243606567 anomaly_mse= 0.9242154955863953 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.714376\n",
      "b= 24 normal_mse= 1.3226639032363892 anomaly_mse= 1.1898192167282104 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.688676\n",
      "b= 25 normal_mse= 0.8098580241203308 anomaly_mse= 0.9122723937034607 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.646615\n",
      "b= 26 normal_mse= 0.8739035725593567 anomaly_mse= 0.9504153728485107 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.311748\n",
      "b= 27 normal_mse= 0.7737450003623962 anomaly_mse= 0.923872709274292 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.714925\n",
      "b= 28 normal_mse= 1.3232847452163696 anomaly_mse= 1.2081315517425537 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.683308\n",
      "b= 29 normal_mse= 0.8010181784629822 anomaly_mse= 0.9218646883964539 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.646306\n",
      "b= 30 normal_mse= 0.8790854215621948 anomaly_mse= 0.9413503408432007 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.314857\n",
      "b= 31 normal_mse= 0.7785259485244751 anomaly_mse= 0.9230132102966309 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.717897\n",
      "b= 32 normal_mse= 1.3189457654953003 anomaly_mse= 1.1982229948043823 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.685912\n",
      "b= 33 normal_mse= 0.8168188333511353 anomaly_mse= 0.9132511019706726 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.647846\n",
      "b= 34 normal_mse= 0.8759562373161316 anomaly_mse= 0.9465258121490479 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.317778\n",
      "b= 35 normal_mse= 0.7784754633903503 anomaly_mse= 0.9233186841011047 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.714451\n",
      "b= 36 normal_mse= 1.325459361076355 anomaly_mse= 1.1982547044754028 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.681600\n",
      "b= 37 normal_mse= 0.8084290027618408 anomaly_mse= 0.9122582077980042 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.647798\n",
      "b= 38 normal_mse= 0.8744721412658691 anomaly_mse= 0.9425325989723206 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.324215\n",
      "b= 39 normal_mse= 0.7738346457481384 anomaly_mse= 0.9261032938957214 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.715494\n",
      "b= 40 normal_mse= 1.324432373046875 anomaly_mse= 1.2039915323257446 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.685509\n",
      "b= 41 normal_mse= 0.8072710633277893 anomaly_mse= 0.9098020195960999 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.651432\n",
      "b= 42 normal_mse= 0.8748490214347839 anomaly_mse= 0.9433704614639282 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.319391\n",
      "b= 43 normal_mse= 0.7810050845146179 anomaly_mse= 0.9227392077445984 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.724592\n",
      "b= 44 normal_mse= 1.3155124187469482 anomaly_mse= 1.1992535591125488 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.682583\n",
      "b= 45 normal_mse= 0.8108289241790771 anomaly_mse= 0.9165570735931396 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.649728\n",
      "b= 46 normal_mse= 0.877210795879364 anomaly_mse= 0.941867470741272 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.320127\n",
      "b= 47 normal_mse= 0.777401864528656 anomaly_mse= 0.92647784948349 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.718186\n",
      "b= 48 normal_mse= 1.321545124053955 anomaly_mse= 1.2002732753753662 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.687334\n",
      "b= 49 normal_mse= 0.8108680844306946 anomaly_mse= 0.9088063836097717 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.647083\n",
      "b= 50 normal_mse= 0.8731577396392822 anomaly_mse= 0.9468832015991211 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.315641\n",
      "b= 51 normal_mse= 0.7755375504493713 anomaly_mse= 0.9220628142356873 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.720304\n",
      "b= 52 normal_mse= 1.3216873407363892 anomaly_mse= 1.2025020122528076 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.688632\n",
      "b= 53 normal_mse= 0.8089679479598999 anomaly_mse= 0.9160643815994263 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.650085\n",
      "b= 54 normal_mse= 0.8744375109672546 anomaly_mse= 0.9401534199714661 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.315009\n",
      "b= 55 normal_mse= 0.7766956686973572 anomaly_mse= 0.9208956956863403 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.719605\n",
      "b= 56 normal_mse= 1.3192285299301147 anomaly_mse= 1.1835049390792847 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.679227\n",
      "b= 57 normal_mse= 0.8039594292640686 anomaly_mse= 0.9135300517082214 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.650843\n",
      "b= 58 normal_mse= 0.8727697134017944 anomaly_mse= 0.9436579346656799 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.328753\n",
      "b= 59 normal_mse= 0.7750609517097473 anomaly_mse= 0.916958212852478 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.717858\n",
      "b= 60 normal_mse= 1.3209105730056763 anomaly_mse= 1.1946210861206055 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.688939\n",
      "b= 61 normal_mse= 0.8087412118911743 anomaly_mse= 0.9141931533813477 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.646402\n",
      "b= 62 normal_mse= 0.8743304014205933 anomaly_mse= 0.9475058913230896 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.319941\n",
      "b= 63 normal_mse= 0.7767572402954102 anomaly_mse= 0.9264297485351562 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.718487\n",
      "b= 64 normal_mse= 1.3191816806793213 anomaly_mse= 1.1978124380111694 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.684429\n",
      "b= 65 normal_mse= 0.8153703808784485 anomaly_mse= 0.9052512645721436 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.649273\n",
      "b= 66 normal_mse= 0.87177574634552 anomaly_mse= 0.9475797414779663 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 1.326492\n",
      "b= 67 normal_mse= 0.7795929908752441 anomaly_mse= 0.9233201146125793 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.721652\n",
      "b= 68 normal_mse= 1.3181054592132568 anomaly_mse= 1.19842529296875 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.683093\n",
      "b= 69 normal_mse= 0.8066779375076294 anomaly_mse= 0.9107100963592529 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.648534\n",
      "b= 70 normal_mse= 0.8745371699333191 anomaly_mse= 0.940835177898407 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.322160\n",
      "b= 71 normal_mse= 0.7762842178344727 anomaly_mse= 0.9161489009857178 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.718940\n",
      "b= 72 normal_mse= 1.3181781768798828 anomaly_mse= 1.1932264566421509 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.687913\n",
      "b= 73 normal_mse= 0.8064876794815063 anomaly_mse= 0.9188210368156433 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.647010\n",
      "b= 74 normal_mse= 0.8740177750587463 anomaly_mse= 0.9448128342628479 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.322567\n",
      "b= 75 normal_mse= 0.7771565914154053 anomaly_mse= 0.9201565980911255 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.719899\n",
      "b= 76 normal_mse= 1.3217118978500366 anomaly_mse= 1.1964694261550903 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.686697\n",
      "b= 77 normal_mse= 0.8091014623641968 anomaly_mse= 0.9088330864906311 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.648546\n",
      "b= 78 normal_mse= 0.8747069239616394 anomaly_mse= 0.9417614936828613 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.322667\n",
      "b= 79 normal_mse= 0.7737363576889038 anomaly_mse= 0.9225674867630005 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.718154\n",
      "b= 80 normal_mse= 1.3184380531311035 anomaly_mse= 1.198123574256897 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.685768\n",
      "b= 81 normal_mse= 0.8104813694953918 anomaly_mse= 0.9062805771827698 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.647628\n",
      "b= 82 normal_mse= 0.8759090900421143 anomaly_mse= 0.934070348739624 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 1.321151\n",
      "b= 83 normal_mse= 0.7757367491722107 anomaly_mse= 0.9207996726036072 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.724077\n",
      "b= 84 normal_mse= 1.317427635192871 anomaly_mse= 1.1991655826568604 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.689879\n",
      "b= 85 normal_mse= 0.8127631545066833 anomaly_mse= 0.9112909436225891 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.650635\n",
      "b= 86 normal_mse= 0.8724323511123657 anomaly_mse= 0.9447541832923889 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.313220\n",
      "b= 87 normal_mse= 0.7819421291351318 anomaly_mse= 0.9181369543075562 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.722155\n",
      "b= 88 normal_mse= 1.3158940076828003 anomaly_mse= 1.1963850259780884 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.690382\n",
      "b= 89 normal_mse= 0.8027967810630798 anomaly_mse= 0.9140017032623291 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.646977\n",
      "b= 90 normal_mse= 0.8775783777236938 anomaly_mse= 0.9418677091598511 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 1.319492\n",
      "b= 91 normal_mse= 0.7753501534461975 anomaly_mse= 0.9173212051391602 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.721244\n",
      "b= 92 normal_mse= 1.324190378189087 anomaly_mse= 1.1994929313659668 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.684060\n",
      "b= 93 normal_mse= 0.8003888726234436 anomaly_mse= 0.9135253429412842 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.646642\n",
      "b= 94 normal_mse= 0.8735343813896179 anomaly_mse= 0.9458540081977844 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.310764\n",
      "b= 95 normal_mse= 0.781533420085907 anomaly_mse= 0.9241988062858582 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.720060\n",
      "b= 96 normal_mse= 1.3197003602981567 anomaly_mse= 1.1963294744491577 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.685375\n",
      "b= 97 normal_mse= 0.8048637509346008 anomaly_mse= 0.912566602230072 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.648650\n",
      "b= 98 normal_mse= 0.8720935583114624 anomaly_mse= 0.9432083368301392 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 1.305157\n",
      "b= 99 normal_mse= 0.7793551683425903 anomaly_mse= 0.9189638495445251 anomaly_mse>normal_mse= True\n",
      "Running for fold - 4\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.409169\n",
      "b= 0 normal_mse= 0.942424476146698 anomaly_mse= 0.9663231372833252 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837762\n",
      "b= 1 normal_mse= 0.7156807780265808 anomaly_mse= 0.7359066009521484 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851895\n",
      "b= 2 normal_mse= 0.7812738418579102 anomaly_mse= 0.7498613595962524 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819508\n",
      "b= 3 normal_mse= 1.1492558717727661 anomaly_mse= 0.9250321388244629 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836987\n",
      "b= 4 normal_mse= 0.9764079451560974 anomaly_mse= 0.8600287437438965 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.651417\n",
      "b= 5 normal_mse= 0.6997278928756714 anomaly_mse= 0.7186511754989624 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851907\n",
      "b= 6 normal_mse= 0.7812812924385071 anomaly_mse= 0.749910831451416 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819504\n",
      "b= 7 normal_mse= 1.1491103172302246 anomaly_mse= 0.9249480366706848 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.615210\n",
      "b= 8 normal_mse= 0.9119057059288025 anomaly_mse= 0.8143860697746277 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.534558\n",
      "b= 9 normal_mse= 0.7354313731193542 anomaly_mse= 0.7346910834312439 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851862\n",
      "b= 10 normal_mse= 0.7811740636825562 anomaly_mse= 0.7499020099639893 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819517\n",
      "b= 11 normal_mse= 1.1490283012390137 anomaly_mse= 0.924921452999115 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836942\n",
      "b= 12 normal_mse= 0.9761596918106079 anomaly_mse= 0.8577727675437927 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837680\n",
      "b= 13 normal_mse= 0.7156766653060913 anomaly_mse= 0.7357964515686035 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851838\n",
      "b= 14 normal_mse= 0.7806815505027771 anomaly_mse= 0.7493475675582886 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819481\n",
      "b= 15 normal_mse= 1.1491726636886597 anomaly_mse= 0.9249581098556519 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.782705\n",
      "b= 16 normal_mse= 0.9362810850143433 anomaly_mse= 0.8295584917068481 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837751\n",
      "b= 17 normal_mse= 0.7156698703765869 anomaly_mse= 0.7358183860778809 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.491580\n",
      "b= 18 normal_mse= 0.7684480547904968 anomaly_mse= 0.7398659586906433 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819499\n",
      "b= 19 normal_mse= 1.1494395732879639 anomaly_mse= 0.9255077838897705 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836932\n",
      "b= 20 normal_mse= 0.9762647747993469 anomaly_mse= 0.859999418258667 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.658248\n",
      "b= 21 normal_mse= 0.711814820766449 anomaly_mse= 0.7464597225189209 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.557158\n",
      "b= 22 normal_mse= 0.9785889983177185 anomaly_mse= 0.9179161190986633 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.399087\n",
      "b= 23 normal_mse= 1.3053560256958008 anomaly_mse= 0.9893646240234375 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836944\n",
      "b= 24 normal_mse= 0.97629314661026 anomaly_mse= 0.8600444197654724 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837718\n",
      "b= 25 normal_mse= 0.7156708240509033 anomaly_mse= 0.7357930541038513 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851915\n",
      "b= 26 normal_mse= 0.7812575697898865 anomaly_mse= 0.7498777508735657 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819523\n",
      "b= 27 normal_mse= 1.1492794752120972 anomaly_mse= 0.9250372648239136 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836905\n",
      "b= 28 normal_mse= 0.9719345569610596 anomaly_mse= 0.859466016292572 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.591890\n",
      "b= 29 normal_mse= 0.8854573965072632 anomaly_mse= 0.9624436497688293 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851857\n",
      "b= 30 normal_mse= 0.7812795042991638 anomaly_mse= 0.7498986124992371 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819516\n",
      "b= 31 normal_mse= 1.1492598056793213 anomaly_mse= 0.9249359965324402 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.474968\n",
      "b= 32 normal_mse= 1.0376213788986206 anomaly_mse= 0.9131004810333252 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837749\n",
      "b= 33 normal_mse= 0.7156387567520142 anomaly_mse= 0.735759973526001 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.608142\n",
      "b= 34 normal_mse= 0.7222829461097717 anomaly_mse= 0.7072272300720215 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819509\n",
      "b= 35 normal_mse= 1.1492438316345215 anomaly_mse= 0.9248383641242981 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.580520\n",
      "b= 36 normal_mse= 0.9748863577842712 anomaly_mse= 0.8661861419677734 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837802\n",
      "b= 37 normal_mse= 0.7156984806060791 anomaly_mse= 0.7357457280158997 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851848\n",
      "b= 38 normal_mse= 0.7812795639038086 anomaly_mse= 0.7498374581336975 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819548\n",
      "b= 39 normal_mse= 1.1492058038711548 anomaly_mse= 0.9250555038452148 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836906\n",
      "b= 40 normal_mse= 0.9762338399887085 anomaly_mse= 0.860016405582428 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837759\n",
      "b= 41 normal_mse= 0.7156194448471069 anomaly_mse= 0.7358700037002563 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851846\n",
      "b= 42 normal_mse= 0.7812651991844177 anomaly_mse= 0.7499313354492188 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.544307\n",
      "b= 43 normal_mse= 1.2984117269515991 anomaly_mse= 1.1176997423171997 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836968\n",
      "b= 44 normal_mse= 0.9762530326843262 anomaly_mse= 0.8599094748497009 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.713817\n",
      "b= 45 normal_mse= 0.6875118017196655 anomaly_mse= 0.696219265460968 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851915\n",
      "b= 46 normal_mse= 0.7812607884407043 anomaly_mse= 0.7499207854270935 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819509\n",
      "b= 47 normal_mse= 1.1492140293121338 anomaly_mse= 0.9249776005744934 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836958\n",
      "b= 48 normal_mse= 0.9762308597564697 anomaly_mse= 0.8599370121955872 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837745\n",
      "b= 49 normal_mse= 0.7157676815986633 anomaly_mse= 0.7361002564430237 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.714808\n",
      "b= 50 normal_mse= 0.8442615270614624 anomaly_mse= 0.7738317251205444 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819477\n",
      "b= 51 normal_mse= 1.1492135524749756 anomaly_mse= 0.9249351620674133 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836960\n",
      "b= 52 normal_mse= 0.9763144850730896 anomaly_mse= 0.8597480654716492 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.674987\n",
      "b= 53 normal_mse= 0.8755404949188232 anomaly_mse= 0.818895161151886 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.545210\n",
      "b= 54 normal_mse= 0.9025835990905762 anomaly_mse= 0.691236674785614 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819532\n",
      "b= 55 normal_mse= 1.1492856740951538 anomaly_mse= 0.9250782132148743 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836929\n",
      "b= 56 normal_mse= 0.9761999845504761 anomaly_mse= 0.8599618673324585 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837751\n",
      "b= 57 normal_mse= 0.7156118750572205 anomaly_mse= 0.7357040643692017 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.474592\n",
      "b= 58 normal_mse= 0.9320080280303955 anomaly_mse= 0.8864254951477051 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819480\n",
      "b= 59 normal_mse= 1.1491318941116333 anomaly_mse= 0.9249905347824097 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.542497\n",
      "b= 60 normal_mse= 0.9225594401359558 anomaly_mse= 0.8341348767280579 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.428201\n",
      "b= 61 normal_mse= 0.9618620872497559 anomaly_mse= 0.9173086881637573 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.590614\n",
      "b= 62 normal_mse= 0.7992187738418579 anomaly_mse= 0.853799045085907 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819518\n",
      "b= 63 normal_mse= 1.1492087841033936 anomaly_mse= 0.9250395894050598 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836944\n",
      "b= 64 normal_mse= 0.9763848185539246 anomaly_mse= 0.8601086139678955 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837732\n",
      "b= 65 normal_mse= 0.7156421542167664 anomaly_mse= 0.7357581257820129 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851857\n",
      "b= 66 normal_mse= 0.7806358933448792 anomaly_mse= 0.7491294145584106 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.523626\n",
      "b= 67 normal_mse= 1.1203041076660156 anomaly_mse= 0.8459398746490479 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836935\n",
      "b= 68 normal_mse= 0.9763287901878357 anomaly_mse= 0.8600584864616394 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837721\n",
      "b= 69 normal_mse= 0.7156775593757629 anomaly_mse= 0.7358048558235168 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851914\n",
      "b= 70 normal_mse= 0.7812244296073914 anomaly_mse= 0.7498786449432373 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.650366\n",
      "b= 71 normal_mse= 1.1071159839630127 anomaly_mse= 0.8124665021896362 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836924\n",
      "b= 72 normal_mse= 0.976266086101532 anomaly_mse= 0.8600110411643982 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837776\n",
      "b= 73 normal_mse= 0.7158333659172058 anomaly_mse= 0.7361782789230347 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851835\n",
      "b= 74 normal_mse= 0.7813109755516052 anomaly_mse= 0.749883234500885 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819519\n",
      "b= 75 normal_mse= 1.149885892868042 anomaly_mse= 0.9251305460929871 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836981\n",
      "b= 76 normal_mse= 0.9761832356452942 anomaly_mse= 0.8599133491516113 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.693545\n",
      "b= 77 normal_mse= 0.7384508848190308 anomaly_mse= 0.681944727897644 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851825\n",
      "b= 78 normal_mse= 0.7812779545783997 anomaly_mse= 0.7498627305030823 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819502\n",
      "b= 79 normal_mse= 1.1492706537246704 anomaly_mse= 0.9249414801597595 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.616210\n",
      "b= 80 normal_mse= 1.035111427307129 anomaly_mse= 0.960135817527771 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837731\n",
      "b= 81 normal_mse= 0.7156866192817688 anomaly_mse= 0.7358091473579407 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851873\n",
      "b= 82 normal_mse= 0.781256914138794 anomaly_mse= 0.7499390244483948 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819526\n",
      "b= 83 normal_mse= 1.1491749286651611 anomaly_mse= 0.9249439239501953 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836967\n",
      "b= 84 normal_mse= 0.9761385321617126 anomaly_mse= 0.859926700592041 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837723\n",
      "b= 85 normal_mse= 0.7156809568405151 anomaly_mse= 0.7358275055885315 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851845\n",
      "b= 86 normal_mse= 0.7812130451202393 anomaly_mse= 0.7498956918716431 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.430266\n",
      "b= 87 normal_mse= 1.241765022277832 anomaly_mse= 0.9117532968521118 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.501014\n",
      "b= 88 normal_mse= 0.9177302718162537 anomaly_mse= 0.9177359342575073 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.670676\n",
      "b= 89 normal_mse= 0.6746355295181274 anomaly_mse= 0.6736794710159302 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851842\n",
      "b= 90 normal_mse= 0.7812737226486206 anomaly_mse= 0.7498621344566345 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819535\n",
      "b= 91 normal_mse= 1.149280071258545 anomaly_mse= 0.9250402450561523 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836937\n",
      "b= 92 normal_mse= 0.9762058258056641 anomaly_mse= 0.8600641489028931 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.388636\n",
      "b= 93 normal_mse= 1.2425148487091064 anomaly_mse= 1.2556648254394531 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851847\n",
      "b= 94 normal_mse= 0.781299352645874 anomaly_mse= 0.7498634457588196 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819475\n",
      "b= 95 normal_mse= 1.1491893529891968 anomaly_mse= 0.9249390959739685 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.836938\n",
      "b= 96 normal_mse= 0.9762724041938782 anomaly_mse= 0.8600463271141052 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.837742\n",
      "b= 97 normal_mse= 0.7156782746315002 anomaly_mse= 0.7357946634292603 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.851857\n",
      "b= 98 normal_mse= 0.7812705039978027 anomaly_mse= 0.7498775720596313 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.819475\n",
      "b= 99 normal_mse= 1.149183750152588 anomaly_mse= 0.9249585866928101 anomaly_mse>normal_mse= False\n"
     ]
    }
   ],
   "source": [
    "B = 100 #ensemble count\n",
    "\n",
    "feats = feats_df.columns[~feats_df.columns.isin(MASK_FEATS)].to_list()\n",
    "\n",
    "results_df = {**{\"fold\":[], \"b\":[], \"permute_seed\":[], \"mse_mean\":[]}, **{\"mse_\"+feat:[] for feat in feats}, **{\"label\":[]}} # {**dict1, **dict2,...} is a way to merge multiple dictionaries\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for fold in cv_dict:\n",
    "\n",
    "    print(f\"Running for fold - {fold}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    num_epochs = 1_000\n",
    "    batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    lr = 1e-3\n",
    "    h_lambda = 1e-2 #with l1 regularization\n",
    "    \n",
    "    input_dim = len(feats)\n",
    "    latent_dim = 5\n",
    "    \n",
    "    activation_fn = nn.LeakyReLU()\n",
    "    encoder_layers = [50, 25, 10] #under-complete hidden layers\n",
    "\n",
    "    \n",
    "    X =  feats_df[feats_df[\"id\"].isin(cv_dict[fold][\"train\"])][feats].to_numpy()\n",
    "    y = feats_df[feats_df[\"id\"].isin(cv_dict[fold][\"train\"])].label.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # X[X>=3] = 3\n",
    "    # X[X<=-3] = -3\n",
    "\n",
    "    X_norm, X_anomaly = utils.norm_anomaly_split(X, y)\n",
    "\n",
    "    for b in range(B):\n",
    "\n",
    "        seed = np.random.randint(B)\n",
    "        np.random.seed(seed)\n",
    "        idx = np.random.permutation(len(X_norm))\n",
    "        \n",
    "        X_train= X_norm[idx[:-len(X_anomaly)]]\n",
    "        X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "        X_test_anomaly = X_anomaly\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_train[X_train>=3] = 3\n",
    "        X_train[X_train<=-3] = -3\n",
    "        \n",
    "        X_test_norm = scaler.transform(X_test_norm)\n",
    "        X_test_norm[X_test_norm>=3] = 3\n",
    "        X_test_norm[X_test_norm<=-3] = -3\n",
    "        \n",
    "        X_test_anomaly = scaler.transform(X_test_anomaly)\n",
    "        X_test_anomaly[X_test_anomaly>=3] = 3\n",
    "        X_test_anomaly[X_test_anomaly<=-3] = -3\n",
    "        \n",
    "        X_train =  torch.from_numpy(X_train).float()\n",
    "        X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "        X_test_anomaly = torch.from_numpy(X_test_anomaly).float()\n",
    "    \n",
    "        train_ds = utils.Dataset(X_train)\n",
    "        val_ds = utils.Dataset(X_train)\n",
    "        dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "        \n",
    "        dsae = utils.Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "        model = utils.Model(dsae)\n",
    "        model.compile(lr, h_lambda, loss_fn)\n",
    "        _ = model.fit(dls, num_epochs, verbose=False)\n",
    "    \n",
    "        recon_X_test_norm, h_norm = model.net(X_test_norm)\n",
    "        recon_X_test_anomaly, h_anomaly = model.net(X_test_anomaly)\n",
    "    \n",
    "        mse = {0:nn.MSELoss(reduction=\"none\")(recon_X_test_norm, X_test_norm).mean(axis=0), 1:nn.MSELoss(reduction=\"none\")(recon_X_test_anomaly, X_test_anomaly).mean(axis=0)}\n",
    "        \n",
    "        for label in mse:\n",
    "            results_df[\"fold\"].append(fold)\n",
    "            results_df[\"b\"].append(b)\n",
    "            results_df[\"permute_seed\"].append(seed)\n",
    "            results_df[\"mse_mean\"].append(mse[label].mean().item())\n",
    "            for feat, feat_mse in zip(feats, mse[label]):\n",
    "                results_df[\"mse_\"+feat].append(feat_mse.item())\n",
    "            results_df[\"label\"].append(label)\n",
    "            \n",
    "        print(\"b=\", b, \"normal_mse=\", mse[0].mean().item(), \"anomaly_mse=\", mse[1].mean().item(), \"anomaly_mse>normal_mse=\", mse[1].mean().item()>mse[0].mean().item())\n",
    "\n",
    "\n",
    "    temp_df = pd.DataFrame(results_df)\n",
    "    temp_df = temp_df[temp_df.fold==fold].groupby(by=[\"label\"]).mean()[[\"mse_\"+feat for feat in feats]]\n",
    "\n",
    "    delta = temp_df.loc[1] - temp_df.loc[0]\n",
    "    rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "\n",
    "    rank_df = pd.DataFrame({\"feature\":feats, \"rank\":rank})\n",
    "    rank_df.to_csv(os.path.join(OUT_DIR, f\"rank_df{fold}.csv\"), index=False)\n",
    "\n",
    "    \n",
    "results_df = pd.DataFrame(results_df) \n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"results_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811c6e1-6b24-47d9-9389-7723afce8884",
   "metadata": {},
   "source": [
    "### Cross Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87ae356-4385-413c-ac5a-9240a8e4363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc45bfa-b5b4-489a-b678-1b13d6309894",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SELECTED_FEATS = 5\n",
    "\n",
    "estimators = [LogisticRegression(penalty=None, max_iter=10_000), SVC(kernel=\"linear\", max_iter=10_000, probability=True), RandomForestClassifier(), MLPClassifier(max_iter=10_000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1b8533-cafc-428d-9699-8e9a74511ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating estimator - LogisticRegression\n",
      "Evaluating estimator - SVC\n",
      "Evaluating estimator - RandomForestClassifier\n",
      "Evaluating estimator - MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "performance_df = {\"estimator\":[], \"fold\":[], \"roc_auc\":[], \"prc_auc\":[]}\n",
    "\n",
    "for estimator in estimators:\n",
    "\n",
    "    print(f\"Evaluating estimator - {estimator.__class__.__name__}\")\n",
    "\n",
    "    pipeline = make_pipeline(StandardScaler(), estimator)\n",
    "\n",
    "    for fold in cv_dict:\n",
    "\n",
    "        train_feats_df = feats_df[feats_df[\"id\"].isin(cv_dict[fold][\"train\"])]\n",
    "        test_feats_df = feats_df[feats_df[\"id\"].isin(cv_dict[fold][\"val\"])]\n",
    "\n",
    "        rank_df = pd.read_csv(os.path.join(OUT_DIR, f\"rank_df{fold}.csv\"))\n",
    "\n",
    "        selected_features = rank_df[rank_df[\"rank\"]<=NUM_SELECTED_FEATS][\"feature\"].to_list()\n",
    "\n",
    "        train_X = train_feats_df[selected_features].to_numpy()\n",
    "        train_y = train_feats_df[\"label\"].to_numpy().ravel()\n",
    "\n",
    "        test_X = test_feats_df[selected_features].to_numpy()\n",
    "        test_y = test_feats_df[\"label\"].to_numpy().ravel()\n",
    "\n",
    "        pipeline.fit(train_X, train_y)\n",
    "        prob_y = pipeline.predict_proba(test_X)[:,1]\n",
    "\n",
    "        roc_auc = roc_auc_score(test_y, prob_y)\n",
    "        prc_auc = average_precision_score(test_y, prob_y)\n",
    "\n",
    "        performance_df[\"estimator\"].append(estimator.__class__.__name__)\n",
    "        performance_df[\"fold\"].append(fold)\n",
    "        performance_df[\"roc_auc\"].append(roc_auc)\n",
    "        performance_df[\"prc_auc\"].append(prc_auc)\n",
    "        \n",
    "        \n",
    "performance_df = pd.DataFrame(performance_df)\n",
    "performance_df.to_csv(os.path.join(OUT_DIR, \"performance_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58901dbf-6503-4948-887a-716283ddf702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold       2.000000\n",
       "roc_auc    0.534988\n",
       "prc_auc    0.444939\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df.groupby(by=\"estimator\").mean().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
