{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c8d6ec-6037-4500-9bb5-1e518c6e1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils as utils\n",
    "import similarity_index as similarity_index\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd380604-c818-49b5-81ec-32e6cd9296a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"radiomicsFeatures.csv\"\n",
    "OUT_DIR = r\"outputs/ensembleDSAE\"\n",
    "MASK_FEATS = [\"id\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67d8e59-4d33-42ee-a6db-996b07b5dd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_wout_original_glcm_ClusterProminence</th>\n",
       "      <th>adc_original_firstorder_Minimum</th>\n",
       "      <th>sub_wout_original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>sub_wout_original_firstorder_Maximum</th>\n",
       "      <th>adc_original_glcm_ClusterShade</th>\n",
       "      <th>sub_wout_original_firstorder_Mean</th>\n",
       "      <th>sub_win_original_glcm_Autocorrelation</th>\n",
       "      <th>adc_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_win_original_glszm_ZoneEntropy</th>\n",
       "      <th>t2w_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>t2w_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glcm_MaximumProbability</th>\n",
       "      <th>sub_win_original_glcm_Imc1</th>\n",
       "      <th>sub_wout_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2535039</td>\n",
       "      <td>1</td>\n",
       "      <td>4.677862e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14835.837461</td>\n",
       "      <td>299.900214</td>\n",
       "      <td>3755.933491</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>...</td>\n",
       "      <td>6.339939</td>\n",
       "      <td>0.286470</td>\n",
       "      <td>10.166389</td>\n",
       "      <td>27423.571919</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>2946.837800</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.041978</td>\n",
       "      <td>10.452108</td>\n",
       "      <td>0.033786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2417361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.834267e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-17634.034850</td>\n",
       "      <td>299.918235</td>\n",
       "      <td>3941.494865</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.424770</td>\n",
       "      <td>0.350004</td>\n",
       "      <td>11.649157</td>\n",
       "      <td>21732.551407</td>\n",
       "      <td>0.604518</td>\n",
       "      <td>3322.225544</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.109242</td>\n",
       "      <td>11.891117</td>\n",
       "      <td>0.009861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2602563</td>\n",
       "      <td>1</td>\n",
       "      <td>5.159220e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-19736.430500</td>\n",
       "      <td>299.820687</td>\n",
       "      <td>2455.254084</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>...</td>\n",
       "      <td>7.239270</td>\n",
       "      <td>0.350692</td>\n",
       "      <td>10.919838</td>\n",
       "      <td>15567.069802</td>\n",
       "      <td>0.574356</td>\n",
       "      <td>3407.597573</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.194449</td>\n",
       "      <td>11.214368</td>\n",
       "      <td>0.018991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2902440</td>\n",
       "      <td>0</td>\n",
       "      <td>3.613791e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-12881.976888</td>\n",
       "      <td>299.240444</td>\n",
       "      <td>3954.079034</td>\n",
       "      <td>0.576021</td>\n",
       "      <td>...</td>\n",
       "      <td>7.454390</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>18389.243521</td>\n",
       "      <td>0.566131</td>\n",
       "      <td>3121.573712</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>11.669841</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2921898</td>\n",
       "      <td>0</td>\n",
       "      <td>5.773968e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2116.811733</td>\n",
       "      <td>299.983523</td>\n",
       "      <td>3793.819336</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.755170</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>9.504938</td>\n",
       "      <td>245786.779116</td>\n",
       "      <td>0.469149</td>\n",
       "      <td>3175.569089</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.058680</td>\n",
       "      <td>11.459667</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  sub_wout_original_glcm_ClusterProminence  \\\n",
       "0  2535039      1                              4.677862e+06   \n",
       "1  2417361      0                              4.834267e+06   \n",
       "2  2602563      1                              5.159220e+06   \n",
       "3  2902440      0                              3.613791e+06   \n",
       "4  2921898      0                              5.773968e+06   \n",
       "\n",
       "   adc_original_firstorder_Minimum  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              0.0   \n",
       "\n",
       "   sub_wout_original_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                          0.003103   \n",
       "1                                          0.001672   \n",
       "2                                          0.001600   \n",
       "3                                          0.002428   \n",
       "4                                          0.001720   \n",
       "\n",
       "   sub_wout_original_firstorder_Maximum  adc_original_glcm_ClusterShade  \\\n",
       "0                                 600.0                    14835.837461   \n",
       "1                                 600.0                   -17634.034850   \n",
       "2                                 600.0                   -19736.430500   \n",
       "3                                 600.0                   -12881.976888   \n",
       "4                                 600.0                     2116.811733   \n",
       "\n",
       "   sub_wout_original_firstorder_Mean  sub_win_original_glcm_Autocorrelation  \\\n",
       "0                         299.900214                            3755.933491   \n",
       "1                         299.918235                            3941.494865   \n",
       "2                         299.820687                            2455.254084   \n",
       "3                         299.240444                            3954.079034   \n",
       "4                         299.983523                            3793.819336   \n",
       "\n",
       "   adc_original_glszm_LargeAreaLowGrayLevelEmphasis  ...  \\\n",
       "0                                          0.010393  ...   \n",
       "1                                          0.058145  ...   \n",
       "2                                          0.019202  ...   \n",
       "3                                          0.576021  ...   \n",
       "4                                          0.011764  ...   \n",
       "\n",
       "   sub_win_original_glszm_ZoneEntropy  \\\n",
       "0                            6.339939   \n",
       "1                            7.424770   \n",
       "2                            7.239270   \n",
       "3                            7.454390   \n",
       "4                            6.755170   \n",
       "\n",
       "   t2w_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.286470    \n",
       "1                                           0.350004    \n",
       "2                                           0.350692    \n",
       "3                                           0.380537    \n",
       "4                                           0.265413    \n",
       "\n",
       "   t2w_original_glcm_JointEntropy  \\\n",
       "0                       10.166389   \n",
       "1                       11.649157   \n",
       "2                       10.919838   \n",
       "3                       11.530000   \n",
       "4                        9.504938   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                       27423.571919   \n",
       "1                                       21732.551407   \n",
       "2                                       15567.069802   \n",
       "3                                       18389.243521   \n",
       "4                                      245786.779116   \n",
       "\n",
       "   sub_win_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.461100        \n",
       "1                                           0.604518        \n",
       "2                                           0.574356        \n",
       "3                                           0.566131        \n",
       "4                                           0.469149        \n",
       "\n",
       "   sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                        2946.837800        \n",
       "1                                        3322.225544        \n",
       "2                                        3407.597573        \n",
       "3                                        3121.573712        \n",
       "4                                        3175.569089        \n",
       "\n",
       "   sub_win_original_glcm_MaximumProbability  sub_win_original_glcm_Imc1  \\\n",
       "0                                  0.034622                   -0.041978   \n",
       "1                                  0.002107                   -0.109242   \n",
       "2                                  0.004002                   -0.194449   \n",
       "3                                  0.004134                   -0.116415   \n",
       "4                                  0.027634                   -0.058680   \n",
       "\n",
       "   sub_wout_original_glcm_JointEntropy  \\\n",
       "0                            10.452108   \n",
       "1                            11.891117   \n",
       "2                            11.214368   \n",
       "3                            11.669841   \n",
       "4                            11.459667   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaLowGrayLevelEmphasis  \n",
       "0                                          0.033786  \n",
       "1                                          0.009861  \n",
       "2                                          0.018991  \n",
       "3                                          0.007846  \n",
       "4                                          0.024444  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6efc18-aa18-494c-9781-cde3d937cbe3",
   "metadata": {},
   "source": [
    "### Stratified CV Fold Generation (Consistent across FS algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd985de-47b7-40a1-83b3-14014e8efada",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = feats_df.id.to_numpy()\n",
    "labels = feats_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac94421f-8f10-460f-a89b-8877a4a32614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'train': array([2602563, 2921898, 3039346, 3110297, 3110706, 3137563, 3207798,\n",
       "         3213683, 3222346, 3226033, 3303911, 3325442, 3327697, 3329611,\n",
       "         3336537, 3405013, 3416781, 3419338, 3502691, 3504033, 3513664,\n",
       "         3519247, 3522629, 3534419, 3536230, 3607842, 3610014, 3613524,\n",
       "         3616819, 3618480, 3621681, 3621824, 3622974, 3631910, 3632788,\n",
       "         3701079, 3702147, 3707565, 3713983, 3714280, 3715560, 3716356,\n",
       "         3718385, 3720950, 3724846, 3725583, 3726460, 3727030, 3727850,\n",
       "         3729691, 3730269, 3800022, 3802504, 3808093, 3811134, 3811967,\n",
       "         3812057, 3815317, 3817381, 3819464, 3821188, 3821859, 3822353,\n",
       "         3823428, 3825318, 3827579, 3828403, 3901619, 3904119, 3904751,\n",
       "         3906071, 3906505, 3907211, 3907314, 3907344, 3908895, 3911843,\n",
       "         9534972, 9803775, 9816715]),\n",
       "  'val': array([2535039, 2417361, 2902440, 3310301, 3332798, 3534604, 3605303,\n",
       "         3621917, 3702859, 3703425, 3712766, 3728041, 3805884, 3811851,\n",
       "         3819781, 3823293, 3833691, 3833806, 3900009, 3902242])},\n",
       " 1: {'train': array([2535039, 2417361, 2602563, 2902440, 2921898, 3039346, 3110297,\n",
       "         3110706, 3137563, 3207798, 3213683, 3222346, 3226033, 3303911,\n",
       "         3310301, 3327697, 3329611, 3332798, 3416781, 3502691, 3504033,\n",
       "         3513664, 3519247, 3522629, 3534604, 3536230, 3605303, 3610014,\n",
       "         3613524, 3616819, 3618480, 3621681, 3621917, 3631910, 3632788,\n",
       "         3702859, 3703425, 3712766, 3713983, 3714280, 3715560, 3720950,\n",
       "         3724846, 3725583, 3726460, 3727030, 3727850, 3728041, 3800022,\n",
       "         3802504, 3805884, 3808093, 3811134, 3811851, 3811967, 3812057,\n",
       "         3819464, 3819781, 3821188, 3822353, 3823293, 3823428, 3825318,\n",
       "         3827579, 3828403, 3833691, 3833806, 3900009, 3902242, 3901619,\n",
       "         3904119, 3904751, 3906071, 3907211, 3907314, 3908895, 3911843,\n",
       "         9534972, 9803775, 9816715]),\n",
       "  'val': array([3325442, 3336537, 3405013, 3419338, 3534419, 3607842, 3621824,\n",
       "         3622974, 3701079, 3702147, 3707565, 3716356, 3718385, 3729691,\n",
       "         3730269, 3815317, 3817381, 3821859, 3906505, 3907344])},\n",
       " 2: {'train': array([2535039, 2417361, 2602563, 2902440, 2921898, 3110297, 3137563,\n",
       "         3213683, 3222346, 3226033, 3303911, 3310301, 3325442, 3329611,\n",
       "         3332798, 3336537, 3405013, 3416781, 3419338, 3502691, 3504033,\n",
       "         3513664, 3519247, 3522629, 3534419, 3534604, 3605303, 3607842,\n",
       "         3613524, 3616819, 3618480, 3621824, 3621917, 3622974, 3631910,\n",
       "         3632788, 3701079, 3702147, 3702859, 3703425, 3707565, 3712766,\n",
       "         3713983, 3714280, 3715560, 3716356, 3718385, 3720950, 3724846,\n",
       "         3725583, 3727030, 3727850, 3728041, 3729691, 3730269, 3805884,\n",
       "         3811134, 3811851, 3815317, 3817381, 3819464, 3819781, 3821859,\n",
       "         3822353, 3823293, 3825318, 3827579, 3828403, 3833691, 3833806,\n",
       "         3900009, 3902242, 3901619, 3906505, 3907314, 3907344, 3911843,\n",
       "         9534972, 9803775, 9816715]),\n",
       "  'val': array([3039346, 3110706, 3207798, 3327697, 3536230, 3610014, 3621681,\n",
       "         3726460, 3800022, 3802504, 3808093, 3811967, 3812057, 3821188,\n",
       "         3823428, 3904119, 3904751, 3906071, 3907211, 3908895])},\n",
       " 3: {'train': array([2535039, 2417361, 2902440, 3039346, 3110297, 3110706, 3207798,\n",
       "         3226033, 3310301, 3325442, 3327697, 3329611, 3332798, 3336537,\n",
       "         3405013, 3416781, 3419338, 3502691, 3504033, 3513664, 3519247,\n",
       "         3534419, 3534604, 3536230, 3605303, 3607842, 3610014, 3616819,\n",
       "         3621681, 3621824, 3621917, 3622974, 3632788, 3701079, 3702147,\n",
       "         3702859, 3703425, 3707565, 3712766, 3713983, 3716356, 3718385,\n",
       "         3726460, 3727030, 3727850, 3728041, 3729691, 3730269, 3800022,\n",
       "         3802504, 3805884, 3808093, 3811134, 3811851, 3811967, 3812057,\n",
       "         3815317, 3817381, 3819781, 3821188, 3821859, 3823293, 3823428,\n",
       "         3825318, 3827579, 3828403, 3833691, 3833806, 3900009, 3902242,\n",
       "         3904119, 3904751, 3906071, 3906505, 3907211, 3907314, 3907344,\n",
       "         3908895, 9534972, 9816715]),\n",
       "  'val': array([2602563, 2921898, 3137563, 3213683, 3222346, 3303911, 3522629,\n",
       "         3613524, 3618480, 3631910, 3714280, 3715560, 3720950, 3724846,\n",
       "         3725583, 3819464, 3822353, 3901619, 3911843, 9803775])},\n",
       " 4: {'train': array([2535039, 2417361, 2602563, 2902440, 2921898, 3039346, 3110706,\n",
       "         3137563, 3207798, 3213683, 3222346, 3303911, 3310301, 3325442,\n",
       "         3327697, 3332798, 3336537, 3405013, 3419338, 3522629, 3534419,\n",
       "         3534604, 3536230, 3605303, 3607842, 3610014, 3613524, 3618480,\n",
       "         3621681, 3621824, 3621917, 3622974, 3631910, 3701079, 3702147,\n",
       "         3702859, 3703425, 3707565, 3712766, 3714280, 3715560, 3716356,\n",
       "         3718385, 3720950, 3724846, 3725583, 3726460, 3728041, 3729691,\n",
       "         3730269, 3800022, 3802504, 3805884, 3808093, 3811851, 3811967,\n",
       "         3812057, 3815317, 3817381, 3819464, 3819781, 3821188, 3821859,\n",
       "         3822353, 3823293, 3823428, 3833691, 3833806, 3900009, 3902242,\n",
       "         3901619, 3904119, 3904751, 3906071, 3906505, 3907211, 3907344,\n",
       "         3908895, 3911843, 9803775]),\n",
       "  'val': array([3110297, 3226033, 3329611, 3416781, 3502691, 3504033, 3513664,\n",
       "         3519247, 3616819, 3632788, 3713983, 3727030, 3727850, 3811134,\n",
       "         3825318, 3827579, 3828403, 3907314, 9534972, 9816715])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_count = 5\n",
    "\n",
    "cv_dict = {}\n",
    "skf = StratifiedKFold(n_splits = cv_count, random_state=0, shuffle=True)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(skf.split(pids, labels)):\n",
    "    cv_dict[i] = {\"train\":pids[train_idx], \"val\":pids[val_idx]} \n",
    "\n",
    "cv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96a9d3-946f-4dc5-8051-6ba783ed4d20",
   "metadata": {},
   "source": [
    "### Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0ae46-b2b1-4d80-862f-0b501950455f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for fold - 0\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 8s\n",
      "Best val Loss: 0.836318\n",
      "b= 0 normal_mse= 0.8677940964698792 anomaly_mse= 0.907132625579834 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.738372\n",
      "b= 1 normal_mse= 1.1694172620773315 anomaly_mse= 1.0855456590652466 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.750266\n",
      "b= 2 normal_mse= 0.7504907846450806 anomaly_mse= 0.8968709111213684 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.170860\n",
      "b= 3 normal_mse= 1.2321064472198486 anomaly_mse= 1.103742241859436 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044348\n",
      "b= 4 normal_mse= 0.8730214834213257 anomaly_mse= 0.9628665447235107 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.850474\n",
      "b= 5 normal_mse= 0.9370166659355164 anomaly_mse= 0.9616538882255554 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748114\n",
      "b= 6 normal_mse= 0.7587926387786865 anomaly_mse= 0.9035707712173462 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.162829\n",
      "b= 7 normal_mse= 1.2344099283218384 anomaly_mse= 1.0924092531204224 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.041360\n",
      "b= 8 normal_mse= 0.8730427622795105 anomaly_mse= 0.9577100276947021 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.851919\n",
      "b= 9 normal_mse= 0.9394505620002747 anomaly_mse= 0.9591653347015381 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748595\n",
      "b= 10 normal_mse= 0.75780189037323 anomaly_mse= 0.902052640914917 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.175464\n",
      "b= 11 normal_mse= 1.2224502563476562 anomaly_mse= 1.0992285013198853 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044527\n",
      "b= 12 normal_mse= 0.8723291158676147 anomaly_mse= 0.9586281776428223 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.844959\n",
      "b= 13 normal_mse= 0.9409392476081848 anomaly_mse= 0.96221923828125 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748224\n",
      "b= 14 normal_mse= 0.7533212900161743 anomaly_mse= 0.8999420404434204 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.173240\n",
      "b= 15 normal_mse= 1.2289623022079468 anomaly_mse= 1.0948997735977173 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.045399\n",
      "b= 16 normal_mse= 0.8750466108322144 anomaly_mse= 0.9660481810569763 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.845989\n",
      "b= 17 normal_mse= 0.936320960521698 anomaly_mse= 0.9683231115341187 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.749143\n",
      "b= 18 normal_mse= 0.7520874738693237 anomaly_mse= 0.8976802825927734 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.169979\n",
      "b= 19 normal_mse= 1.2336065769195557 anomaly_mse= 1.1005358695983887 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.041436\n",
      "b= 20 normal_mse= 0.8675193190574646 anomaly_mse= 0.9553560614585876 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.849410\n",
      "b= 21 normal_mse= 0.9381701946258545 anomaly_mse= 0.9616622924804688 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.740339\n",
      "b= 22 normal_mse= 0.7553534507751465 anomaly_mse= 0.9074587225914001 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.167452\n",
      "b= 23 normal_mse= 1.231047511100769 anomaly_mse= 1.0994446277618408 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.048472\n",
      "b= 24 normal_mse= 0.8695720434188843 anomaly_mse= 0.9494288563728333 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.849625\n",
      "b= 25 normal_mse= 0.9387285113334656 anomaly_mse= 0.9642161726951599 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.746448\n",
      "b= 26 normal_mse= 0.7545212507247925 anomaly_mse= 0.8998009562492371 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.174317\n",
      "b= 27 normal_mse= 1.2306609153747559 anomaly_mse= 1.0994203090667725 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044614\n",
      "b= 28 normal_mse= 0.8711336851119995 anomaly_mse= 0.9581956267356873 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.847017\n",
      "b= 29 normal_mse= 0.9361227750778198 anomaly_mse= 0.9629937410354614 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748705\n",
      "b= 30 normal_mse= 0.7517545223236084 anomaly_mse= 0.8961021304130554 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.173255\n",
      "b= 31 normal_mse= 1.22989022731781 anomaly_mse= 1.096954107284546 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.045259\n",
      "b= 32 normal_mse= 0.8708732724189758 anomaly_mse= 0.9583985209465027 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.844388\n",
      "b= 33 normal_mse= 0.9376705288887024 anomaly_mse= 0.9706302881240845 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.748641\n",
      "b= 34 normal_mse= 0.7508570551872253 anomaly_mse= 0.89881432056427 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.170121\n",
      "b= 35 normal_mse= 1.230928659439087 anomaly_mse= 1.093765139579773 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.043068\n",
      "b= 36 normal_mse= 0.8720038533210754 anomaly_mse= 0.9578945636749268 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.843913\n",
      "b= 37 normal_mse= 0.9367184638977051 anomaly_mse= 0.9654300808906555 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.746114\n",
      "b= 38 normal_mse= 0.7537438273429871 anomaly_mse= 0.8968117237091064 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.170252\n",
      "b= 39 normal_mse= 1.2305973768234253 anomaly_mse= 1.097620964050293 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.045746\n",
      "b= 40 normal_mse= 0.8714298605918884 anomaly_mse= 0.9569817185401917 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.850037\n",
      "b= 41 normal_mse= 0.9375008344650269 anomaly_mse= 0.9575827717781067 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.745938\n",
      "b= 42 normal_mse= 0.7535531520843506 anomaly_mse= 0.8983399271965027 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.167330\n",
      "b= 43 normal_mse= 1.2219042778015137 anomaly_mse= 1.1029596328735352 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 1.044800\n",
      "b= 44 normal_mse= 0.8733559846878052 anomaly_mse= 0.9513654112815857 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 7s\n",
      "Best val Loss: 0.851407\n",
      "b= 45 normal_mse= 0.9437885880470276 anomaly_mse= 0.9706256985664368 anomaly_mse>normal_mse= True\n"
     ]
    }
   ],
   "source": [
    "B = 100 #ensemble count\n",
    "\n",
    "feats = feats_df.columns[~feats_df.columns.isin(MASK_FEATS)].to_list()\n",
    "\n",
    "results_df = {**{\"fold\":[], \"b\":[], \"permute_seed\":[], \"mse_mean\":[]}, **{\"mse_\"+feat:[] for feat in feats}, **{\"label\":[]}} # {**dict1, **dict2,...} is a way to merge multiple dictionaries\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for fold in cv_dict:\n",
    "\n",
    "    print(f\"Running for fold - {fold}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    num_epochs = 1_000\n",
    "    batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    lr = 1e-3\n",
    "    h_lambda = 1e-2 #with l1 regularization\n",
    "    \n",
    "    input_dim = len(feats)\n",
    "    latent_dim = 5\n",
    "    \n",
    "    activation_fn = nn.LeakyReLU()\n",
    "    encoder_layers = [50, 25, 10] #under-complete hidden layers\n",
    "\n",
    "    \n",
    "    X =  feats_df[feats_df[\"id\"].isin(cv_dict[fold][\"train\"])][feats].to_numpy()\n",
    "    y = feats_df[feats_df[\"id\"].isin(cv_dict[fold][\"train\"])].label.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # X[X>=3] = 3\n",
    "    # X[X<=-3] = -3\n",
    "\n",
    "    X_norm, X_anomaly = utils.norm_anomaly_split(X, y)\n",
    "\n",
    "    for b in range(B):\n",
    "\n",
    "        seed = np.random.randint(B)\n",
    "        np.random.seed(seed)\n",
    "        idx = np.random.permutation(len(X_norm))\n",
    "        \n",
    "        X_train= X_norm[idx[:-len(X_anomaly)]]\n",
    "        X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "        X_test_anomaly = X_anomaly\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_train[X_train>=3] = 3\n",
    "        X_train[X_train<=-3] = -3\n",
    "        \n",
    "        X_test_norm = scaler.transform(X_test_norm)\n",
    "        X_test_norm[X_test_norm>=3] = 3\n",
    "        X_test_norm[X_test_norm<=-3] = -3\n",
    "        \n",
    "        X_test_anomaly = scaler.transform(X_test_anomaly)\n",
    "        X_test_anomaly[X_test_anomaly>=3] = 3\n",
    "        X_test_anomaly[X_test_anomaly<=-3] = -3\n",
    "        \n",
    "        X_train =  torch.from_numpy(X_train).float()\n",
    "        X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "        X_test_anomaly = torch.from_numpy(X_test_anomaly).float()\n",
    "    \n",
    "        train_ds = utils.Dataset(X_train)\n",
    "        val_ds = utils.Dataset(X_train)\n",
    "        dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "        \n",
    "        dsae = utils.Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "        model = utils.Model(dsae)\n",
    "        model.compile(lr, h_lambda, loss_fn)\n",
    "        _ = model.fit(dls, num_epochs, verbose=False)\n",
    "    \n",
    "        recon_X_test_norm, h_norm = model.net(X_test_norm)\n",
    "        recon_X_test_anomaly, h_anomaly = model.net(X_test_anomaly)\n",
    "    \n",
    "        mse = {0:nn.MSELoss(reduction=\"none\")(recon_X_test_norm, X_test_norm).mean(axis=0), 1:nn.MSELoss(reduction=\"none\")(recon_X_test_anomaly, X_test_anomaly).mean(axis=0)}\n",
    "        \n",
    "        for label in mse:\n",
    "            results_df[\"fold\"].append(fold)\n",
    "            results_df[\"b\"].append(b)\n",
    "            results_df[\"permute_seed\"].append(seed)\n",
    "            results_df[\"mse_mean\"].append(mse[label].mean().item())\n",
    "            for feat, feat_mse in zip(feats, mse[label]):\n",
    "                results_df[\"mse_\"+feat].append(feat_mse.item())\n",
    "            results_df[\"label\"].append(label)\n",
    "            \n",
    "        print(\"b=\", b, \"normal_mse=\", mse[0].mean().item(), \"anomaly_mse=\", mse[1].mean().item(), \"anomaly_mse>normal_mse=\", mse[1].mean().item()>mse[0].mean().item())\n",
    "\n",
    "\n",
    "    temp_df = pd.DataFrame(results_df)\n",
    "    temp_df = temp_df[temp_df.fold==fold].groupby(by=[\"label\"]).mean()[[\"mse_\"+feat for feat in feats]]\n",
    "\n",
    "    delta = temp_df.loc[1] - temp_df.loc[0]\n",
    "    rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "\n",
    "    rank_df = pd.DataFrame({\"feature\":feats, \"rank\":rank})\n",
    "    rank_df.to_csv(os.path.join(OUT_DIR, f\"rank_df{fold}.csv\"), index=False)\n",
    "\n",
    "    \n",
    "results_df = pd.DataFrame(results_df) \n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"results_df.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
