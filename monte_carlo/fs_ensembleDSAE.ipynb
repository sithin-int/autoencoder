{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c8d6ec-6037-4500-9bb5-1e518c6e1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils as utils\n",
    "import similarity_index as similarity_index\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd380604-c818-49b5-81ec-32e6cd9296a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"inputs/radiomicsFeatures.csv\"\n",
    "OUT_DIR = r\"outputs/ensembleDSAE\"\n",
    "MASK_FEATS = [\"id\", \"label\"]\n",
    "\n",
    "NUM_REPEATS = 100\n",
    "\n",
    "B = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67d8e59-4d33-42ee-a6db-996b07b5dd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_wout_original_glcm_ClusterProminence</th>\n",
       "      <th>adc_original_firstorder_Minimum</th>\n",
       "      <th>sub_wout_original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>sub_wout_original_firstorder_Maximum</th>\n",
       "      <th>adc_original_glcm_ClusterShade</th>\n",
       "      <th>sub_wout_original_firstorder_Mean</th>\n",
       "      <th>sub_win_original_glcm_Autocorrelation</th>\n",
       "      <th>adc_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_win_original_glszm_ZoneEntropy</th>\n",
       "      <th>t2w_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>t2w_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glcm_MaximumProbability</th>\n",
       "      <th>sub_win_original_glcm_Imc1</th>\n",
       "      <th>sub_wout_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2535039</td>\n",
       "      <td>1</td>\n",
       "      <td>4.677862e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14835.837461</td>\n",
       "      <td>299.900214</td>\n",
       "      <td>3755.933491</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>...</td>\n",
       "      <td>6.339939</td>\n",
       "      <td>0.286470</td>\n",
       "      <td>10.166389</td>\n",
       "      <td>27423.571919</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>2946.837800</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.041978</td>\n",
       "      <td>10.452108</td>\n",
       "      <td>0.033786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2417361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.834267e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-17634.034850</td>\n",
       "      <td>299.918235</td>\n",
       "      <td>3941.494865</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.424770</td>\n",
       "      <td>0.350004</td>\n",
       "      <td>11.649157</td>\n",
       "      <td>21732.551407</td>\n",
       "      <td>0.604518</td>\n",
       "      <td>3322.225544</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.109242</td>\n",
       "      <td>11.891117</td>\n",
       "      <td>0.009861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2602563</td>\n",
       "      <td>1</td>\n",
       "      <td>5.159220e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-19736.430500</td>\n",
       "      <td>299.820687</td>\n",
       "      <td>2455.254084</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>...</td>\n",
       "      <td>7.239270</td>\n",
       "      <td>0.350692</td>\n",
       "      <td>10.919838</td>\n",
       "      <td>15567.069802</td>\n",
       "      <td>0.574356</td>\n",
       "      <td>3407.597573</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.194449</td>\n",
       "      <td>11.214368</td>\n",
       "      <td>0.018991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2902440</td>\n",
       "      <td>0</td>\n",
       "      <td>3.613791e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-12881.976888</td>\n",
       "      <td>299.240444</td>\n",
       "      <td>3954.079034</td>\n",
       "      <td>0.576021</td>\n",
       "      <td>...</td>\n",
       "      <td>7.454390</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>18389.243521</td>\n",
       "      <td>0.566131</td>\n",
       "      <td>3121.573712</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>11.669841</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2921898</td>\n",
       "      <td>0</td>\n",
       "      <td>5.773968e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2116.811733</td>\n",
       "      <td>299.983523</td>\n",
       "      <td>3793.819336</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.755170</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>9.504938</td>\n",
       "      <td>245786.779116</td>\n",
       "      <td>0.469149</td>\n",
       "      <td>3175.569089</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.058680</td>\n",
       "      <td>11.459667</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  sub_wout_original_glcm_ClusterProminence  \\\n",
       "0  2535039      1                              4.677862e+06   \n",
       "1  2417361      0                              4.834267e+06   \n",
       "2  2602563      1                              5.159220e+06   \n",
       "3  2902440      0                              3.613791e+06   \n",
       "4  2921898      0                              5.773968e+06   \n",
       "\n",
       "   adc_original_firstorder_Minimum  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              0.0   \n",
       "\n",
       "   sub_wout_original_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                          0.003103   \n",
       "1                                          0.001672   \n",
       "2                                          0.001600   \n",
       "3                                          0.002428   \n",
       "4                                          0.001720   \n",
       "\n",
       "   sub_wout_original_firstorder_Maximum  adc_original_glcm_ClusterShade  \\\n",
       "0                                 600.0                    14835.837461   \n",
       "1                                 600.0                   -17634.034850   \n",
       "2                                 600.0                   -19736.430500   \n",
       "3                                 600.0                   -12881.976888   \n",
       "4                                 600.0                     2116.811733   \n",
       "\n",
       "   sub_wout_original_firstorder_Mean  sub_win_original_glcm_Autocorrelation  \\\n",
       "0                         299.900214                            3755.933491   \n",
       "1                         299.918235                            3941.494865   \n",
       "2                         299.820687                            2455.254084   \n",
       "3                         299.240444                            3954.079034   \n",
       "4                         299.983523                            3793.819336   \n",
       "\n",
       "   adc_original_glszm_LargeAreaLowGrayLevelEmphasis  ...  \\\n",
       "0                                          0.010393  ...   \n",
       "1                                          0.058145  ...   \n",
       "2                                          0.019202  ...   \n",
       "3                                          0.576021  ...   \n",
       "4                                          0.011764  ...   \n",
       "\n",
       "   sub_win_original_glszm_ZoneEntropy  \\\n",
       "0                            6.339939   \n",
       "1                            7.424770   \n",
       "2                            7.239270   \n",
       "3                            7.454390   \n",
       "4                            6.755170   \n",
       "\n",
       "   t2w_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.286470    \n",
       "1                                           0.350004    \n",
       "2                                           0.350692    \n",
       "3                                           0.380537    \n",
       "4                                           0.265413    \n",
       "\n",
       "   t2w_original_glcm_JointEntropy  \\\n",
       "0                       10.166389   \n",
       "1                       11.649157   \n",
       "2                       10.919838   \n",
       "3                       11.530000   \n",
       "4                        9.504938   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                       27423.571919   \n",
       "1                                       21732.551407   \n",
       "2                                       15567.069802   \n",
       "3                                       18389.243521   \n",
       "4                                      245786.779116   \n",
       "\n",
       "   sub_win_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.461100        \n",
       "1                                           0.604518        \n",
       "2                                           0.574356        \n",
       "3                                           0.566131        \n",
       "4                                           0.469149        \n",
       "\n",
       "   sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                        2946.837800        \n",
       "1                                        3322.225544        \n",
       "2                                        3407.597573        \n",
       "3                                        3121.573712        \n",
       "4                                        3175.569089        \n",
       "\n",
       "   sub_win_original_glcm_MaximumProbability  sub_win_original_glcm_Imc1  \\\n",
       "0                                  0.034622                   -0.041978   \n",
       "1                                  0.002107                   -0.109242   \n",
       "2                                  0.004002                   -0.194449   \n",
       "3                                  0.004134                   -0.116415   \n",
       "4                                  0.027634                   -0.058680   \n",
       "\n",
       "   sub_wout_original_glcm_JointEntropy  \\\n",
       "0                            10.452108   \n",
       "1                            11.891117   \n",
       "2                            11.214368   \n",
       "3                            11.669841   \n",
       "4                            11.459667   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaLowGrayLevelEmphasis  \n",
       "0                                          0.033786  \n",
       "1                                          0.009861  \n",
       "2                                          0.018991  \n",
       "3                                          0.007846  \n",
       "4                                          0.024444  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd985de-47b7-40a1-83b3-14014e8efada",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = feats_df.id.to_numpy()\n",
    "labels = feats_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96a9d3-946f-4dc5-8051-6ba783ed4d20",
   "metadata": {},
   "source": [
    "### Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0ae46-b2b1-4d80-862f-0b501950455f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for repeat#- 1\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.858233\n",
      "b= 0 normal_mse= 1.1791519969701767 anomaly_mse= 0.9621249830180948 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.844762\n",
      "b= 1 normal_mse= 1.5179753466085955 anomaly_mse= 1.1140284463763237 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.910443\n",
      "b= 2 normal_mse= 1.4749388003891164 anomaly_mse= 1.114214164289561 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.547949\n",
      "b= 3 normal_mse= 0.9320521185343916 anomaly_mse= 0.8962696614590558 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862228\n",
      "b= 4 normal_mse= 0.8446477759968151 anomaly_mse= 0.8166338029232892 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879509\n",
      "b= 5 normal_mse= 1.145872019908645 anomaly_mse= 0.9841272072358564 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.848392\n",
      "b= 6 normal_mse= 0.7362019338391044 anomaly_mse= 0.7803209789774634 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862036\n",
      "b= 7 normal_mse= 0.9717232788150961 anomaly_mse= 0.8916920538653027 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.886457\n",
      "b= 8 normal_mse= 0.8013084016062997 anomaly_mse= 0.8448230854489587 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.916711\n",
      "b= 9 normal_mse= 1.1932000429792837 anomaly_mse= 0.9761344011534344 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879498\n",
      "b= 10 normal_mse= 0.7226112742315639 anomaly_mse= 0.7917525219646367 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.846272\n",
      "b= 11 normal_mse= 0.9468399692665447 anomaly_mse= 0.8578722537918524 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.875950\n",
      "b= 12 normal_mse= 1.1151896674524655 anomaly_mse= 0.9596276479688558 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.874094\n",
      "b= 13 normal_mse= 1.0047197314825924 anomaly_mse= 0.9143610339273106 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.877088\n",
      "b= 14 normal_mse= 0.9646243168549105 anomaly_mse= 0.9111883701248602 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.874241\n",
      "b= 15 normal_mse= 1.085450062697584 anomaly_mse= 0.9478930173949762 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.844835\n",
      "b= 16 normal_mse= 1.517899289727211 anomaly_mse= 1.1140577962452716 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.910497\n",
      "b= 17 normal_mse= 1.4749636311422696 anomaly_mse= 1.1142016635699705 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.871879\n",
      "b= 18 normal_mse= 0.9351065849716013 anomaly_mse= 0.8513492501594804 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.482233\n",
      "b= 19 normal_mse= 0.9268027225678618 anomaly_mse= 1.2158371047540144 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.463180\n",
      "b= 20 normal_mse= 0.9503223354166205 anomaly_mse= 1.026243113658645 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.848394\n",
      "b= 21 normal_mse= 0.7362298708070408 anomaly_mse= 0.7803039218891751 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862055\n",
      "b= 22 normal_mse= 0.9717362834648653 anomaly_mse= 0.8916868818077174 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.437106\n",
      "b= 23 normal_mse= 0.8868428130041469 anomaly_mse= 0.9507827650416981 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.916692\n",
      "b= 24 normal_mse= 1.1935198740525679 anomaly_mse= 0.9767651361497965 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879478\n",
      "b= 25 normal_mse= 0.7229736596345901 anomaly_mse= 0.791548719460314 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.568659\n",
      "b= 26 normal_mse= 0.9937146129933271 anomaly_mse= 0.852741314606233 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.875878\n",
      "b= 27 normal_mse= 1.1149945855140686 anomaly_mse= 0.959650648588484 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.874110\n",
      "b= 28 normal_mse= 1.0046912133693695 anomaly_mse= 0.91439615664157 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.877129\n",
      "b= 29 normal_mse= 0.9647512029517781 anomaly_mse= 0.9113145274194804 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.874231\n",
      "b= 30 normal_mse= 1.0854297226125544 anomaly_mse= 0.9478006559339437 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.481838\n",
      "b= 31 normal_mse= 1.6552779986099764 anomaly_mse= 1.2180019088766791 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.910483\n",
      "b= 32 normal_mse= 1.4750340160998432 anomaly_mse= 1.1142739003354853 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.585746\n",
      "b= 33 normal_mse= 0.9387116506695747 anomaly_mse= 0.8742522488940846 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.390982\n",
      "b= 34 normal_mse= 0.8588884574445811 anomaly_mse= 0.969060477885333 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.477803\n",
      "b= 35 normal_mse= 0.9911587678573348 anomaly_mse= 1.1473820101131091 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.848345\n",
      "b= 36 normal_mse= 0.7362137680703943 anomaly_mse= 0.7803660915656523 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862088\n",
      "b= 37 normal_mse= 0.9717220894315026 anomaly_mse= 0.8916751864281568 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.886509\n",
      "b= 38 normal_mse= 0.8013760014013811 anomaly_mse= 0.8447209379889749 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.916703\n",
      "b= 39 normal_mse= 1.1930983364582062 anomaly_mse= 0.9765522290359844 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879472\n",
      "b= 40 normal_mse= 0.7229707877744328 anomaly_mse= 0.7918896885080771 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.846220\n",
      "b= 41 normal_mse= 0.9468617046421225 anomaly_mse= 0.857873032038862 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.875939\n",
      "b= 42 normal_mse= 1.1163923984224147 anomaly_mse= 0.960253166204149 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.413384\n",
      "b= 43 normal_mse= 1.1021090773018924 anomaly_mse= 1.0935723144899716 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.877061\n",
      "b= 44 normal_mse= 0.9647258465940302 anomaly_mse= 0.9113377630710602 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.874235\n",
      "b= 45 normal_mse= 1.0864814533428713 anomaly_mse= 0.9482837068763647 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.844798\n",
      "b= 46 normal_mse= 1.5180136222730984 anomaly_mse= 1.1140321283177896 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.910491\n",
      "b= 47 normal_mse= 1.475009261207147 anomaly_mse= 1.1141599904407153 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.871822\n",
      "b= 48 normal_mse= 0.9354044551199133 anomaly_mse= 0.8516542552547022 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862191\n",
      "b= 49 normal_mse= 0.8446472422643141 anomaly_mse= 0.8167245970530943 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879506\n",
      "b= 50 normal_mse= 1.1458548984744332 anomaly_mse= 0.9841412610628388 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.848390\n",
      "b= 51 normal_mse= 0.7362330190160058 anomaly_mse= 0.780349266122688 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.460694\n",
      "b= 52 normal_mse= 0.9127488488500769 anomaly_mse= 0.8487378616224636 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.460874\n",
      "b= 53 normal_mse= 0.880748840895566 anomaly_mse= 0.9231632595712488 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.916693\n",
      "b= 54 normal_mse= 1.193635368211703 anomaly_mse= 0.976779774508693 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879491\n",
      "b= 55 normal_mse= 0.7229562428864565 anomaly_mse= 0.7919044596227732 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.846212\n",
      "b= 56 normal_mse= 0.9468622735955499 anomaly_mse= 0.8577675927769054 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.489432\n",
      "b= 57 normal_mse= 1.237671356309544 anomaly_mse= 1.065149807117202 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.870755\n",
      "b= 58 normal_mse= 1.0002688413316554 anomaly_mse= 0.9121060500090773 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.877083\n",
      "b= 59 normal_mse= 0.9647314805876125 anomaly_mse= 0.9112933413548903 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.874241\n",
      "b= 60 normal_mse= 1.0854572044177488 anomaly_mse= 0.9479060843586922 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.844776\n",
      "b= 61 normal_mse= 1.5177344666285948 anomaly_mse= 1.113965167240663 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.910446\n",
      "b= 62 normal_mse= 1.4750476018948988 anomaly_mse= 1.1143351170149716 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.871846\n",
      "b= 63 normal_mse= 0.9354528893123973 anomaly_mse= 0.8517616960135374 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.503315\n",
      "b= 64 normal_mse= 0.9407290707934987 anomaly_mse= 1.0117565786296672 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879507\n",
      "b= 65 normal_mse= 1.1459285725246777 anomaly_mse= 0.9840640703385527 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.848366\n",
      "b= 66 normal_mse= 0.7361932654272426 anomaly_mse= 0.7803444530476223 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862064\n",
      "b= 67 normal_mse= 0.9717482341961428 anomaly_mse= 0.8916935534639792 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.886471\n",
      "b= 68 normal_mse= 0.8013263642787933 anomaly_mse= 0.8448921936479482 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.916766\n",
      "b= 69 normal_mse= 1.1937227723273365 anomaly_mse= 0.9769415225494992 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879489\n",
      "b= 70 normal_mse= 0.722855269908905 anomaly_mse= 0.7919250699606809 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.735125\n",
      "b= 71 normal_mse= 0.946634522893212 anomaly_mse= 0.8389685953205283 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.875908\n",
      "b= 72 normal_mse= 1.1149093982848255 anomaly_mse= 0.9596286626024679 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.863863\n",
      "b= 73 normal_mse= 1.001002455299551 anomaly_mse= 0.9079769985242323 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.877113\n",
      "b= 74 normal_mse= 0.9646167971871116 anomaly_mse= 0.9112863804806363 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.458762\n",
      "b= 75 normal_mse= 0.9747272032228383 anomaly_mse= 0.951799754392017 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.551191\n",
      "b= 76 normal_mse= 1.5631242976947264 anomaly_mse= 1.2290124026211826 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.910453\n",
      "b= 77 normal_mse= 1.4750989783893933 anomaly_mse= 1.1143370230089535 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.871805\n",
      "b= 78 normal_mse= 0.9353914613073523 anomaly_mse= 0.8516915135762908 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.862196\n",
      "b= 79 normal_mse= 0.8446068059314381 anomaly_mse= 0.8165602948177945 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.879496\n",
      "b= 80 normal_mse= 1.145809237252582 anomaly_mse= 0.9841352904384787 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.451430\n",
      "b= 81 normal_mse= 1.0595097799192776 anomaly_mse= 0.8803506710312583 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.621543\n",
      "b= 82 normal_mse= 0.9510359466075897 anomaly_mse= 0.8887515393170443 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.886501\n",
      "b= 83 normal_mse= 0.8014186986468055 anomaly_mse= 0.8448862555352125 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.916715\n",
      "b= 84 normal_mse= 1.1936494281346148 anomaly_mse= 0.9768930707465519 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.879477\n",
      "b= 85 normal_mse= 0.7229438640854575 anomaly_mse= 0.7917954156344588 anomaly_mse>normal_mse= True\n",
      "Training complete in 0m 4s\n",
      "Best val Loss: 0.846264\n",
      "b= 86 normal_mse= 0.9468715028329329 anomaly_mse= 0.8579219335859473 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.527723\n",
      "b= 87 normal_mse= 1.0770207061008974 anomaly_mse= 0.9425382248379968 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.636158\n",
      "b= 88 normal_mse= 1.21925389631228 anomaly_mse= 1.0707135823639957 anomaly_mse>normal_mse= False\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.583243\n",
      "b= 89 normal_mse= 1.1126667579466647 anomaly_mse= 0.9955809753049504 anomaly_mse>normal_mse= False\n"
     ]
    }
   ],
   "source": [
    "feats = feats_df.columns[~feats_df.columns.isin(MASK_FEATS)].to_list()\n",
    "\n",
    "results_df = {**{\"outer_seed\":[], \"exe_time\":[], \"b\":[], \"permute_seed\":[], \"re_mean\":[]}, **{\"re_\"+feat:[] for feat in feats}, **{\"label\":[]}} # {**dict1, **dict2,...} is a way to merge multiple dictionaries\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for i in range(NUM_REPEATS):\n",
    "\n",
    "    print(f\"Running for repeat#- {i+1}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    num_epochs = 1_000\n",
    "    batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    lr = 1e-3\n",
    "    h_lambda = 1e-2 #with l1 regularization\n",
    "    \n",
    "    input_dim = len(feats)\n",
    "    latent_dim = 10\n",
    "    \n",
    "    activation_fn = nn.LeakyReLU()\n",
    "    encoder_layers = [50, 30, 20] #under-complete hidden layers\n",
    "\n",
    "    train_pids, test_pids, train_labels, test_labels = train_test_split(pids, labels, test_size=0.25, random_state=i, stratify=labels)\n",
    "\n",
    "    X =  feats_df[feats_df[\"id\"].isin(train_pids)][feats].to_numpy()\n",
    "    y = feats_df[feats_df[\"id\"].isin(train_pids)].label.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # X[X>=3] = 3\n",
    "    # X[X<=-3] = -3\n",
    "\n",
    "    X_norm, X_anomaly = utils.norm_anomaly_split(X, y)\n",
    "\n",
    "    for b in range(B):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        seed = np.random.randint(B)\n",
    "        np.random.seed(seed)\n",
    "        idx = np.random.permutation(len(X_norm))\n",
    "        \n",
    "        X_train= X_norm[idx[:-len(X_anomaly)]]\n",
    "        X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "        X_test_anomaly = X_anomaly\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_train[X_train>=3] = 3\n",
    "        X_train[X_train<=-3] = -3\n",
    "        \n",
    "        X_test_norm = scaler.transform(X_test_norm)\n",
    "        X_test_norm[X_test_norm>=3] = 3\n",
    "        X_test_norm[X_test_norm<=-3] = -3\n",
    "        \n",
    "        X_test_anomaly = scaler.transform(X_test_anomaly)\n",
    "        X_test_anomaly[X_test_anomaly>=3] = 3\n",
    "        X_test_anomaly[X_test_anomaly<=-3] = -3\n",
    "        \n",
    "        X_train =  torch.from_numpy(X_train).float()\n",
    "        X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "        X_test_anomaly = torch.from_numpy(X_test_anomaly).float()\n",
    "        X_test = torch.cat([X_test_norm, X_test_anomaly])\n",
    "    \n",
    "        train_ds = utils.Dataset(X_train)\n",
    "        val_ds = utils.Dataset(X_train)\n",
    "        dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "        \n",
    "        dsae = utils.Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "        model = utils.Model(dsae)\n",
    "        model.compile(lr, h_lambda, loss_fn, cuda_device_id=1)\n",
    "        _ = model.fit(dls, num_epochs, verbose=False)\n",
    "\n",
    "        exe_time = time.time() - start_time\n",
    "    \n",
    "        recon_X_test_norm, h_norm = model.net(X_test_norm)\n",
    "        recon_X_test_anomaly, h_anomaly = model.net(X_test_anomaly)\n",
    "        \n",
    "        recon_X_test = torch.cat([recon_X_test_norm, recon_X_test_anomaly])\n",
    "        y_test = torch.cat([torch.zeros(len(recon_X_test_norm)), torch.ones(len(recon_X_test_anomaly))])\n",
    "\n",
    "        re_test = nn.MSELoss(reduction=\"none\")(recon_X_test, X_test)\n",
    "\n",
    "        \n",
    "        for re_row, label in zip(re_test, y_test):\n",
    "            results_df[\"outer_seed\"].append(i)\n",
    "            results_df[\"exe_time\"].append(exe_time)\n",
    "            results_df[\"b\"].append(b)\n",
    "            results_df[\"permute_seed\"].append(seed)\n",
    "            results_df[\"re_mean\"].append(re_row.mean().item())\n",
    "    \n",
    "            for feat, re_feat in zip(feats, re_row):\n",
    "                results_df[\"re_\"+feat].append(re_feat.item())\n",
    "    \n",
    "            results_df[\"label\"].append(label.item())\n",
    "\n",
    "        _df = pd.DataFrame(results_df)\n",
    "        grp_mean_df = _df[(_df.outer_seed==i)&(_df.b==b)].groupby(by=[\"label\"]).mean()\n",
    "\n",
    "        print(\"b=\", b, \"normal_mse=\",grp_mean_df.loc[0].re_mean, \"anomaly_mse=\", grp_mean_df.loc[1].re_mean, \"anomaly_mse>normal_mse=\", grp_mean_df.loc[1].re_mean>grp_mean_df.loc[0].re_mean)\n",
    "       \n",
    "        \n",
    "    _df = pd.DataFrame(results_df)\n",
    "    grp_mean_df = _df[_df.outer_seed==i].groupby(by=[\"label\"]).mean()\n",
    "    \n",
    "    print(\"normal_mse=\",grp_mean_df.loc[0].re_mean, \"anomaly_mse=\", grp_mean_df.loc[1].re_mean, \"anomaly_mse>normal_mse=\", grp_mean_df.loc[1].re_mean>grp_mean_df.loc[0].re_mean)\n",
    "\n",
    "    grp_mean_df = grp_mean_df[[\"re_\"+feat for feat in feats]]\n",
    "    delta = grp_mean_df.loc[1] - grp_mean_df.loc[0]\n",
    "\n",
    "    rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "    rank_df = pd.DataFrame({\"feature\":feats, \"rank\":rank})\n",
    "    rank_df.to_csv(os.path.join(OUT_DIR, f\"rank_df{i}.csv\"), index=False)\n",
    "    \n",
    "results_df = pd.DataFrame(results_df) \n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"results_df.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
