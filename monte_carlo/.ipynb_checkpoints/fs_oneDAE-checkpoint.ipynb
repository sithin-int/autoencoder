{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b54003-83d4-4e49-bc27-639bf5e0e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils as utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e2f99-9a00-49e9-b816-32a704ed876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"inputs/radiomicsFeatures.csv\"\n",
    "OUT_DIR = r\"outputs/oneDSAE\"\n",
    "MASK_FEATS = [\"id\", \"label\"]\n",
    "\n",
    "NUM_REPEATS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7772f5-6eb3-4748-bf66-1528e9d8b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7db66-a4d3-4a87-ba00-1ee6878852f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = feats_df.id.to_numpy()\n",
    "labels = feats_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b7a02-3bc1-474b-ba32-8be75ab9ceb1",
   "metadata": {},
   "source": [
    "### Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ea514-c68e-4faa-b273-5430c3631f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats = feats_df.columns[~feats_df.columns.isin(MASK_FEATS)].to_list()\n",
    "\n",
    "results_df = {**{\"outer_seed\":[], \"exe_time\":[] \"re_mean\":[]}, **{\"re_\"+feat:[] for feat in feats}, **{\"label\":[]}} # {**dict1, **dict2,...} is a way to merge multiple dictionaries\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for i in range(NUM_REPEATS):\n",
    "\n",
    "    print(f\"Running for repeat#- {i+1}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_epochs = 1_000\n",
    "    batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    lr = 1e-3\n",
    "    h_lambda = 1e-2 #with l1 regularization\n",
    "    \n",
    "    input_dim = len(feats)\n",
    "    latent_dim = 10\n",
    "    \n",
    "    activation_fn = nn.LeakyReLU()\n",
    "    encoder_layers = [50, 30, 20] #under-complete hidden layers\n",
    "\n",
    "    train_pids, test_pids, train_labels, test_labels = train_test_split(pids, labels, test_size=0.25, random_state=i, stratify=labels)\n",
    "\n",
    "    \n",
    "    X =  feats_df[feats_df[\"id\"].isin(train_pids)][feats].to_numpy()\n",
    "    y = feats_df[feats_df[\"id\"].isin(train_pids)].label.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # X[X>=3] = 3\n",
    "    # X[X<=-3] = -3\n",
    "\n",
    "    X_norm, X_anomaly = utils.norm_anomaly_split(X, y)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    idx = np.random.permutation(len(X_norm))\n",
    "    \n",
    "    X_train= X_norm[idx[:-len(X_anomaly)]]\n",
    "    X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "    X_test_anomaly = X_anomaly\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train[X_train>=3] = 3\n",
    "    X_train[X_train<=-3] = -3\n",
    "    \n",
    "    X_test_norm = scaler.transform(X_test_norm)\n",
    "    X_test_norm[X_test_norm>=3] = 3\n",
    "    X_test_norm[X_test_norm<=-3] = -3\n",
    "    \n",
    "    X_test_anomaly = scaler.transform(X_test_anomaly)\n",
    "    X_test_anomaly[X_test_anomaly>=3] = 3\n",
    "    X_test_anomaly[X_test_anomaly<=-3] = -3\n",
    "    \n",
    "    \n",
    "    X_train =  torch.from_numpy(X_train).float()\n",
    "   \n",
    "    X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "    X_test_anomaly = torch.from_numpy(X_test_anomaly).float()\n",
    "    X_test = torch.cat([X_test_norm, X_test_anomaly])\n",
    "\n",
    "    train_ds = utils.Dataset(X_train)\n",
    "    val_ds = utils.Dataset(X_train)\n",
    "    dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "    \n",
    "    dsae = utils.Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "    model = utils.Model(dsae)\n",
    "    model.compile(lr, h_lambda, loss_fn)\n",
    "    _ = model.fit(dls, num_epochs, verbose=False)\n",
    "\n",
    "    recon_X_test_norm, h_norm = model.net(X_test_norm)\n",
    "    recon_X_test_anomaly, h_anomaly = model.net(X_test_anomaly)\n",
    "\n",
    "    recon_X_test = torch.cat([recon_X_test_norm, recon_X_test_anomaly])\n",
    "    y_test = torch.cat([torch.zeros(len(recon_X_test_norm)), torch.ones(len(recon_X_test_anomaly))])\n",
    "    \n",
    "    re_test = nn.MSELoss(reduction=\"none\")(recon_X_test, X_test)\n",
    "\n",
    "    exe_time = time.time()-start_time\n",
    "    \n",
    "    for re_row, label in zip(re_test, y_test):\n",
    "        results_df[\"outer_seed\"].append(i)\n",
    "        results_df[\"exe_time\"].append(exe_time)\n",
    "        results_df[\"re_mean\"].append(re_row.mean().item())\n",
    "\n",
    "        for feat, re_feat in zip(feats, re_row):\n",
    "            results_df[\"re_\"+feat].append(re_feat.item())\n",
    "\n",
    "        results_df[\"label\"].append(label.item())\n",
    "\n",
    "    _df = pd.DataFrame(results_df)\n",
    "    grp_mean_df = _df[_df.outer_seed==i].groupby(by=[\"label\"]).mean()\n",
    "\n",
    "    print(\"normal_mse=\",grp_mean_df.loc[0].re_mean, \"anomaly_mse=\", grp_mean_df.loc[1].re_mean, \"anomaly_mse>normal_mse=\", grp_mean_df.loc[1].re_mean>grp_mean_df.loc[0].re_mean)\n",
    "\n",
    "    grp_mean_df = grp_mean_df[[\"re_\"+feat for feat in feats]]\n",
    "    delta = grp_mean_df.loc[1] - grp_mean_df.loc[0]\n",
    "\n",
    "    rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "    rank_df = pd.DataFrame({\"feature\":feats, \"rank\":rank})\n",
    "    rank_df.to_csv(os.path.join(OUT_DIR, f\"rank_df{i}.csv\"), index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "results_df = pd.DataFrame(results_df) \n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"results_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcf544-f2db-4e84-a733-3e30488ceab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
