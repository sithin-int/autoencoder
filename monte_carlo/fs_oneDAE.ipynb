{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b54003-83d4-4e49-bc27-639bf5e0e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils as utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e2f99-9a00-49e9-b816-32a704ed876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"inputs/radiomicsFeatures.csv\"\n",
    "OUT_DIR = r\"outputs/oneDAE\"\n",
    "MASK_FEATS = [\"id\", \"label\"]\n",
    "\n",
    "NUM_REPEATS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7772f5-6eb3-4748-bf66-1528e9d8b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_wout_original_glcm_ClusterProminence</th>\n",
       "      <th>adc_original_firstorder_Minimum</th>\n",
       "      <th>sub_wout_original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>sub_wout_original_firstorder_Maximum</th>\n",
       "      <th>adc_original_glcm_ClusterShade</th>\n",
       "      <th>sub_wout_original_firstorder_Mean</th>\n",
       "      <th>sub_win_original_glcm_Autocorrelation</th>\n",
       "      <th>adc_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_win_original_glszm_ZoneEntropy</th>\n",
       "      <th>t2w_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>t2w_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glcm_MaximumProbability</th>\n",
       "      <th>sub_win_original_glcm_Imc1</th>\n",
       "      <th>sub_wout_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2535039</td>\n",
       "      <td>1</td>\n",
       "      <td>4.677862e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14835.837461</td>\n",
       "      <td>299.900214</td>\n",
       "      <td>3755.933491</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>...</td>\n",
       "      <td>6.339939</td>\n",
       "      <td>0.286470</td>\n",
       "      <td>10.166389</td>\n",
       "      <td>27423.571919</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>2946.837800</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.041978</td>\n",
       "      <td>10.452108</td>\n",
       "      <td>0.033786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2417361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.834267e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-17634.034850</td>\n",
       "      <td>299.918235</td>\n",
       "      <td>3941.494865</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.424770</td>\n",
       "      <td>0.350004</td>\n",
       "      <td>11.649157</td>\n",
       "      <td>21732.551407</td>\n",
       "      <td>0.604518</td>\n",
       "      <td>3322.225544</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.109242</td>\n",
       "      <td>11.891117</td>\n",
       "      <td>0.009861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2602563</td>\n",
       "      <td>1</td>\n",
       "      <td>5.159220e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-19736.430500</td>\n",
       "      <td>299.820687</td>\n",
       "      <td>2455.254084</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>...</td>\n",
       "      <td>7.239270</td>\n",
       "      <td>0.350692</td>\n",
       "      <td>10.919838</td>\n",
       "      <td>15567.069802</td>\n",
       "      <td>0.574356</td>\n",
       "      <td>3407.597573</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.194449</td>\n",
       "      <td>11.214368</td>\n",
       "      <td>0.018991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2902440</td>\n",
       "      <td>0</td>\n",
       "      <td>3.613791e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-12881.976888</td>\n",
       "      <td>299.240444</td>\n",
       "      <td>3954.079034</td>\n",
       "      <td>0.576021</td>\n",
       "      <td>...</td>\n",
       "      <td>7.454390</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>18389.243521</td>\n",
       "      <td>0.566131</td>\n",
       "      <td>3121.573712</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>11.669841</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2921898</td>\n",
       "      <td>0</td>\n",
       "      <td>5.773968e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2116.811733</td>\n",
       "      <td>299.983523</td>\n",
       "      <td>3793.819336</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.755170</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>9.504938</td>\n",
       "      <td>245786.779116</td>\n",
       "      <td>0.469149</td>\n",
       "      <td>3175.569089</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.058680</td>\n",
       "      <td>11.459667</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  sub_wout_original_glcm_ClusterProminence  \\\n",
       "0  2535039      1                              4.677862e+06   \n",
       "1  2417361      0                              4.834267e+06   \n",
       "2  2602563      1                              5.159220e+06   \n",
       "3  2902440      0                              3.613791e+06   \n",
       "4  2921898      0                              5.773968e+06   \n",
       "\n",
       "   adc_original_firstorder_Minimum  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              0.0   \n",
       "\n",
       "   sub_wout_original_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                          0.003103   \n",
       "1                                          0.001672   \n",
       "2                                          0.001600   \n",
       "3                                          0.002428   \n",
       "4                                          0.001720   \n",
       "\n",
       "   sub_wout_original_firstorder_Maximum  adc_original_glcm_ClusterShade  \\\n",
       "0                                 600.0                    14835.837461   \n",
       "1                                 600.0                   -17634.034850   \n",
       "2                                 600.0                   -19736.430500   \n",
       "3                                 600.0                   -12881.976888   \n",
       "4                                 600.0                     2116.811733   \n",
       "\n",
       "   sub_wout_original_firstorder_Mean  sub_win_original_glcm_Autocorrelation  \\\n",
       "0                         299.900214                            3755.933491   \n",
       "1                         299.918235                            3941.494865   \n",
       "2                         299.820687                            2455.254084   \n",
       "3                         299.240444                            3954.079034   \n",
       "4                         299.983523                            3793.819336   \n",
       "\n",
       "   adc_original_glszm_LargeAreaLowGrayLevelEmphasis  ...  \\\n",
       "0                                          0.010393  ...   \n",
       "1                                          0.058145  ...   \n",
       "2                                          0.019202  ...   \n",
       "3                                          0.576021  ...   \n",
       "4                                          0.011764  ...   \n",
       "\n",
       "   sub_win_original_glszm_ZoneEntropy  \\\n",
       "0                            6.339939   \n",
       "1                            7.424770   \n",
       "2                            7.239270   \n",
       "3                            7.454390   \n",
       "4                            6.755170   \n",
       "\n",
       "   t2w_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.286470    \n",
       "1                                           0.350004    \n",
       "2                                           0.350692    \n",
       "3                                           0.380537    \n",
       "4                                           0.265413    \n",
       "\n",
       "   t2w_original_glcm_JointEntropy  \\\n",
       "0                       10.166389   \n",
       "1                       11.649157   \n",
       "2                       10.919838   \n",
       "3                       11.530000   \n",
       "4                        9.504938   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                       27423.571919   \n",
       "1                                       21732.551407   \n",
       "2                                       15567.069802   \n",
       "3                                       18389.243521   \n",
       "4                                      245786.779116   \n",
       "\n",
       "   sub_win_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.461100        \n",
       "1                                           0.604518        \n",
       "2                                           0.574356        \n",
       "3                                           0.566131        \n",
       "4                                           0.469149        \n",
       "\n",
       "   sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                        2946.837800        \n",
       "1                                        3322.225544        \n",
       "2                                        3407.597573        \n",
       "3                                        3121.573712        \n",
       "4                                        3175.569089        \n",
       "\n",
       "   sub_win_original_glcm_MaximumProbability  sub_win_original_glcm_Imc1  \\\n",
       "0                                  0.034622                   -0.041978   \n",
       "1                                  0.002107                   -0.109242   \n",
       "2                                  0.004002                   -0.194449   \n",
       "3                                  0.004134                   -0.116415   \n",
       "4                                  0.027634                   -0.058680   \n",
       "\n",
       "   sub_wout_original_glcm_JointEntropy  \\\n",
       "0                            10.452108   \n",
       "1                            11.891117   \n",
       "2                            11.214368   \n",
       "3                            11.669841   \n",
       "4                            11.459667   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaLowGrayLevelEmphasis  \n",
       "0                                          0.033786  \n",
       "1                                          0.009861  \n",
       "2                                          0.018991  \n",
       "3                                          0.007846  \n",
       "4                                          0.024444  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c7db66-a4d3-4a87-ba00-1ee6878852f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = feats_df.id.to_numpy()\n",
    "labels = feats_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b7a02-3bc1-474b-ba32-8be75ab9ceb1",
   "metadata": {},
   "source": [
    "### Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451ea514-c68e-4faa-b273-5430c3631f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for repeat#- 1\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 6s\n",
      "Best val Loss: 0.000441\n",
      "normal_mse= 0.8289259712804448 anomaly_mse= 0.818874447860501 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 2\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000025\n",
      "normal_mse= 1.1194339719685642 anomaly_mse= 1.0576902004805477 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 3\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000031\n",
      "normal_mse= 0.7053562561896715 anomaly_mse= 0.79098146002401 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 4\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000134\n",
      "normal_mse= 0.9869487495584921 anomaly_mse= 1.2362009151415392 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 5\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001083\n",
      "normal_mse= 0.9954227290370248 anomaly_mse= 1.1202130805362354 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 6\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000184\n",
      "normal_mse= 1.2387618842450054 anomaly_mse= 1.2292040193622762 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 7\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000043\n",
      "normal_mse= 1.0246823728084564 anomaly_mse= 0.954436559568752 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 8\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001235\n",
      "normal_mse= 1.0289040634577924 anomaly_mse= 0.9340660003098574 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 9\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000316\n",
      "normal_mse= 0.8659627545963634 anomaly_mse= 0.8151633102785457 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 10\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000094\n",
      "normal_mse= 1.1273743523792787 anomaly_mse= 0.7859707948836413 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 11\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000539\n",
      "normal_mse= 0.7908084277402271 anomaly_mse= 0.764051692052321 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 12\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000189\n",
      "normal_mse= 0.62904738296162 anomaly_mse= 0.867610367861661 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 13\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000777\n",
      "normal_mse= 1.036383297633041 anomaly_mse= 1.0873838737607002 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 14\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000244\n",
      "normal_mse= 1.0556546679951928 anomaly_mse= 1.3080658966844732 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 15\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000766\n",
      "normal_mse= 0.6932269382205877 anomaly_mse= 0.889267386360602 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 16\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000629\n",
      "normal_mse= 0.9892011115496809 anomaly_mse= 0.9093352657827464 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 17\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000380\n",
      "normal_mse= 0.6267310252243822 anomaly_mse= 0.818018754774874 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 18\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.003461\n",
      "normal_mse= 0.9128773835572329 anomaly_mse= 1.046688434752551 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 19\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.002432\n",
      "normal_mse= 0.7931207052685998 anomaly_mse= 0.9363012686371803 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 20\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.002721\n",
      "normal_mse= 0.8081408508799293 anomaly_mse= 0.8419938500631939 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 21\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000705\n",
      "normal_mse= 0.5305217098106038 anomaly_mse= 0.8011050210757689 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 22\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000352\n",
      "normal_mse= 0.7956086959351193 anomaly_mse= 0.8591408675367181 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 23\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000593\n",
      "normal_mse= 0.6374843432144686 anomaly_mse= 0.7646895084868778 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 24\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000748\n",
      "normal_mse= 0.6882551678202369 anomaly_mse= 1.0654183707453988 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 25\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001619\n",
      "normal_mse= 1.1246131787245923 anomaly_mse= 0.9435213093053211 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 26\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000225\n",
      "normal_mse= 0.7001334103670988 anomaly_mse= 0.8296061998063867 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 27\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.002137\n",
      "normal_mse= 0.9981107352809473 anomaly_mse= 0.8953227915547111 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 28\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.002910\n",
      "normal_mse= 0.661862774328752 anomaly_mse= 0.7142990908839486 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 29\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000744\n",
      "normal_mse= 0.6074280034412037 anomaly_mse= 0.6887399716810747 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 30\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000141\n",
      "normal_mse= 0.6910334960980848 anomaly_mse= 0.8227932466702028 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 31\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000462\n",
      "normal_mse= 0.8058527538722212 anomaly_mse= 0.7143106785687533 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 32\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000815\n",
      "normal_mse= 0.6975348219275475 anomaly_mse= 0.7005155770616098 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 33\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001868\n",
      "normal_mse= 0.7417487935586409 anomaly_mse= 0.8608184883540327 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 34\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000188\n",
      "normal_mse= 0.6422976038672707 anomaly_mse= 0.8127113607796755 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 35\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000137\n",
      "normal_mse= 0.845414397391406 anomaly_mse= 0.8358058455315504 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 36\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000356\n",
      "normal_mse= 0.8033273843201724 anomaly_mse= 0.8920588777823881 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 37\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001673\n",
      "normal_mse= 0.7079627527432009 anomaly_mse= 0.9126176685094833 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 38\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000732\n",
      "normal_mse= 0.7100182344967668 anomaly_mse= 0.7357643673365767 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 39\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000587\n",
      "normal_mse= 0.9240719892761924 anomaly_mse= 1.149387388066812 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 40\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.004387\n",
      "normal_mse= 0.8133595714514906 anomaly_mse= 0.9567347019910812 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 41\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001209\n",
      "normal_mse= 0.6809050860730085 anomaly_mse= 0.7651722959496758 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 42\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.003637\n",
      "normal_mse= 0.9221592017195441 anomaly_mse= 0.9100316153331236 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 43\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001988\n",
      "normal_mse= 0.8647997690872713 anomaly_mse= 0.8660006468946283 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 44\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001504\n",
      "normal_mse= 0.6718779829415408 anomaly_mse= 0.834160640835762 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 45\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000233\n",
      "normal_mse= 0.7039785588329489 anomaly_mse= 0.7467776509848508 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 46\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000298\n",
      "normal_mse= 0.5366435301574793 anomaly_mse= 0.7479805275797844 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 47\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000066\n",
      "normal_mse= 0.7080199874260209 anomaly_mse= 0.7626833509315144 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 48\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001109\n",
      "normal_mse= 0.7587224543094635 anomaly_mse= 0.8736888834021308 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 49\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000287\n",
      "normal_mse= 0.9847243685613979 anomaly_mse= 0.9449627900665457 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 50\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000570\n",
      "normal_mse= 0.670239465480501 anomaly_mse= 0.66593092138117 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 51\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000488\n",
      "normal_mse= 0.5502635721455921 anomaly_mse= 0.7678193030032244 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 52\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001457\n",
      "normal_mse= 0.6947859532453797 anomaly_mse= 0.7334798723459244 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 53\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000250\n",
      "normal_mse= 0.7280608598481525 anomaly_mse= 0.8544762378389185 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 54\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.003952\n",
      "normal_mse= 0.7363315590403297 anomaly_mse= 0.9773569865660234 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 55\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001351\n",
      "normal_mse= 1.0746277922933751 anomaly_mse= 0.9127845588055524 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 56\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000138\n",
      "normal_mse= 1.0373607989061961 anomaly_mse= 0.9074527702548287 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 57\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001067\n",
      "normal_mse= 0.6290027661757036 anomaly_mse= 0.7386765331029892 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 58\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000455\n",
      "normal_mse= 0.7087553902105852 anomaly_mse= 0.7306776317683134 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 59\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000234\n",
      "normal_mse= 1.1861792220310732 anomaly_mse= 1.2609787691723218 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 60\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000234\n",
      "normal_mse= 0.7384820729494095 anomaly_mse= 0.8869733607227152 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 61\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000269\n",
      "normal_mse= 0.8475862111557614 anomaly_mse= 0.8181938989595934 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 62\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001569\n",
      "normal_mse= 0.8027065890756521 anomaly_mse= 0.7802546823566611 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 63\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.002406\n",
      "normal_mse= 1.154215121133761 anomaly_mse= 0.977887557988817 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 64\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000169\n",
      "normal_mse= 1.2220002304423938 anomaly_mse= 0.9514982117847963 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 65\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.004235\n",
      "normal_mse= 0.6985777860338037 anomaly_mse= 1.0187665752389214 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 66\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001871\n",
      "normal_mse= 0.8672824305566874 anomaly_mse= 1.0325261225754565 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 67\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.004304\n",
      "normal_mse= 0.7795774008740078 anomaly_mse= 0.9563764387911017 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 68\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000952\n",
      "normal_mse= 0.7620415931398218 anomaly_mse= 0.7896670211445201 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 69\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000446\n",
      "normal_mse= 0.7962654720653187 anomaly_mse= 0.9021652733737772 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 70\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000592\n",
      "normal_mse= 0.9240475676276467 anomaly_mse= 0.8220473873344335 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 71\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.003189\n",
      "normal_mse= 0.8834473612633619 anomaly_mse= 1.1228975281119347 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 72\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000993\n",
      "normal_mse= 0.7900054949251089 anomaly_mse= 0.7709389579567042 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 73\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000504\n",
      "normal_mse= 1.0200822244990955 anomaly_mse= 1.0375811037692158 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 74\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001816\n",
      "normal_mse= 0.982696229761297 anomaly_mse= 0.912941684099761 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 75\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000452\n",
      "normal_mse= 0.6657521785660223 anomaly_mse= 0.7666960033503446 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 76\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.008464\n",
      "normal_mse= 1.046949410980398 anomaly_mse= 1.1144516291943463 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 77\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000732\n",
      "normal_mse= 0.9650587385351007 anomaly_mse= 0.7370518486608159 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 78\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000397\n",
      "normal_mse= 0.9817027679898522 anomaly_mse= 0.8831054398959334 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 79\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001894\n",
      "normal_mse= 0.7653680768879977 anomaly_mse= 0.934823911298405 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 80\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000557\n",
      "normal_mse= 0.7068221061067148 anomaly_mse= 0.7766714637929742 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 81\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001983\n",
      "normal_mse= 0.8170011822472919 anomaly_mse= 1.0589685020121662 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 82\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000138\n",
      "normal_mse= 1.3100229623642834 anomaly_mse= 1.3993464586409656 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 83\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.002164\n",
      "normal_mse= 0.855078705332496 anomaly_mse= 0.9599678733132102 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 84\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.003538\n",
      "normal_mse= 0.9756533645770766 anomaly_mse= 1.0225838314403186 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 85\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000255\n",
      "normal_mse= 1.0700428133661097 anomaly_mse= 1.2121128345077687 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 86\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.003716\n",
      "normal_mse= 0.5719180039384149 anomaly_mse= 0.710035654631528 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 87\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000036\n",
      "normal_mse= 0.683647633953528 anomaly_mse= 0.8148396109992807 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 88\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001844\n",
      "normal_mse= 0.7851366211067546 anomaly_mse= 0.7907783348451961 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 89\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001367\n",
      "normal_mse= 0.5562342445958744 anomaly_mse= 0.6884974762797356 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 90\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000626\n",
      "normal_mse= 0.8214786736802622 anomaly_mse= 0.9388190291144631 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 91\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001470\n",
      "normal_mse= 1.0052905976772308 anomaly_mse= 1.1026804433627562 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 92\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001981\n",
      "normal_mse= 0.7459380572492426 anomaly_mse= 0.8203870891170069 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 93\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001160\n",
      "normal_mse= 1.2131125385111028 anomaly_mse= 0.8346938775344328 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 94\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001915\n",
      "normal_mse= 0.8173747394572605 anomaly_mse= 0.8046977486122738 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 95\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000478\n",
      "normal_mse= 0.751883865757422 anomaly_mse= 0.8297942240129818 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 96\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001055\n",
      "normal_mse= 0.7403034561059691 anomaly_mse= 0.8196624998341907 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 97\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.006208\n",
      "normal_mse= 0.7947152690453962 anomaly_mse= 1.0374186140569774 anomaly_mse>normal_mse= True\n",
      "Running for repeat#- 98\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001418\n",
      "normal_mse= 1.0240673944354057 anomaly_mse= 0.9312645386565815 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 99\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.000616\n",
      "normal_mse= 0.8649347952821038 anomaly_mse= 0.853679128668525 anomaly_mse>normal_mse= False\n",
      "Running for repeat#- 100\n",
      "--------------------------------------------------\n",
      "Training complete in 0m 5s\n",
      "Best val Loss: 0.001028\n",
      "normal_mse= 0.8672333908351985 anomaly_mse= 0.9227093790065158 anomaly_mse>normal_mse= True\n"
     ]
    }
   ],
   "source": [
    "feats = feats_df.columns[~feats_df.columns.isin(MASK_FEATS)].to_list()\n",
    "\n",
    "results_df = {**{\"outer_seed\":[], \"exe_time\":[], \"re_mean\":[]}, **{\"re_\"+feat:[] for feat in feats}, **{\"label\":[]}} # {**dict1, **dict2,...} is a way to merge multiple dictionaries\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for i in range(NUM_REPEATS):\n",
    "\n",
    "    print(f\"Running for repeat#- {i+1}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_epochs = 1_000\n",
    "    batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    lr = 1e-3\n",
    "    h_lambda = 0 #with no l1 regularization, to make it behave like a normal AE\n",
    "    \n",
    "    input_dim = len(feats)\n",
    "    latent_dim = 10\n",
    "    \n",
    "    activation_fn = nn.LeakyReLU()\n",
    "    encoder_layers = [50, 30, 20] #under-complete hidden layers\n",
    "\n",
    "    train_pids, test_pids, train_labels, test_labels = train_test_split(pids, labels, test_size=0.25, random_state=i, stratify=labels)\n",
    "\n",
    "    \n",
    "    X =  feats_df[feats_df[\"id\"].isin(train_pids)][feats].to_numpy()\n",
    "    y = feats_df[feats_df[\"id\"].isin(train_pids)].label.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # X[X>=3] = 3\n",
    "    # X[X<=-3] = -3\n",
    "\n",
    "    X_norm, X_anomaly = utils.norm_anomaly_split(X, y)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    idx = np.random.permutation(len(X_norm))\n",
    "    \n",
    "    X_train= X_norm[idx[:-len(X_anomaly)]]\n",
    "    X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "    X_test_anomaly = X_anomaly\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train[X_train>=3] = 3\n",
    "    X_train[X_train<=-3] = -3\n",
    "    \n",
    "    X_test_norm = scaler.transform(X_test_norm)\n",
    "    X_test_norm[X_test_norm>=3] = 3\n",
    "    X_test_norm[X_test_norm<=-3] = -3\n",
    "    \n",
    "    X_test_anomaly = scaler.transform(X_test_anomaly)\n",
    "    X_test_anomaly[X_test_anomaly>=3] = 3\n",
    "    X_test_anomaly[X_test_anomaly<=-3] = -3\n",
    "    \n",
    "    \n",
    "    X_train =  torch.from_numpy(X_train).float()\n",
    "   \n",
    "    X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "    X_test_anomaly = torch.from_numpy(X_test_anomaly).float()\n",
    "    X_test = torch.cat([X_test_norm, X_test_anomaly])\n",
    "\n",
    "    train_ds = utils.Dataset(X_train)\n",
    "    val_ds = utils.Dataset(X_train)\n",
    "    dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "    \n",
    "    dae = utils.Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "    model = utils.Model(dae)\n",
    "    model.compile(lr, h_lambda, loss_fn, cuda_device_id=1)\n",
    "    _ = model.fit(dls, num_epochs, verbose=False)\n",
    "\n",
    "    exe_time = time.time()-start_time\n",
    "\n",
    "    recon_X_test_norm, h_norm = model.net(X_test_norm)\n",
    "    recon_X_test_anomaly, h_anomaly = model.net(X_test_anomaly)\n",
    "\n",
    "    recon_X_test = torch.cat([recon_X_test_norm, recon_X_test_anomaly])\n",
    "    y_test = torch.cat([torch.zeros(len(recon_X_test_norm)), torch.ones(len(recon_X_test_anomaly))])\n",
    "    \n",
    "    re_test = nn.MSELoss(reduction=\"none\")(recon_X_test, X_test)\n",
    "    \n",
    "    for re_row, label in zip(re_test, y_test):\n",
    "        results_df[\"outer_seed\"].append(i)\n",
    "        results_df[\"exe_time\"].append(exe_time)\n",
    "        results_df[\"re_mean\"].append(re_row.mean().item())\n",
    "\n",
    "        for feat, re_feat in zip(feats, re_row):\n",
    "            results_df[\"re_\"+feat].append(re_feat.item())\n",
    "\n",
    "        results_df[\"label\"].append(label.item())\n",
    "\n",
    "    _df = pd.DataFrame(results_df)\n",
    "    grp_mean_df = _df[_df.outer_seed==i].groupby(by=[\"label\"]).mean()\n",
    "\n",
    "    print(\"normal_mse=\",grp_mean_df.loc[0].re_mean, \"anomaly_mse=\", grp_mean_df.loc[1].re_mean, \"anomaly_mse>normal_mse=\", grp_mean_df.loc[1].re_mean>grp_mean_df.loc[0].re_mean)\n",
    "\n",
    "    grp_mean_df = grp_mean_df[[\"re_\"+feat for feat in feats]]\n",
    "    delta = grp_mean_df.loc[1] - grp_mean_df.loc[0]\n",
    "\n",
    "    rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "    rank_df = pd.DataFrame({\"feature\":feats, \"rank\":rank})\n",
    "    rank_df.to_csv(os.path.join(OUT_DIR, f\"rank_df{i}.csv\"), index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "results_df = pd.DataFrame(results_df) \n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"results_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcf544-f2db-4e84-a733-3e30488ceab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
