{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43875eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") #to access custom \"utils\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d3e746-9155-41d1-9a52-5bbde24c84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import utils.similarity_index as similarity_index\n",
    "from scipy import stats\n",
    "import statsmodels as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5ded9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68162b6f-a11a-4abb-a600-eb987f5ea5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = os.path.join(\"..\", r\"scripts/outputs\")\n",
    "XL_PATH = os.path.join(\"..\", r\"inputs/radiomicsFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311eb5b9-6ec9-4282-9130-ed079cde0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats = 100\n",
    "\n",
    "feats_df = pd.read_csv(XL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c1a275-0277-4158-83ad-403e75c40fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cfa7a573c745528c12bf9e3d098f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stability_df = {\"fs_method\":[], \"similarity_measure\":[], \"top_k\":[], \"estimate\":[]}\n",
    "\n",
    "fs_methods = [\"random\", \"oneDSAE\", \"bayesianDSAE\", \"ensembleDSAE\", \"backwardSFS/LogisticRegression\", \"backwardSFS/SVC\", \"backwardSFS/RandomForestClassifier\", \"backwardSFS/MLPClassifier\"]\n",
    "similarity_methods = {\"jaccard\":similarity_index.jaccard, \"dice\":similarity_index.dice, \"kuncheva\":similarity_index.kuncheva, \"mwm\":similarity_index.mwm}\n",
    "top_ks = [5, 10, 15, 20, 25]\n",
    "\n",
    "\n",
    "for fs_method in tqdm(fs_methods):\n",
    "\n",
    "    for i in range(num_repeats):\n",
    "    \n",
    "        for j in range(i+1, num_repeats):\n",
    "    \n",
    "            df1 = pd.read_csv(os.path.join(OUT_DIR, fs_method, f\"rank_df{i}.csv\"))\n",
    "            df2 = pd.read_csv(os.path.join(OUT_DIR, fs_method, f\"rank_df{j}.csv\"))\n",
    "\n",
    "            for similarity_measure, similarity_fn in similarity_methods.items():\n",
    "\n",
    "                for k in top_ks:\n",
    "\n",
    "                    estimate = similarity_fn(df1=df1, df2=df2, k=k, feats_df = feats_df)\n",
    "\n",
    "                    stability_df[\"fs_method\"].append(fs_method)\n",
    "                    stability_df[\"similarity_measure\"].append(similarity_measure)\n",
    "                    stability_df[\"top_k\"].append(k)\n",
    "                    stability_df[\"estimate\"].append(estimate)\n",
    "\n",
    "                \n",
    "            estimate = similarity_index.global_spearman(df1, df2)\n",
    "\n",
    "            stability_df[\"fs_method\"].append(fs_method)\n",
    "            stability_df[\"similarity_measure\"].append(\"global_spearman\")\n",
    "            stability_df[\"top_k\"].append(\"NA\")\n",
    "            stability_df[\"estimate\"].append(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98080385-66e6-4108-9961-755183acaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_df = pd.DataFrame(stability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "783a3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_df.to_csv(\"stability_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_df = pd.read_csv(\"stability_df.csv\")\n",
    "\n",
    "mean_stability_df = stability_df.groupby(by=[\"fs_method\", \"similarity_measure\", \"top_k\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a28ac3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['random', 'oneDSAE', 'bayesianDSAE', 'ensembleDSAE',\n",
       "       'backwardSFS/LogisticRegression', 'backwardSFS/SVC',\n",
       "       'backwardSFS/RandomForestClassifier', 'backwardSFS/MLPClassifier'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stability_df.fs_method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "115c087a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_measure</th>\n",
       "      <th>top_k</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dice</th>\n",
       "      <th>5</th>\n",
       "      <td>0.452404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.584384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.678478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.693980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.702966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_spearman</th>\n",
       "      <th>NA</th>\n",
       "      <td>0.759545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">jaccard</th>\n",
       "      <th>5</th>\n",
       "      <td>0.316288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.427787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.525472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.540514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.547949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">kuncheva</th>\n",
       "      <th>5</th>\n",
       "      <td>0.419809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.531774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.613305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.605278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.586937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">mwm</th>\n",
       "      <th>5</th>\n",
       "      <td>0.632293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.719755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.777926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.790118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.795362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          estimate\n",
       "similarity_measure top_k          \n",
       "dice               5      0.452404\n",
       "                   10     0.584384\n",
       "                   15     0.678478\n",
       "                   20     0.693980\n",
       "                   25     0.702966\n",
       "global_spearman    NA     0.759545\n",
       "jaccard            5      0.316288\n",
       "                   10     0.427787\n",
       "                   15     0.525472\n",
       "                   20     0.540514\n",
       "                   25     0.547949\n",
       "kuncheva           5      0.419809\n",
       "                   10     0.531774\n",
       "                   15     0.613305\n",
       "                   20     0.605278\n",
       "                   25     0.586937\n",
       "mwm                5      0.632293\n",
       "                   10     0.719755\n",
       "                   15     0.777926\n",
       "                   20     0.790118\n",
       "                   25     0.795362"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_stability_df\n",
    "mean_stability_df.groupby(by=[\"fs_method\", \"similarity_measure\", \"top_k\"]).mean().xs(\"ensembleDSAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the custom order and mapping\n",
    "custom_order = [\n",
    "    \"random\",\n",
    "    \"backwardSFS/LogisticRegression\",\n",
    "    \"backwardSFS/SVC\",\n",
    "    \"backwardSFS/RandomForestClassifier\",\n",
    "    \"backwardSFS/MLPClassifier\",\n",
    "    \"oneDSAE\",\n",
    "    \"bayesianDSAE\",\n",
    "    \"ensembleDSAE\"\n",
    "]\n",
    "\n",
    "label_mapping = {\n",
    "    \"random\": \"random\",\n",
    "    \"backwardSFS/LogisticRegression\": \"bSFS+LR\",\n",
    "    \"backwardSFS/SVC\": \"bSFS+L-SVM\",\n",
    "    \"backwardSFS/RandomForestClassifier\": \"bSFS+RF\",\n",
    "    \"backwardSFS/MLPClassifier\": \"bSFS+MLP\",\n",
    "    \"oneDSAE\": \"singleAE\",\n",
    "    \"bayesianDSAE\": \"bayesianAE\",\n",
    "    \"ensembleDSAE\": \"ensembleAE\"\n",
    "}\n",
    "\n",
    "# Filter and map\n",
    "plot_data = stability_df[\n",
    "    (stability_df.similarity_measure.isin([\"global_spearman\", \"kuncheva\", \"mwm\"])) &\n",
    "    (stability_df.top_k.isin([\"NA\", 5]))\n",
    "].copy()\n",
    "\n",
    "plot_data['fs_method'] = pd.Categorical(plot_data['fs_method'], categories=custom_order, ordered=True)\n",
    "plot_data['fs_method'] = plot_data['fs_method'].map(label_mapping)\n",
    "\n",
    "# # Calculate mean estimate for \"random\"\n",
    "# random_mean = stability_df[\n",
    "#     (stability_df.similarity_measure == \"global_spearman\") &\n",
    "#     (stability_df.top_k == \"NA\") &\n",
    "#     (stability_df.fs_method == \"random\")\n",
    "# ]['estimate'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=plot_data,\n",
    "    x='fs_method',\n",
    "    y='estimate',\n",
    "    errorbar='sd',\n",
    "    marker='o',\n",
    "    hue='similarity_measure',\n",
    "    style='similarity_measure',\n",
    "    markers={\n",
    "        'kuncheva': 'o',           # Circle\n",
    "        'mwm': 's',                # Square\n",
    "        'global_spearman': 'D'     # Diamond\n",
    "    },\n",
    "    hue_order=[\"global_spearman\", \"kuncheva\", \"mwm\"],\n",
    "    style_order=[\"global_spearman\", \"kuncheva\", \"mwm\"]\n",
    ")\n",
    "\n",
    "# Horizontal line for random\n",
    "# plt.axhline(y=random_mean, color='blue', linestyle='--', label='random')\n",
    "\n",
    "# Draw horizontal lines for random for each similarity_measure\n",
    "# random_means = stability_df[\n",
    "#     (stability_df.top_k.isin([\"NA\",5])) &\n",
    "#     (stability_df.fs_method == \"random\") &\n",
    "#     (stability_df.similarity_measure.isin([\"global_spearman\", \"kuncheva\", \"mwm\"]))\n",
    "# ].groupby(\"similarity_measure\")[\"estimate\"].mean()\n",
    "\n",
    "# colors = {\n",
    "#     'kuncheva': 'blue',\n",
    "#     'mwm': 'orange',\n",
    "#     'global_spearman': 'green'\n",
    "# }\n",
    "\n",
    "# for measure, mean in random_means.items():\n",
    "#     plt.axhline(y=mean, linestyle='--', color=colors.get(measure, 'gray'), label=f'random ({measure})')\n",
    "\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"stability_plot.tif\", format=\"tiff\", dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db464cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2\n",
    "\n",
    "# top-5 frequent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c99b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_methods = [\"backwardSFS/LogisticRegression\", \"backwardSFS/SVC\", \"backwardSFS/RandomForestClassifier\", \"backwardSFS/MLPClassifier\", \"oneDSAE\", \"bayesianDSAE\", \"ensembleDSAE\"]\n",
    "top_k = 5\n",
    "freq_df = {}\n",
    "freq_feats = {\"fs_method\":[], \"freq_feats\":[]}\n",
    "\n",
    "for fs_method in fs_methods:\n",
    "    \n",
    "    freq_dict = {}\n",
    "    \n",
    "    for i in range(num_repeats):\n",
    "     \n",
    "        df = pd.read_csv(os.path.join(OUT_DIR, fs_method, f\"rank_df{i}.csv\"))\n",
    "        \n",
    "        selected_feats = df.sort_values(by=\"rank\").head(top_k).feature.to_list()\n",
    "        \n",
    "        for feat in selected_feats:\n",
    "            freq_dict[feat] = freq_dict.get(feat,0)+1\n",
    "\n",
    "    feats, freq = zip(*freq_dict.items())\n",
    "    \n",
    "    freq_df[fs_method] = pd.DataFrame({\"feature\":feats, \"frequency\":freq})\n",
    "    \n",
    "    freq_feats[\"fs_method\"].append(fs_method)\n",
    "    freq_feats[\"freq_feats\"].append(sorted(freq_df[fs_method].sort_values(by=\"frequency\", ascending=False).head(top_k).feature.to_list()))\n",
    "    \n",
    "\n",
    "freq_feats = pd.DataFrame(freq_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b71e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seaborn styling for a cleaner look\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
    "\n",
    "df_exploded = freq_feats.explode(\"freq_feats\")\n",
    "\n",
    "# Pivot table creation (as you already did)\n",
    "pivot = pd.crosstab(df_exploded[\"fs_method\"], df_exploded[\"freq_feats\"])\n",
    "\n",
    "# Sort features by frequency (most to least)\n",
    "top_features = pivot.sum().sort_values(ascending=False).index\n",
    "pivot = pivot[top_features]\n",
    "\n",
    "fs_methods = [\n",
    "    \"backwardSFS/LogisticRegression\", \"backwardSFS/SVC\", \n",
    "    \"backwardSFS/RandomForestClassifier\", \"backwardSFS/MLPClassifier\", \n",
    "    \"oneDSAE\", \"bayesianDSAE\", \"ensembleDSAE\"\n",
    "]\n",
    "label_mapping = {\n",
    "    \"random\": \"random\",\n",
    "    \"backwardSFS/LogisticRegression\": \"bSFS+LR\",\n",
    "    \"backwardSFS/SVC\": \"bSFS+L-SVM\",\n",
    "    \"backwardSFS/RandomForestClassifier\": \"bSFS+RF\",\n",
    "    \"backwardSFS/MLPClassifier\": \"bSFS+MLP\",\n",
    "    \"oneDSAE\": \"singleAE\",\n",
    "    \"bayesianDSAE\": \"bayesianAE\",\n",
    "    \"ensembleDSAE\": \"ensembleAE\"\n",
    "}\n",
    "\n",
    "pivot = pivot.reindex(fs_methods)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot 'x' markers for each selected feature-method pair\n",
    "for i, method in enumerate(pivot.index):\n",
    "    for j, feat in enumerate(pivot.columns):\n",
    "        if pivot.loc[method, feat]:\n",
    "            ax.scatter(j, i, marker='x', color='black', s=60, linewidths=1.5)\n",
    "\n",
    "# Format axes\n",
    "y_labels = [label_mapping.get(method, method) for method in pivot.index]\n",
    "ax.set_yticks(range(len(pivot.index)))\n",
    "ax.set_yticklabels(y_labels, fontsize=10)\n",
    "ax.set_xticks(range(len(pivot.columns)))\n",
    "ax.set_xticklabels(pivot.columns, rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "# Add labels and styling\n",
    "ax.set_xlabel(\"Top Frequent Features\", fontsize=12)\n",
    "ax.set_ylabel(\"Feature Selection Method\", fontsize=12)\n",
    "# ax.set_title(\"Top Features Selected by Different Methods\", fontsize=14)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "ax.tick_params(axis='both', which='major', length=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"freq_plot.tif\", format=\"tiff\", dpi=600)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22875a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c288988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7d733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c9140",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    train_size=0.3,           # 30% for training\n",
    "    test_size=0.7,            # 70% for validation (optional, since it's implied)\n",
    "    stratify=y,               # Ensures stratified split\n",
    "    random_state=42           # For reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "for fs_method in fs_methods:\n",
    "    \n",
    "    print('*'*25, fs_method, '*'*25)\n",
    "    \n",
    "    feats = pivot.columns[pivot.loc[fs_method]==1].to_list()\n",
    "    \n",
    "    X, y = feats_df[feats], feats_df['label']\n",
    "    \n",
    "    \n",
    "    \n",
    "    for clf in [LogisticRegression(penalty='none', max_iter=10_000), LinearSVC(max_iter=100_000), MLPClassifier(), RandomForestClassifier()]:\n",
    "\n",
    "        # Repeated Stratified K-Fold Cross Validator\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
    "\n",
    "        # ROC AUC and Average Precision scorers\n",
    "        results = cross_validate(clf, X, y, scoring=['roc_auc', 'average_precision'], cv=cv)\n",
    "\n",
    "        print(clf.__class__.__name__,results[\"test_roc_auc\"].mean(), results[\"test_average_precision\"].mean())\n",
    "\n",
    "\n",
    "#     # Report mean and standard deviation\n",
    "#     print(f\"ROC AUC: Mean = {np.mean(roc_auc_scores):.4f}, Std = {np.std(roc_auc_scores):.4f}\")\n",
    "#     print(f\"Average Precision: Mean = {np.mean(avg_precision_scores):.4f}, Std = {np.std(avg_precision_scores):.4f}\")\n",
    "    \n",
    "#     print(fs_method, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063fc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93663724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot = pd.crosstab(df_exploded[\"fs_method\"], df_exploded[\"freq_feats\"])\n",
    "# # Limit to most common features (optional)\n",
    "# top_features = pivot.sum().sort_values(ascending=False).index\n",
    "# pivot = pivot[top_features]\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for i, method in enumerate(pivot.index):\n",
    "#     for j, feat in enumerate(pivot.columns):\n",
    "#         if pivot.loc[method, feat]:\n",
    "#             plt.scatter(j, i, marker='x', color='black')\n",
    "\n",
    "# plt.yticks(range(len(pivot.index)), pivot.index)\n",
    "# plt.xticks(range(len(pivot.columns)), pivot.columns, rotation=45, ha='right')\n",
    "# plt.xlabel(\"Top Frequent Features\")\n",
    "# plt.ylabel(\"Feature Selection Method\")\n",
    "# # plt.title(\"Top Features Selected by Different Methods\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eff385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_freq_feats = freq_feats[freq_feats.fs_method.isin([\"oneDSAE\", \"bayesianDSAE\", \"ensembleDSAE\"])].freq_feats.to_list()\n",
    "\n",
    "conv_freq_feats = freq_feats[freq_feats.fs_method.isin([\"backwardSFS/LogisticRegression\", \"backwardSFS/SVC\", \"backwardSFS/RandomForestClassifier\", \"backwardSFS/MLPClassifier\"])].freq_feats.to_list()\n",
    "\n",
    "lconv_freq_feats = freq_feats[freq_feats.fs_method.isin([\"backwardSFS/LogisticRegression\", \"backwardSFS/SVC\"])].freq_feats.to_list()\n",
    "nlconv_freq_feats = freq_feats[freq_feats.fs_method.isin([\"backwardSFS/RandomForestClassifier\", \"backwardSFS/MLPClassifier\"])].freq_feats.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_ae = set(ae_freq_feats[0]).intersection(*ae_freq_feats[1:])\n",
    "overlap_conv = set(conv_freq_feats[0]).intersection(*conv_freq_feats[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f83465",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_ae, overlap_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_lconv = set(lconv_freq_feats[0]).intersection(*lconv_freq_feats[1:])\n",
    "overlap_nlconv = set(nlconv_freq_feats[0]).intersection(*nlconv_freq_feats[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a252605",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_lconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_nlconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1dfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d95d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_methods = [\n",
    "    \"backwardSFS/LogisticRegression\", \"backwardSFS/SVC\", \n",
    "    \"backwardSFS/RandomForestClassifier\", \"backwardSFS/MLPClassifier\", \n",
    "    \"oneDSAE\", \"bayesianDSAE\", \"ensembleDSAE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c864212",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complexity_df = {\"estimator\":[], \"exe_time\":[], \"mem_usage\":[]}\n",
    "\n",
    "for fs_method in fs_methods:\n",
    "\n",
    "    result_dir = os.path.join(OUT_DIR, fs_method, \"results_df.csv\")\n",
    "    \n",
    "    results = pd.read_csv(result_dir, index_col=0)\n",
    "    \n",
    "    if \"DSAE\" in fs_method:\n",
    "        \n",
    "        if \"bayesian\" in fs_method:\n",
    "            results = results.groupby(by=\"b\").max()\n",
    "        elif \"ensemble\" in fs_method:\n",
    "            results = results.groupby(by=\"b\").sum()\n",
    "        mem_usage = (results.cpu_mem + results.gpu_mem).to_list()\n",
    "    else:\n",
    "        results = results[results.estimator==fs_method.split(\"/\")[-1]]\n",
    "        mem_usage = results.mem_usage\n",
    "        \n",
    "    exe_time = results.exe_time.to_list()\n",
    "    \n",
    "    complexity_df[\"estimator\"].append(fs_method)\n",
    "    complexity_df[\"exe_time\"].append(exe_time)\n",
    "    complexity_df[\"mem_usage\"].append(mem_usage)\n",
    "\n",
    "complexity_df = pd.DataFrame(complexity_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325526f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = complexity_df.copy()\n",
    "sns.set(style=\"whitegrid\", palette=\"gray\")\n",
    "\n",
    "fs_methods = [\n",
    "    \"backwardSFS/LogisticRegression\", \"backwardSFS/SVC\", \n",
    "    \"backwardSFS/RandomForestClassifier\", \"backwardSFS/MLPClassifier\", \n",
    "    \"oneDSAE\", \"bayesianDSAE\", \"ensembleDSAE\"\n",
    "]\n",
    "label_mapping = {\n",
    "    \"random\": \"random\",\n",
    "    \"backwardSFS/LogisticRegression\": \"bSFS+LR\",\n",
    "    \"backwardSFS/SVC\": \"bSFS+L-SVM\",\n",
    "    \"backwardSFS/RandomForestClassifier\": \"bSFS+RF\",\n",
    "    \"backwardSFS/MLPClassifier\": \"bSFS+MLP\",\n",
    "    \"oneDSAE\": \"singleAE\",\n",
    "    \"bayesianDSAE\": \"bayesianAE\",\n",
    "    \"ensembleDSAE\": \"ensembleAE\"\n",
    "}\n",
    "\n",
    "\n",
    "df['fs_method'] = df['estimator'].map(label_mapping)\n",
    "\n",
    "# Simulated: Load your DataFrame here\n",
    "# df = pd.read_csv(\"your_file.csv\") or define directly\n",
    "\n",
    "# Normalize memory values (bytes to GiB)\n",
    "df['mem_usage'] = df['mem_usage'].apply(lambda x: [float(i) for i in x])\n",
    "\n",
    "# Compute cumulative stats\n",
    "df['cumulative_time'] = df['exe_time'].apply(lambda x: sum(x) / 3600)  # hours\n",
    "df['cumulative_memory'] = df['mem_usage'].apply(lambda x: sum(x) / (1024 ** 3))  # GiB\n",
    "\n",
    "# Explode lists to individual rows for boxplots\n",
    "exploded_time = df[['fs_method', 'exe_time']].explode('exe_time')\n",
    "exploded_time['exe_time'] = exploded_time['exe_time'].astype(float) / 60  # minutes\n",
    "\n",
    "exploded_mem = df[['fs_method', 'mem_usage']].explode('mem_usage')\n",
    "exploded_mem['mem_usage'] = exploded_mem['mem_usage'].astype(float) / (1024 ** 3)  # GiB\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Top-left: Boxplot of Execution time\n",
    "sns.boxplot(\n",
    "    x='exe_time', y='fs_method', data=exploded_time, ax=axs[0, 0],\n",
    "    color='white', fliersize=3, linewidth=1, width=0.4,\n",
    "    boxprops=dict(edgecolor='black'),\n",
    "    whiskerprops=dict(color='black'),\n",
    "    capprops=dict(color='black'),\n",
    "    medianprops=dict(color='black')\n",
    ")\n",
    "axs[0, 0].set_xlabel(\"exe_time (mins)\")\n",
    "axs[0, 0].set_ylabel(\"fs_method\")\n",
    "\n",
    "# Top-right: Boxplot of Memory usage\n",
    "sns.boxplot(\n",
    "    x='mem_usage', y='fs_method', data=exploded_mem, ax=axs[0, 1],\n",
    "    color='white', fliersize=3, linewidth=1, width=0.4,\n",
    "    boxprops=dict(edgecolor='black'),\n",
    "    whiskerprops=dict(color='black'),\n",
    "    capprops=dict(color='black'),\n",
    "    medianprops=dict(color='black')\n",
    ")\n",
    "axs[0, 1].set_xlabel(\"memory (GiB)\")\n",
    "axs[0, 1].set_ylabel(\"fs_method\")\n",
    "\n",
    "# Bottom-left: Cumulative Execution Time\n",
    "sns.barplot(\n",
    "    x='cumulative_time', y='fs_method', data=df, ax=axs[1, 0],\n",
    "    color='white', edgecolor='black', width=0.4\n",
    ")\n",
    "axs[1, 0].set_xlabel(\"cumulative_exe_time (hrs)\")\n",
    "axs[1, 0].set_ylabel(\"fs_method\")\n",
    "\n",
    "# Bottom-right: Cumulative Memory Usage\n",
    "sns.barplot(\n",
    "    x='cumulative_memory', y='fs_method', data=df, ax=axs[1, 1],\n",
    "    color='white', edgecolor='black', width=0.4\n",
    ")\n",
    "axs[1, 1].set_xlabel(\"cumulative_memory (GiB)\")\n",
    "axs[1, 1].set_ylabel(\"fs_method\")\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"complexity_plot.tif\", format=\"tiff\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13df1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_time'] = df['exe_time'].apply(lambda x: sum(x) / len(x) / 60)  # convert to mins\n",
    "\n",
    "df['avg_memory'] = df['mem_usage'].apply(lambda x: sum(x) / len(x) / (1024 ** 3))  # convert to GiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8b87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d171dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142df65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ab85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92445a88-99b4-4c1f-817f-81060ac93617",
   "metadata": {},
   "source": [
    "### Statistical Analysis (Wilcoxon Signed Rank Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198d698-dd04-486f-846a-a867855a056f",
   "metadata": {},
   "source": [
    "##### <> 1. SFS+LR v/s Ensemble AE\n",
    "- global, and Kuncheva Top-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7011c8e-1522-4086-9a6c-746745284a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_measure=\"global_spearman\"\n",
    "top_k = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e6114-27cb-423f-9040-8269fb9f54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stability_df[(stability_df.fs_method==\"backwardSFS/LogisticRegression\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "y = stability_df[(stability_df.fs_method==\"random\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "\n",
    "sns_data = pd.DataFrame({\"LR\":x, \"ensembleAE\":y})\n",
    "sns.boxplot(data=sns_data)\n",
    "\n",
    "print(\"Wilcoxon Signed Rank Test: p-value = \", stats.wilcoxon(x, y).pvalue)\n",
    "\n",
    "print(\"Paired T-Test: \", \"normality, x-\", stats.shapiro(x).pvalue, \",y-\", stats.shapiro(y).pvalue, \"ttest-\", stats.ttest_rel(x, y).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e9123-7345-4996-bae1-35c4279b19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_measure=\"kuncheva\"\n",
    "top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa172d-5288-4ac5-8ac1-2b508d680d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stability_df[(stability_df.fs_method==\"backwardSFS/LogisticRegression\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "y = stability_df[(stability_df.fs_method==\"ensembleDSAE\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "\n",
    "sns_data = pd.DataFrame({\"LR\":x, \"ensembleAE\":y})\n",
    "sns.boxplot(data=sns_data)\n",
    "\n",
    "print(\"Wilcoxon Signed Rank Test: p-value = \", stats.wilcoxon(x, y).pvalue)\n",
    "\n",
    "print(\"Paired T-Test: \", \"normality, x-\", stats.shapiro(x).pvalue, \",y-\", stats.shapiro(y).pvalue, \"ttest-\", stats.ttest_rel(x, y).pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97816f7-4cd5-4c36-9f0d-33f6c00cca52",
   "metadata": {},
   "source": [
    "##### <> 1. bayesian AE v/s Ensemble AE\n",
    "- global, and Kuncheva Top-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1ebf0-90f1-4046-be89-09f25185ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_measure=\"global_spearman\"\n",
    "top_k = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028ca1d-e35f-468a-a432-3b670375bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stability_df[(stability_df.fs_method==\"bayesianDSAE\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "y = stability_df[(stability_df.fs_method==\"ensembleDSAE\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "\n",
    "sns_data = pd.DataFrame({\"bayesianAE\":x, \"ensembleAE\":y})\n",
    "sns.boxplot(data=sns_data)\n",
    "\n",
    "print(\"Wilcoxon Signed Rank Test: p-value = \", stats.wilcoxon(x, y).pvalue)\n",
    "\n",
    "print(\"Paired T-Test: \", \"normality, x-\", stats.shapiro(x).pvalue, \",y-\", stats.shapiro(y).pvalue, \"ttest-\", stats.ttest_rel(x, y).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342e3b5-5902-4f57-99bd-09035d7d8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_measure=\"kuncheva\"\n",
    "top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c9293-3397-4a21-b07e-b43c5f9ce080",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stability_df[(stability_df.fs_method==\"bayesianDSAE\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "y = stability_df[(stability_df.fs_method==\"ensembleDSAE\")&(stability_df.similarity_measure==similarity_measure)&(stability_df.top_k==top_k)].estimate.to_list()\n",
    "\n",
    "sns_data = pd.DataFrame({\"LR\":x, \"ensembleAE\":y})\n",
    "sns.boxplot(data=sns_data)\n",
    "\n",
    "print(\"Wilcoxon Signed Rank Test: p-value = \", stats.wilcoxon(x, y).pvalue)\n",
    "\n",
    "print(\"Paired T-Test: \", \"normality, x-\", stats.shapiro(x).pvalue, \",y-\", stats.shapiro(y).pvalue, \"ttest-\", stats.ttest_rel(x, y).pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e008ee6-c5b8-47b2-94aa-2a2e38066ffe",
   "metadata": {},
   "source": [
    "### Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1a51e-479c-4a95-8197-89b557ae2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"outputs\"\n",
    "FS_METHODS = [\"backwardSFS\", \"oneDSAE\", \"bayesianDSAE\", \"ensembleDSAE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450890db-ecc3-49ce-8cdc-f12832bb2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_results_df = pd.read_csv(os.path.join(DATA_DIR, \"backwardSFS/results_df.csv\"), index_col=0)\n",
    "sAE_results_df = pd.read_csv(os.path.join(DATA_DIR, \"oneDSAE\", \"results_df.csv\"))\n",
    "bAE_results_df = pd.read_csv(os.path.join(DATA_DIR, \"bayesianDSAE\", \"results_df.csv\"))\n",
    "eAE_results_df = pd.read_csv(os.path.join(DATA_DIR, \"ensembleDSAE\", \"results_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91e34f-1df2-4c3a-8243-fb5719bb3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = {\"fs_method\":[], \"# runs\":[], \"exe_time\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc7544-4563-436a-b9b9-ede04ec10a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sAE_time_df = pd.DataFrame({\"# runs\":sAE_results_df.groupby([\"outer_seed\"]).first().index.to_numpy(), \"exe_time\":sAE_results_df.groupby([\"outer_seed\"]).first()[\"exe_time\"].to_numpy()})\n",
    "time_df[\"fs_method\"] += ['singleAE'] * len(sAE_time_df)\n",
    "time_df[\"# runs\"] += list(sAE_time_df[\"# runs\"].to_numpy() + 1)\n",
    "time_df[\"exe_time\"] += list(sAE_time_df[\"exe_time\"].to_numpy())\n",
    "\n",
    "bAE_time_df = pd.DataFrame({\"# runs\":bAE_results_df.groupby([\"outer_seed\"]).first().index.to_numpy(), \"exe_time\":bAE_results_df.groupby([\"outer_seed\"]).first()[\"exe_time\"].to_numpy()})\n",
    "time_df[\"fs_method\"] += ['bayesianAE'] * len(bAE_time_df)\n",
    "time_df[\"# runs\"] += list(bAE_time_df[\"# runs\"].to_numpy() + 1)\n",
    "time_df[\"exe_time\"] += list(bAE_time_df[\"exe_time\"].to_numpy())\n",
    "\n",
    "eAE_time_df = pd.DataFrame({\"# runs\":eAE_results_df.groupby([\"outer_seed\", \"b\"]).first().groupby(\"outer_seed\").sum().index.to_numpy(), \"exe_time\":eAE_results_df.groupby([\"outer_seed\", \"b\"]).first().groupby(\"outer_seed\").sum()[\"exe_time\"].to_numpy()})\n",
    "time_df[\"fs_method\"] += ['ensembleAE'] * len(eAE_time_df)\n",
    "time_df[\"# runs\"] += list(eAE_time_df[\"# runs\"].to_numpy()+1)\n",
    "time_df[\"exe_time\"] += list(eAE_time_df[\"exe_time\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ed27e-3f0b-483a-b8f3-d1e4760762f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acronym(estimator):\n",
    "\n",
    "    acronym = \"\"\n",
    "    \n",
    "    if estimator==\"LogisticRegression\":\n",
    "        acronym = \"SFS+LR\"\n",
    "    elif estimator==\"SVC\":\n",
    "        acronym = \"SFS+L-SVM\"\n",
    "    elif estimator==\"RandomForestClassifier\":\n",
    "        acronym = \"SFS+RF\"\n",
    "    elif estimator==\"MLPClassifier\":\n",
    "        acronym = \"SFS+MLP\"\n",
    "    else:\n",
    "        print(\"Invalid estimator name\")\n",
    "\n",
    "    return acronym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a675e-0b24-49b0-b91e-202a03cf7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for estimator in [\"LogisticRegression\", \"SVC\", \"RandomForestClassifier\", \"MLPClassifier\"]:\n",
    "\n",
    "    _df = sfs_results_df.groupby([\"estimator\",\"outer_seed\"]).sum().loc[estimator]\n",
    "    sfs_time_df = pd.DataFrame({\"# runs\":_df.index.to_numpy()+1, \"exe_time\":_df[\"exe_time\"].to_numpy()})\n",
    "\n",
    "    time_df[\"fs_method\"] += [acronym(estimator)] * len(sfs_time_df)\n",
    "    time_df[\"# runs\"] += list(sfs_time_df[\"# runs\"].to_numpy()+1)\n",
    "    time_df[\"exe_time\"] += list(sfs_time_df[\"exe_time\"].to_numpy())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ffa89-73dc-48fc-a010-04581c532276",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame(time_df)\n",
    "time_df[\"cumulative_exe_time\"] = time_df.groupby('fs_method')['exe_time'].cumsum()\n",
    "\n",
    "display(time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e964fe8-dbd8-4564-9e34-61886924d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['exe_time (mins)'] = time_df['exe_time']/60\n",
    "time_df['cumulative_exe_time (mins)'] = time_df['cumulative_exe_time']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe35aa0-94bd-4647-9904-48dc5dc8ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a84b0-8c1a-4243-945a-8ae28b231c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=time_df, x='exe_time (mins)', y='fs_method', width=.2, fill=False, color=\".1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586d185-c48f-4298-b9e0-667fbdbbc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(data=time_df, x='cumulative_exe_time', y='fs_method', width=.2, fill=False, color=\".4\")\n",
    "# sns.boxplot(data=time_df, x='exe_time', y='fs_method', width=.2, fill=False, color=\".4\")\n",
    "sns.barplot(data=time_df, x='cumulative_exe_time (mins)', y='fs_method', width=.2, fill=False, color=\".1\", errorbar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e946736-34be-4f52-a7be-6ead97986722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e7673-2836-46c1-bf57-45e92d27b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a8419-55bb-447f-9f26-639bd7fa062d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ee8f4-c15f-4753-83eb-41ed44c97829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6570c-1a8a-4fa0-bbff-e5bf8130b184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26593a9f-16ef-49ff-9c3b-0627f21b1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='# runs', y=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b0532-3596-4159-815c-d788f676df6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d0412-414e-4491-b9b1-10b66c7c8fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef06d40-c18c-4b1e-96d3-afe9c431ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "eAE_results_df.groupby([\"outer_seed\", \"b\"]).first().groupby(\"outer_seed\").sum()[\"exe_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767261a7-e9e9-4702-af78-25be6e2ec3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eAE_results_df.groupby([\"outer_seed\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9c171-0d2e-4750-9fe9-40bec90573c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eAE_results_df.groupby([\"outer_seed\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320ca6c-1b66-4b84-95a9-23411b70bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eAE_results_df.groupby([\"outer_seed\",\"b\", \"permute_seed\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f864021-e51a-4e20-9f4e-6af7c0ae6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "eAE_results_df.groupby([\"outer_seed\", \"permute_seed\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d9560-da36-434c-b149-0354b2f9e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bAE_results_df.groupby(\"outer_seed\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8a8b8-e048-48c3-b223-49d62db9dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sAE_results_df.groupby(\"outer_seed\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db7c26-8b86-4aed-9a74-1167b85cce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fs_method in FS_METHODS:\n",
    "\n",
    "    results_df = pd.read_csv(os.path.join(DATA_DIR, fs_method, \"results_df.csv\"))\n",
    "\n",
    "    display(results_df.head(10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8ae9b-94a7-47d2-899c-b41883881969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
