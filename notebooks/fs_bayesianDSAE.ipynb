{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56179a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") #to access custom \"utils\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcfbf80-9a72-4680-afbf-03f67e2cd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "import gc\n",
    "import tracemalloc\n",
    "import GPUtil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import nn_utils\n",
    "from utils import similarity_index\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b744b7-a69d-4cc3-9765-6f3a03631445",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = os.path.join(\"..\", r\"inputs/radiomicsFeatures.csv\")\n",
    "OUT_DIR = r\"outputs/bayesianDSAE\"\n",
    "MASK_FEATS = [\"id\", \"label\"]\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "CUDA_DEVICE_ID = 1\n",
    "NUM_REPEATS = 100\n",
    "\n",
    "B = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1fa93-0417-4b87-a8ea-fe5f6979e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c4213-fff2-44f4-90f3-60268172e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = feats_df.id.to_numpy()\n",
    "labels = feats_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory(init_mem):\n",
    "    \n",
    "    global CUDA_DEVICE_ID\n",
    "    \n",
    "    return (GPUtil.getGPUs()[CUDA_DEVICE_ID].memoryUsed-init_mem) #in MiB\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6ce8d-8db8-48f7-9026-f639fcb2e216",
   "metadata": {},
   "source": [
    "### Feature Selection Pipeline with MonteCarlo Model Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c7a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_gpu_memory = get_gpu_memory(0.0) #in MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb9dbd-89a0-461d-bea6-a69683f04c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats = feats_df.columns[~feats_df.columns.isin(MASK_FEATS)].to_list()\n",
    "\n",
    "results_df = {**{\"outer_seed\":[], \"exe_time\":[], \"cpu_mem\":[], \"gpu_mem\":[], \"b\":[], \"re_mean0\":[], \"re_mean1\":[]}, **{\"delta_\"+feat:[] for feat in feats}} # {**dict1, **dict2,...} is a way to merge multiple dictionaries\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for i in tqdm(range(NUM_REPEATS), position=0, desc=\"running bayesianDSAE\"):\n",
    "    \n",
    "    if VERBOSE:\n",
    "\n",
    "        print(f\"Running for repeat#- {i+1}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    gc.collect()\n",
    "    tracemalloc.start()\n",
    "\n",
    "    num_epochs = 1_000\n",
    "    batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    lr = 1e-3\n",
    "    h_lambda = 1e-2 #with l1 regularization\n",
    "    \n",
    "    input_dim = len(feats)\n",
    "    latent_dim = 10\n",
    "    \n",
    "    activation_fn = nn.LeakyReLU()\n",
    "    encoder_layers = [50, 30, 20] #under-complete hidden layers\n",
    "\n",
    "    #the train v/s test pids changes with each repeat; soft-perturbation\n",
    "    train_pids, test_pids, train_labels, test_labels = train_test_split(pids, labels, test_size=0.25, random_state=i, stratify=labels)\n",
    "\n",
    "    X =  feats_df[feats_df[\"id\"].isin(train_pids)][feats].to_numpy()\n",
    "    y = feats_df[feats_df[\"id\"].isin(train_pids)].label.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # X[X>=3] = 3\n",
    "    # X[X<=-3] = -3\n",
    "\n",
    "    X_norm, X_anomaly = nn_utils.norm_anomaly_split(X, y)\n",
    "    \n",
    "    # we can keep the seed fixed here, because train/val split difference is enough to simulate soft-perturbation\n",
    "    np.random.seed(0)\n",
    "    idx = np.random.permutation(len(X_norm))\n",
    "    \n",
    "    X_train= X_norm[idx[:-len(X_anomaly)]]\n",
    "    X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "    X_test_anomaly = X_anomaly\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train[X_train>=3] = 3\n",
    "    X_train[X_train<=-3] = -3\n",
    "    \n",
    "    X_test_norm = scaler.transform(X_test_norm)\n",
    "    X_test_norm[X_test_norm>=3] = 3\n",
    "    X_test_norm[X_test_norm<=-3] = -3\n",
    "    \n",
    "    X_test_anomaly = scaler.transform(X_test_anomaly)\n",
    "    X_test_anomaly[X_test_anomaly>=3] = 3\n",
    "    X_test_anomaly[X_test_anomaly<=-3] = -3\n",
    "    \n",
    "    \n",
    "    X_train =  torch.from_numpy(X_train).float()\n",
    "    X_test_norm = torch.from_numpy(X_test_norm).float()\n",
    "    X_test_anomaly = torch.from_numpy(X_test_anomaly).float()\n",
    "    X_test = torch.cat([X_test_norm, X_test_anomaly])\n",
    "\n",
    "    train_ds = nn_utils.Dataset(X_train)\n",
    "    val_ds = nn_utils.Dataset(X_train)\n",
    "    dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "    \n",
    "    bayesian_dsae = nn_utils.bayesianAutoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn, dropout_prob=0.5)\n",
    "    model = nn_utils.Model(bayesian_dsae)\n",
    "    model.compile(lr, h_lambda, loss_fn, cuda_device_id=CUDA_DEVICE_ID)\n",
    "    _ = model.fit(dls, num_epochs, verbose=False)\n",
    "\n",
    "    gpu_mem = get_gpu_memory(init_gpu_memory) * 2**20 #MiB to bytes\n",
    "    current, cpu_mem = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    exe_time = time.perf_counter()-start_time\n",
    "\n",
    "    for b in range(B):\n",
    "\n",
    "        model.net.train() #to enable dropout for stochasticity during inference\n",
    "        \n",
    "        recon_X_test_norm, h_norm = model.net(X_test_norm)\n",
    "        recon_X_test_anomaly, h_anomaly = model.net(X_test_anomaly)\n",
    "\n",
    "        recon_X_test = torch.cat([recon_X_test_norm, recon_X_test_anomaly])\n",
    "        y_test = torch.cat([torch.zeros(len(recon_X_test_norm)), torch.ones(len(recon_X_test_anomaly))])\n",
    "        \n",
    "        re_test = nn.MSELoss(reduction=\"none\")(recon_X_test, X_test)\n",
    "        \n",
    "        re_test0 = re_test[y_test==0].mean(dim=0)\n",
    "        re_test1 = re_test[y_test==1].mean(dim=0)\n",
    "        \n",
    "        deltas = re_test1 - re_test0\n",
    "        \n",
    "        results_df[\"outer_seed\"].append(i)\n",
    "        results_df[\"exe_time\"].append(exe_time)\n",
    "        results_df[\"cpu_mem\"].append(cpu_mem)\n",
    "        results_df[\"gpu_mem\"].append(gpu_mem)\n",
    "        results_df[\"b\"].append(b)\n",
    "        results_df[\"re_mean0\"].append(re_test0.mean().item())\n",
    "        results_df[\"re_mean1\"].append(re_test1.mean().item())\n",
    "\n",
    "        for feat, delta in zip(feats, deltas):\n",
    "            results_df[\"delta_\"+feat].append(delta.item())\n",
    "        \n",
    "        if VERBOSE:\n",
    "            print(\"b=\", b, \"normal_mse=\",re_test0.mean().item(), \"anomaly_mse=\", re_test1.mean().item(), \"anomaly_mse>normal_mse=\", re_test1.mean().item()>re_test0.mean().item())\n",
    "\n",
    "        \n",
    "    _df = pd.DataFrame(results_df)\n",
    "    _results_df = _df[_df.outer_seed==i].mean()\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"run #{i}: normal_mse=\",_results_df.re_mean0, \"anomaly_mse=\", _results_df.re_mean1, \"anomaly_mse>normal_mse=\", _results_df.re_mean1>_results_df.re_mean0)\n",
    "\n",
    "    delta_df = _results_df[[\"delta_\"+feat for feat in feats]]\n",
    "\n",
    "    ranks = (len(delta_df) - (delta_df.argsort().argsort() + 1) + 1).to_list()\n",
    "    rank_df = pd.DataFrame({\"feature\":feats, \"rank\":ranks})\n",
    "    rank_df.to_csv(os.path.join(OUT_DIR, f\"rank_df{i}.csv\"), index=False)\n",
    "    \n",
    "    \n",
    "results_df = pd.DataFrame(results_df) \n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"results_df.csv\"), index=False)\n",
    "\n",
    "print(\"Completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
