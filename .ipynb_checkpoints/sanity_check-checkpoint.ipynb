{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b991d9a2-84e8-4f21-8c11-81698c022746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "import copy as copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70626d02-36b6-4c4f-bcf3-a2799741adac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XL_PATH = r\"curated_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8021174f-0b86-42f4-9f0d-39d70d443e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>sub_wout_original_glcm_ClusterProminence</th>\n",
       "      <th>adc_original_firstorder_Minimum</th>\n",
       "      <th>sub_wout_original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>sub_wout_original_firstorder_Maximum</th>\n",
       "      <th>adc_original_glcm_ClusterShade</th>\n",
       "      <th>sub_wout_original_firstorder_Mean</th>\n",
       "      <th>sub_win_original_glcm_Autocorrelation</th>\n",
       "      <th>adc_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_win_original_glszm_ZoneEntropy</th>\n",
       "      <th>t2w_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>t2w_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>sub_win_original_glcm_MaximumProbability</th>\n",
       "      <th>sub_win_original_glcm_Imc1</th>\n",
       "      <th>sub_wout_original_glcm_JointEntropy</th>\n",
       "      <th>t2w_original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2535039</td>\n",
       "      <td>1</td>\n",
       "      <td>4.677862e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14835.837461</td>\n",
       "      <td>299.900214</td>\n",
       "      <td>3755.933491</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>...</td>\n",
       "      <td>6.339939</td>\n",
       "      <td>0.286470</td>\n",
       "      <td>10.166389</td>\n",
       "      <td>27423.571919</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>2946.837800</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.041978</td>\n",
       "      <td>10.452108</td>\n",
       "      <td>0.033786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2417361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.834267e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-17634.034850</td>\n",
       "      <td>299.918235</td>\n",
       "      <td>3941.494865</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.424770</td>\n",
       "      <td>0.350004</td>\n",
       "      <td>11.649157</td>\n",
       "      <td>21732.551407</td>\n",
       "      <td>0.604518</td>\n",
       "      <td>3322.225544</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.109242</td>\n",
       "      <td>11.891117</td>\n",
       "      <td>0.009861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2602563</td>\n",
       "      <td>1</td>\n",
       "      <td>5.159220e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-19736.430500</td>\n",
       "      <td>299.820687</td>\n",
       "      <td>2455.254084</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>...</td>\n",
       "      <td>7.239270</td>\n",
       "      <td>0.350692</td>\n",
       "      <td>10.919838</td>\n",
       "      <td>15567.069802</td>\n",
       "      <td>0.574356</td>\n",
       "      <td>3407.597573</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.194449</td>\n",
       "      <td>11.214368</td>\n",
       "      <td>0.018991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2902440</td>\n",
       "      <td>0</td>\n",
       "      <td>3.613791e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-12881.976888</td>\n",
       "      <td>299.240444</td>\n",
       "      <td>3954.079034</td>\n",
       "      <td>0.576021</td>\n",
       "      <td>...</td>\n",
       "      <td>7.454390</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>18389.243521</td>\n",
       "      <td>0.566131</td>\n",
       "      <td>3121.573712</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>11.669841</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2921898</td>\n",
       "      <td>0</td>\n",
       "      <td>5.773968e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2116.811733</td>\n",
       "      <td>299.983523</td>\n",
       "      <td>3793.819336</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.755170</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>9.504938</td>\n",
       "      <td>245786.779116</td>\n",
       "      <td>0.469149</td>\n",
       "      <td>3175.569089</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.058680</td>\n",
       "      <td>11.459667</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  sub_wout_original_glcm_ClusterProminence  \\\n",
       "0  2535039      1                              4.677862e+06   \n",
       "1  2417361      0                              4.834267e+06   \n",
       "2  2602563      1                              5.159220e+06   \n",
       "3  2902440      0                              3.613791e+06   \n",
       "4  2921898      0                              5.773968e+06   \n",
       "\n",
       "   adc_original_firstorder_Minimum  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              0.0   \n",
       "\n",
       "   sub_wout_original_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                          0.003103   \n",
       "1                                          0.001672   \n",
       "2                                          0.001600   \n",
       "3                                          0.002428   \n",
       "4                                          0.001720   \n",
       "\n",
       "   sub_wout_original_firstorder_Maximum  adc_original_glcm_ClusterShade  \\\n",
       "0                                 600.0                    14835.837461   \n",
       "1                                 600.0                   -17634.034850   \n",
       "2                                 600.0                   -19736.430500   \n",
       "3                                 600.0                   -12881.976888   \n",
       "4                                 600.0                     2116.811733   \n",
       "\n",
       "   sub_wout_original_firstorder_Mean  sub_win_original_glcm_Autocorrelation  \\\n",
       "0                         299.900214                            3755.933491   \n",
       "1                         299.918235                            3941.494865   \n",
       "2                         299.820687                            2455.254084   \n",
       "3                         299.240444                            3954.079034   \n",
       "4                         299.983523                            3793.819336   \n",
       "\n",
       "   adc_original_glszm_LargeAreaLowGrayLevelEmphasis  ...  \\\n",
       "0                                          0.010393  ...   \n",
       "1                                          0.058145  ...   \n",
       "2                                          0.019202  ...   \n",
       "3                                          0.576021  ...   \n",
       "4                                          0.011764  ...   \n",
       "\n",
       "   sub_win_original_glszm_ZoneEntropy  \\\n",
       "0                            6.339939   \n",
       "1                            7.424770   \n",
       "2                            7.239270   \n",
       "3                            7.454390   \n",
       "4                            6.755170   \n",
       "\n",
       "   t2w_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.286470    \n",
       "1                                           0.350004    \n",
       "2                                           0.350692    \n",
       "3                                           0.380537    \n",
       "4                                           0.265413    \n",
       "\n",
       "   t2w_original_glcm_JointEntropy  \\\n",
       "0                       10.166389   \n",
       "1                       11.649157   \n",
       "2                       10.919838   \n",
       "3                       11.530000   \n",
       "4                        9.504938   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                       27423.571919   \n",
       "1                                       21732.551407   \n",
       "2                                       15567.069802   \n",
       "3                                       18389.243521   \n",
       "4                                      245786.779116   \n",
       "\n",
       "   sub_win_original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                           0.461100        \n",
       "1                                           0.604518        \n",
       "2                                           0.574356        \n",
       "3                                           0.566131        \n",
       "4                                           0.469149        \n",
       "\n",
       "   sub_wout_original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                        2946.837800        \n",
       "1                                        3322.225544        \n",
       "2                                        3407.597573        \n",
       "3                                        3121.573712        \n",
       "4                                        3175.569089        \n",
       "\n",
       "   sub_win_original_glcm_MaximumProbability  sub_win_original_glcm_Imc1  \\\n",
       "0                                  0.034622                   -0.041978   \n",
       "1                                  0.002107                   -0.109242   \n",
       "2                                  0.004002                   -0.194449   \n",
       "3                                  0.004134                   -0.116415   \n",
       "4                                  0.027634                   -0.058680   \n",
       "\n",
       "   sub_wout_original_glcm_JointEntropy  \\\n",
       "0                            10.452108   \n",
       "1                            11.891117   \n",
       "2                            11.214368   \n",
       "3                            11.669841   \n",
       "4                            11.459667   \n",
       "\n",
       "   t2w_original_glszm_LargeAreaLowGrayLevelEmphasis  \n",
       "0                                          0.033786  \n",
       "1                                          0.009861  \n",
       "2                                          0.018991  \n",
       "3                                          0.007846  \n",
       "4                                          0.024444  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df = pd.read_csv(XL_PATH)\n",
    "\n",
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc17915-8cc7-416e-a38e-d6bcf5163e8c",
   "metadata": {},
   "source": [
    "### Autoencoder Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9c52f-ad80-471a-9b36-2aa85680be5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f23cb4e-551e-4421-a656-80f5e46c01b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ab2dc7-3caf-4f61-8101-31d5ec9d729e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoisyDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, X, p = 0.3):\n",
    "        self.X = X\n",
    "        self.p = p\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        x = self.X[i]\n",
    "        \n",
    "        noise = nn.Dropout(np.random.uniform(0, self.p))(torch.ones(x.shape))\n",
    "        \n",
    "        noisy_x = x * noise\n",
    "        \n",
    "        return noisy_x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208a1325-3716-441a-8e6d-24c5b8565a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SyntheticNoisyDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, X, p = 0.3):\n",
    "        self.ds = NoisyDataset(X, p)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        noisy_x, _ = self.ds[i]\n",
    "        return noisy_x, noisy_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45849542-1d55-4972-ae17-3f3cff7860e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c19d579-a051-4b4e-9321-6d2d4f94ca12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FC_Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_feats, hidden_layers, activation_fn = nn.LeakyReLU()):\n",
    "        \n",
    "        super(FC_Block, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for out_feats in hidden_layers:\n",
    "            layers += [nn.Linear(in_feats, out_feats), activation_fn]\n",
    "            in_feats = out_feats\n",
    "            \n",
    "        self.block = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.block(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7c8add-56ee-4b05-96bd-c38e116121a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, encoder_layers=[100,50,25], latent_dim=5, activation_fn = nn.LeakyReLU()):\n",
    "        \n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder_block = FC_Block(input_dim, encoder_layers, activation_fn)\n",
    "        \n",
    "        self.embedding_layer = nn.Sequential(*[nn.Linear(encoder_layers[-1], latent_dim), activation_fn])\n",
    "        \n",
    "        decoder_layers = list(reversed(encoder_layers))\n",
    "        self.decoder_block = FC_Block(latent_dim, decoder_layers, activation_fn)\n",
    "        self.scores = nn.Linear(decoder_layers[-1], input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encoder_block(x)\n",
    "        h = x = self.embedding_layer(x)\n",
    "        x = self.decoder_block(x)\n",
    "        x = self.scores(x)\n",
    "        \n",
    "        return x, h\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f6c92-60c4-4e92-89c6-a5466c87e5dc",
   "metadata": {},
   "source": [
    "##### Training/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9e811300-e230-4256-9b92-9ac7895e5673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, net):\n",
    "        self.net = net\n",
    "        \n",
    "    def compile(self, lr, h_lambda, loss_fn, cuda_device_id=0):\n",
    "        \n",
    "        self.h_lambda = h_lambda\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr)\n",
    "        self.loss_fn = loss_fn \n",
    "        self.device = torch.device(f\"cuda:{cuda_device_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.net.to(self.device)\n",
    "        \n",
    "    def prepare_minibatch(self, mini_batch):\n",
    "        \n",
    "        inputs, targets = mini_batch\n",
    "        \n",
    "        return inputs.float().to(self.device), targets.float().to(self.device)\n",
    "        \n",
    "    def fit(self, dls, num_epochs, verbose=True):\n",
    "        \n",
    "        since = time.time()\n",
    "        \n",
    "        hist = {'train':{'loss':[]}, 'val':{'loss':[]}}\n",
    "        \n",
    "        best_loss = np.inf\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            if verbose:\n",
    "                \n",
    "                print('Epoch {}/{}'.format(epoch,num_epochs-1))\n",
    "                print('-'*10)\n",
    "                \n",
    "            for phase in [\"train\", \"val\"]:\n",
    "                \n",
    "                if phase==\"train\":\n",
    "                    self.net.train()\n",
    "                else:\n",
    "                    self.net.eval()\n",
    "                    \n",
    "                running_loss = 0.0\n",
    "                \n",
    "                for mini_batch in dls[phase]:\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    \n",
    "                    inputs, targets = self.prepare_minibatch(mini_batch)\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase==\"train\"):\n",
    "                        \n",
    "                        recon_inputs, h = self.net(inputs)\n",
    "                        \n",
    "                        loss = self.loss_fn(recon_inputs, targets) + self.h_lambda * h.flatten().abs().sum()\n",
    "                        \n",
    "                        if phase==\"train\":\n",
    "                            \n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "                            \n",
    "                        running_loss += loss.item()\n",
    "                            \n",
    "                epoch_loss = running_loss/len(dls[phase])\n",
    "                hist[phase][\"loss\"].append(epoch_loss)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"{} Loss :{:.4f}\".format(phase,epoch_loss))\n",
    "                    \n",
    "                if phase == \"val\":\n",
    "                    \n",
    "                    if epoch_loss<best_loss:\n",
    "                        best_loss = epoch_loss\n",
    "                        best_model_wts = copy.deepcopy(self.net.state_dict())\n",
    "                        if verbose:\n",
    "                            print(f\"Checkpoing made at {epoch}\")\n",
    "                        \n",
    "            if verbose:\n",
    "                print()\n",
    "                \n",
    "            \n",
    "        time_elapsed = time.time() - since\n",
    "        \n",
    "        \n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best val Loss: {:4f}'.format(best_loss)) \n",
    "\n",
    "        \n",
    "        self.net.load_state_dict(best_model_wts)\n",
    "        \n",
    "        return self.net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb1d156e-b218-45cd-8065-2abe7024c8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm_anomaly_split(X, y):\n",
    "    \n",
    "    normal_indeces = np.argwhere(y==0).ravel()\n",
    "    anomaly_indeces = np.argwhere(y==1).ravel()\n",
    "    \n",
    "    X_norm = X[normal_indeces]\n",
    "    X_anomaly = X[anomaly_indeces]\n",
    "\n",
    "    return X_norm, X_anomaly\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31220cc-2f84-4ed8-b25e-fbe569c1b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_using_tsne(X, y, n_components=2):\n",
    "    \n",
    "    X_transformed = TSNE(n_components = n_components, random_state=0).fit_transform(X)\n",
    "    \n",
    "    plt.scatter(*zip(*X_transformed[y==1]), marker='o', color='r', s=10, label='Anomalous')\n",
    "    plt.scatter(*zip(*X_transformed[y==0]), marker='o', color='g', s=10, label='Normal')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf57083-a415-4983-8de4-15f4ba2401c3",
   "metadata": {},
   "source": [
    "### Autoencoder Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94132c8d-7e37-45a9-95ba-5c0e44da0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mvaldenegro/UncertaintyML-course-ESSAI-labs\n",
    "# https://github.com/mvaldenegro/UncertaintyML-course-ESSAI-labs/blob/main/02_eval_uncertainty_calibration.ipynb\n",
    "# https://atcold.github.io/NYU-DLSP20/en/week01/01-3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c8754b-fe01-45f6-9d48-0543a05fb69f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "feats = [column for column in feats_df.columns if column not in [\"id\",\"label\"]]\n",
    "print(len(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "104520ac-316a-4fa0-a4d0-935012e5b7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = feats_df[feats].to_numpy()\n",
    "y = feats_df[\"label\"].to_numpy()\n",
    "\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "X_norm, X_anomaly = norm_anomaly_split(X, y)\n",
    "\n",
    "X_norm = scaler.fit_transform(X_norm) #this works better than the alternative where you standardize the whole X\n",
    "X_anomaly = scaler.transform(X_anomaly)\n",
    "\n",
    "X_norm = torch.from_numpy(X_norm).float()\n",
    "X_anomaly = torch.from_numpy(X_anomaly).float()\n",
    "\n",
    "_, input_dim = X.shape\n",
    "\n",
    "torch.manual_seed(0)\n",
    "idx = torch.randperm(len(X_norm))\n",
    "\n",
    "X_train = X_norm[idx[:-len(X_anomaly)]]\n",
    "\n",
    "X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "X_test_anomaly = X_anomaly\n",
    "\n",
    "# X_test = torch.concat([X_test_norm, X_test_anomaly])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1abe0-d133-45f7-b759-57686d82933d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize_using_tsne(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b2952458-50f7-4a33-8cad-d4992133b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10_000\n",
    "batch_size = 32\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "latent_dim = 5\n",
    "\n",
    "activation_fn = nn.LeakyReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec0d7a-4217-4d22-a9a3-48f1b20df0f6",
   "metadata": {},
   "source": [
    "##### 1. Single Standard Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5ed5ec7d-01d9-4529-baad-b68beb298481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 0m 43s\n",
      "Best val Loss: 0.000004\n"
     ]
    }
   ],
   "source": [
    "train_ds = Dataset(X_train)\n",
    "val_ds = Dataset(X_train)\n",
    "dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "\n",
    "h_lambda = 0.0 #disabling l1 sparsity constraint\n",
    "encoder_layers = [50, 25, 10] #under-complete hidden layers\n",
    "standard_ae = Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "\n",
    "model = Model(standard_ae)\n",
    "model.compile(lr, h_lambda, loss_fn)\n",
    "_ = model.fit(dls, num_epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cefdfcf3-0e0a-41c9-b0a3-a4d24a2bbd29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0178026 1.083022\n"
     ]
    }
   ],
   "source": [
    "recon_X_test_norm, h = model.net(X_test_norm)\n",
    "recon_X_test_anomaly, h = model.net(X_test_anomaly)\n",
    "\n",
    "normal_mse = nn.MSELoss(reduction=\"none\")(recon_X_test_norm, X_test_norm).mean(axis=0).detach().numpy()\n",
    "anomaly_mse = nn.MSELoss(reduction=\"none\")(recon_X_test_anomaly, X_test_anomaly).mean(axis=0).detach().numpy()\n",
    "\n",
    "delta = anomaly_mse - normal_mse\n",
    "rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "\n",
    "print(normal_mse.mean(), anomaly_mse.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e0cb3-2bcc-4fee-abf5-2103d8f49f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Mixup augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5032b54-4014-4620-95d3-d597f8e63667",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 2. Single Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "797cd322-0764-450e-ac28-b2f4f82013bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 0m 58s\n",
      "Best val Loss: 1.155962\n"
     ]
    }
   ],
   "source": [
    "train_ds = Dataset(X_train)\n",
    "val_ds = Dataset(X_train)\n",
    "dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "\n",
    "h_lambda = 1e-2 #with l1 regularization\n",
    "encoder_layers = [50, 25, 10] #under-complete hidden layers\n",
    "sparse_ae = Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "\n",
    "model = Model(sparse_ae)\n",
    "model.compile(lr, h_lambda, loss_fn)\n",
    "_ = model.fit(dls, num_epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f1343c93-d976-4995-9b04-50a13f9a9836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86655784 1.0333871\n"
     ]
    }
   ],
   "source": [
    "recon_X_test_norm, h = model.net(X_test_norm)\n",
    "recon_X_test_anomaly, h = model.net(X_test_anomaly)\n",
    "\n",
    "normal_mse = nn.MSELoss(reduction=\"none\")(recon_X_test_norm, X_test_norm).mean(axis=0).detach().numpy()\n",
    "anomaly_mse = nn.MSELoss(reduction=\"none\")(recon_X_test_anomaly, X_test_anomaly).mean(axis=0).detach().numpy()\n",
    "\n",
    "delta = anomaly_mse - normal_mse\n",
    "rank = len(delta) - (delta.argsort().argsort() + 1) + 1\n",
    "\n",
    "print(normal_mse.mean(), anomaly_mse.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "172c02b0-c3d3-4d60-8343-d20e193571e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 3)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank.argmin(), rank.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd265dff-d261-4566-a35b-9f0a0968eca1",
   "metadata": {},
   "source": [
    "##### 3. Ensemble Sparse Autoencoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "6f89af25-66b6-4032-8fd6-66b92f0fdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_count = 100\n",
    "\n",
    "num_epochs = 10_000\n",
    "batch_size = 32\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "latent_dim = 5\n",
    "\n",
    "activation_fn = nn.LeakyReLU()\n",
    "\n",
    "h_lambda = 1e-2 #with l1 regularization\n",
    "encoder_layers = [50, 25, 10] #under-complete hidden layers\n",
    "sparse_ae = Autoencoder(input_dim, encoder_layers=encoder_layers, latent_dim=latent_dim, activation_fn = activation_fn)\n",
    "\n",
    "results_df = {**{\"ae_id\":[], \"mse_mean\":[]}, **{\"mse_\"+f:[] for f in feats}, **{\"label\":[]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda1b24-6613-4fe0-b18f-31ad8d29112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Autoencoder ID: 1\n",
      "Training complete in 0m 43s\n",
      "Best val Loss: 0.193056\n",
      "normal_mse= 1.1711873 anomaly_mse= 1.3523108\n",
      "**************************************************\n",
      "Autoencoder ID: 2\n",
      "Training complete in 0m 43s\n",
      "Best val Loss: 0.142379\n",
      "normal_mse= 11.432494 anomaly_mse= 1.3132628\n",
      "**************************************************\n",
      "Autoencoder ID: 3\n",
      "Training complete in 0m 43s\n",
      "Best val Loss: 0.113647\n",
      "normal_mse= 1.1749511 anomaly_mse= 1.7340851\n",
      "**************************************************\n",
      "Autoencoder ID: 4\n"
     ]
    }
   ],
   "source": [
    "for ae_id in range(ensemble_count):\n",
    "    \n",
    "    print(\"*\"*50)\n",
    "    print(f\"Autoencoder ID: {ae_id+1}\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = feats_df[feats].to_numpy()\n",
    "    y = feats_df[\"label\"].to_numpy()\n",
    "\n",
    "    # X = scaler.fit_transform(X)\n",
    "\n",
    "    X_norm, X_anomaly = norm_anomaly_split(X, y)\n",
    "\n",
    "    X_norm = scaler.fit_transform(X_norm) #this works better than the alternative where you standardize the whole X\n",
    "    X_anomaly = scaler.transform(X_anomaly)\n",
    "\n",
    "    X_norm = torch.from_numpy(X_norm).float()\n",
    "    X_anomaly = torch.from_numpy(X_anomaly).float()\n",
    "\n",
    "    _, input_dim = X.shape\n",
    "\n",
    "    # torch.manual_seed(0) #this is where each ensemble run essentially differ, \n",
    "    idx = torch.randperm(len(X_norm))\n",
    "\n",
    "    X_train = X_norm[idx[:-len(X_anomaly)]]\n",
    "\n",
    "    X_test_norm = X_norm[idx[-len(X_anomaly):]]\n",
    "    X_test_anomaly = X_anomaly\n",
    "\n",
    "    \n",
    "    train_ds = Dataset(X_train)\n",
    "    val_ds = Dataset(X_train)\n",
    "    dls = {\"train\":torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True),\"val\":torch.utils.data.DataLoader(val_ds, batch_size=batch_size)}\n",
    "\n",
    "    model = Model(sparse_ae)\n",
    "    model.compile(lr, h_lambda, loss_fn)\n",
    "    _ = model.fit(dls, num_epochs, verbose=False)\n",
    "    \n",
    "    recon_X_test_norm, h = model.net(X_test_norm)\n",
    "    recon_X_test_anomaly, h = model.net(X_test_anomaly)\n",
    "\n",
    "    normal_mse = nn.MSELoss(reduction=\"none\")(recon_X_test_norm, X_test_norm).mean(axis=0).detach().numpy()\n",
    "    anomaly_mse = nn.MSELoss(reduction=\"none\")(recon_X_test_anomaly, X_test_anomaly).mean(axis=0).detach().numpy()\n",
    "    \n",
    "    \n",
    "    results_df[\"ae_id\"].append(ae_id+1)\n",
    "    results_df[\"mse_mean\"].append(normal_mse.mean())\n",
    "    for f, f_normal_mse in zip(feats, normal_mse):\n",
    "        results_df[\"mse_\"+f].append(f_normal_mse)\n",
    "    results_df[\"label\"].append(0)\n",
    "        \n",
    "    results_df[\"ae_id\"].append(ae_id+1)\n",
    "    results_df[\"mse_mean\"].append(anomaly_mse.mean())\n",
    "    for f, f_anomaly_mse in zip(feats, anomaly_mse):\n",
    "        results_df[\"mse_\"+f].append(f_anomaly_mse)\n",
    "    results_df[\"label\"].append(1)\n",
    "        \n",
    "    print(\"normal_mse=\", normal_mse.mean(), \"anomaly_mse=\", anomaly_mse.mean())\n",
    "    \n",
    "results_df = pd.DataFrame(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ab4aa-3288-46c2-a7e1-168c8e38edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
